Warning: Ignoring non-spark config property: hive.exec.reducers.bytes.per.reducer=67108864
Warning: Ignoring non-spark config property: hive.fetch.task.aggr=false
Warning: Ignoring non-spark config property: hive.merge.sparkfiles=false
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask=true
Warning: Ignoring non-spark config property: hive.merge.size.per.task=256000000
Warning: Ignoring non-spark config property: hive.smbjoin.cache.rows=10000
Warning: Ignoring non-spark config property: hive.merge.smallfiles.avgsize=16000000
Warning: Ignoring non-spark config property: hive.optimize.sort.dynamic.partition=false
Warning: Ignoring non-spark config property: hive.exec.orc.default.stripe.size=67108864
Warning: Ignoring non-spark config property: hive.vectorized.execution.enabled=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication.min.reducer=4
Warning: Ignoring non-spark config property: hive.orc.splits.include.file.footer=false
Warning: Ignoring non-spark config property: hive.merge.mapfiles=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.list-status.num-threads=5
Warning: Ignoring non-spark config property: hive.vectorized.groupby.checkinterval=4096
Warning: Ignoring non-spark config property: hive.compute.query.using.stats=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.split.maxsize=750000000
Warning: Ignoring non-spark config property: hive.merge.orcfile.stripe.level=true
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask.size=894435328
Warning: Ignoring non-spark config property: hive.fetch.task.conversion.threshold=1073741824
Warning: Ignoring non-spark config property: hive.auto.convert.join=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication=true
Warning: Ignoring non-spark config property: hive.vectorized.groupby.flush.percent=0.1
Warning: Ignoring non-spark config property: hive.fetch.task.conversion=more
Warning: Ignoring non-spark config property: hive.limit.pushdown.memory.usage=0.4
Warning: Ignoring non-spark config property: hive.vectorized.execution.reduce.enabled=false
Warning: Ignoring non-spark config property: hive.map.aggr=true
Warning: Ignoring non-spark config property: hive.stats.autogather=true
Warning: Ignoring non-spark config property: hive.stats.fetch.column.stats=true
Warning: Ignoring non-spark config property: hive.cbo.enable=true
Warning: Ignoring non-spark config property: hive.map.aggr.hash.percentmemory=0.5
Warning: Ignoring non-spark config property: hive.optimize.index.filter=true
Warning: Ignoring non-spark config property: hive.optimize.bucketmapjoin.sortedmerge=false
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/30 02:26:04 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 02:26:19 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 02:26:19 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 02:26:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/30 02:26:21 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 02:26:32 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://128.110.152.45:4040
Spark context available as 'sc' (master = spark://ctl:7077, app id = app-20170530022621-0713).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_121)
Type in expressions to have them evaluated.
Type :help for more information.

scala> import java.io.File
import java.io.File

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> import org.apache.spark.sql._
import org.apache.spark.sql._

scala> 

scala> val queryMsg = "#QUERY "
queryMsg: String = "#QUERY "

scala> val loadDBMsg = "#LOAD_DB "
loadDBMsg: String = "#LOAD_DB "

scala> val loadTable = "#LOAD_TABLE "
loadTable: String = "#LOAD_TABLE "

scala> val loadsqlHive = "#LOAD_SQL_CONTEXT "
loadsqlHive: String = "#LOAD_SQL_CONTEXT "

scala> 

scala> def show_timing[T](proc: => T): T = {
     |     val start=System.nanoTime()
     |     val res = proc
     |     val end = System.nanoTime()
     |     println("Time elapsed: " + (end-start)/1000000000.0 + " seconds")
     |     res
     | }
show_timing: [T](proc: => T)T

scala> 

scala> val writeToLocal = (in:(Array[Byte], Long, String)) =>{
     |     val bytes = in._1
     |     val output = in._3
     |     
     |     val writer = new FileOutputStream(output)
     |     writer.write(bytes)
     |     writer.close
     |     1
     |   }
writeToLocal: ((Array[Byte], Long, String)) => Int = <function1>

scala>   
     | val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@55c78556

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide4"
dataSource: String = /nidan/orc/individualORC/slide4

scala> 

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 4.3811838 seconds

scala> val queries = List(("SELECT imageBytes FROM data WHERE partitionZIndex>=100 AND partitionZIndex<=107", 8))
queries: List[(String, Int)] = List((SELECT imageBytes FROM data WHERE partitionZIndex>=100 AND partitionZIndex<=107,8))

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 0:>                                                      (0 + 112) / 115][Stage 0:===============>                                       (33 + 82) / 115][Stage 0:===========================>                           (57 + 58) / 115][Stage 0:==============================>                        (63 + 52) / 115][Stage 0:===============================>                       (66 + 49) / 115][Stage 0:================================>                      (68 + 47) / 115][Stage 0:=================================>                     (70 + 45) / 115][Stage 0:====================================>                  (76 + 39) / 115][Stage 0:====================================>                  (77 + 38) / 115][Stage 0:=======================================>               (83 + 32) / 115][Stage 0:==============================================>        (97 + 18) / 115][Stage 0:===============================================>       (99 + 16) / 115][Stage 0:=================================================>    (105 + 10) / 115][Stage 0:=====================================================> (111 + 4) / 115]                                                                                [Stage 1:=========================>                             (54 + 62) / 116][Stage 1:===========================>                           (59 + 57) / 116][Stage 1:================================>                      (68 + 48) / 116][Stage 1:==================================>                    (72 + 44) / 116][Stage 1:====================================>                  (78 + 38) / 116][Stage 1:======================================>                (81 + 35) / 116][Stage 1:==========================================>            (90 + 26) / 116][Stage 1:=============================================>         (96 + 20) / 116][Stage 1:==============================================>        (98 + 18) / 116][Stage 1:===============================================>      (102 + 14) / 116][Stage 1:==================================================>    (107 + 9) / 116][Stage 1:===================================================>   (109 + 7) / 116][Stage 1:=======================================================(116 + 0) / 116]                                                                                Time elapsed: 13.363706441 seconds
res2: Int = 0

scala> 

scala>  
     | val dataSource = "/nidan/orc/individualORC/slide32"
dataSource: String = /nidan/orc/individualORC/slide32

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 96  OR  partitionIndex = 97  OR  pa rtitionIndex = 112  OR  partitionIndex = 113 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 96  OR  partitionIndex = 97  OR  partitionIndex = 112  OR  partitionIndex = 113 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.688080357 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 2:===========================>                           (58 + 57) / 115][Stage 2:==============================>                        (64 + 51) / 115][Stage 2:===============================>                       (66 + 49) / 115][Stage 2:==================================>                    (72 + 43) / 115][Stage 2:=======================================>               (82 + 33) / 115][Stage 2:==========================================>            (88 + 27) / 115][Stage 2:============================================>          (94 + 21) / 115][Stage 2:=============================================>         (96 + 19) / 115][Stage 2:=================================================>    (105 + 10) / 115][Stage 2:====================================================>  (109 + 6) / 115][Stage 2:=====================================================> (111 + 4) / 115][Stage 2:=====================================================> (112 + 3) / 115][Stage 2:======================================================>(114 + 1) / 115]                                                                                [Stage 3:===========================>                           (58 + 58) / 116][Stage 3:==============================>                        (65 + 51) / 116][Stage 3:==================================>                    (72 + 44) / 116][Stage 3:====================================>                  (77 + 39) / 116][Stage 3:=========================================>             (87 + 29) / 116][Stage 3:==============================================>        (99 + 17) / 116][Stage 3:================================================>     (104 + 12) / 116][Stage 3:==================================================>    (107 + 9) / 116][Stage 3:====================================================>  (111 + 5) / 116][Stage 3:=====================================================> (113 + 3) / 116]                                                                                Time elapsed: 6.786063649 seconds
res5: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide3"
dataSource: String = /nidan/orc/individualORC/slide3

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 202  OR  partitionIndex = 203  OR   partitionIndex = 217  OR  partitionIndex = 218 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 202  OR  partitionIndex = 203  OR  partitionIndex = 217  OR  partitionIndex = 218 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.78535638 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 4:==================>                                    (40 + 81) / 121][Stage 4:=========================>                             (55 + 66) / 121][Stage 4:===========================>                           (60 + 61) / 121][Stage 4:==============================>                        (66 + 55) / 121][Stage 4:===================================>                   (78 + 43) / 121][Stage 4:=======================================>               (87 + 34) / 121][Stage 4:==============================================>       (104 + 17) / 121][Stage 4:====================================================>  (116 + 5) / 121]                                                                                [Stage 5:===========================>                           (60 + 62) / 122][Stage 5:============================>                          (63 + 59) / 122][Stage 5:===============================>                       (70 + 52) / 122][Stage 5:====================================>                  (81 + 41) / 122][Stage 5:============================================>         (100 + 22) / 122][Stage 5:==================================================>    (113 + 9) / 122][Stage 5:=====================================================> (119 + 3) / 122]                                                                                Time elapsed: 4.631671622 seconds
res7: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 234  OR  partitionIndex = 235  OR   partitionIndex = 250  OR  partitionIndex = 251 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 234  OR  partitionIndex = 235  OR  partitionIndex = 250  OR  partitionIndex = 251 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 6:>                                                        (0 + 0) / 121][Stage 6:===========================>                           (61 + 60) / 121][Stage 6:==============================>                        (66 + 55) / 121][Stage 6:==================================>                    (75 + 46) / 121][Stage 6:========================================>              (89 + 32) / 121][Stage 6:===============================================>      (106 + 15) / 121][Stage 6:======================================================>(119 + 2) / 121]                                                                                [Stage 7:===========================>                           (60 + 62) / 122][Stage 7:============================>                          (64 + 58) / 122][Stage 7:=================================>                     (75 + 47) / 122][Stage 7:=======================================>               (88 + 34) / 122][Stage 7:============================================>          (99 + 23) / 122][Stage 7:=================================================>    (112 + 10) / 122][Stage 7:======================================================>(121 + 1) / 122]                                                                                Time elapsed: 4.35647304 seconds
res9: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide14"
dataSource: String = /nidan/orc/individualORC/slide14

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 1  OR  partitionIndex = 2  OR  part itionIndex = 16  OR  partitionIndex = 17 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 1  OR  partitionIndex = 2  OR  partitionIndex = 16  OR  partitionIndex = 17 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.69156464 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 8:===========================>                           (60 + 62) / 122][Stage 8:===========================>                           (62 + 60) / 122][Stage 8:==============================>                        (67 + 55) / 122][Stage 8:========================================>              (90 + 32) / 122][Stage 8:================================================>     (110 + 12) / 122][Stage 8:====================================================>  (117 + 5) / 122][Stage 8:======================================================>(121 + 1) / 122]                                                                                [Stage 9:==========================>                            (60 + 63) / 123][Stage 9:===========================>                           (61 + 62) / 123][Stage 9:==============================>                        (69 + 54) / 123][Stage 9:======================================>                (86 + 37) / 123][Stage 9:===============================================>      (108 + 15) / 123][Stage 9:===================================================>   (116 + 7) / 123]                                                                                Time elapsed: 4.261247975 seconds
res11: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide10"
dataSource: String = /nidan/orc/individualORC/slide10

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR   partitionIndex = 209  OR  partitionIndex = 210 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR  partitionIndex = 209  OR  partitionIndex = 210 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.654803981 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 10:==========================>                           (59 + 62) / 121][Stage 10:===========================>                          (61 + 60) / 121][Stage 10:===============================>                      (71 + 50) / 121][Stage 10:=======================================>              (88 + 33) / 121][Stage 10:===============================================>     (109 + 12) / 121][Stage 10:====================================================> (117 + 4) / 121]                                                                                [Stage 11:===========================>                          (62 + 60) / 122][Stage 11:===============================>                      (72 + 50) / 122][Stage 11:====================================>                 (83 + 39) / 122][Stage 11:===========================================>         (100 + 22) / 122][Stage 11:===============================================>     (110 + 12) / 122][Stage 11:=====================================================>(120 + 2) / 122][Stage 11:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 3.947946863 seconds
res13: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide96"
dataSource: String = /nidan/orc/individualORC/slide96

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR   partitionIndex = 157  OR  partitionIndex = 158 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR  partitionIndex = 157  OR  partitionIndex = 158 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.563056932 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 12:================================>                     (70 + 47) / 117][Stage 12:==================================>                   (74 + 43) / 117][Stage 12:====================================>                 (79 + 38) / 117][Stage 12:=======================================>              (85 + 32) / 117][Stage 12:=============================================>        (98 + 19) / 117][Stage 12:================================================>    (107 + 10) / 117][Stage 12:====================================================> (113 + 4) / 117]                                                                                [Stage 13:=================================>                    (74 + 44) / 118][Stage 13:====================================>                 (79 + 39) / 118][Stage 13:======================================>               (85 + 33) / 118][Stage 13:===========================================>          (94 + 24) / 118][Stage 13:===============================================>     (106 + 12) / 118]                                                                                Time elapsed: 4.039011653 seconds
res15: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide12"
dataSource: String = /nidan/orc/individualORC/slide12

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  pa rtitionIndex = 28  OR  partitionIndex = 59 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  partitionIndex = 28  OR  partitionIndex = 59 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.491118082 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 14:================================>                     (71 + 46) / 117][Stage 14:====================================>                 (79 + 38) / 117][Stage 14:============================================>         (97 + 20) / 117][Stage 14:===================================================>  (112 + 5) / 117]                                                                                [Stage 15:================================>                     (72 + 46) / 118][Stage 15:===================================>                  (78 + 40) / 118][Stage 15:=======================================>              (87 + 31) / 118][Stage 15:================================================>    (108 + 10) / 118][Stage 15:=====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.440880813 seconds
res17: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide98"
dataSource: String = /nidan/orc/individualORC/slide98

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR   partitionIndex = 145  OR  partitionIndex = 146 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR  partitionIndex = 145  OR  partitionIndex = 146 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.585605548 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 16:===========================>                          (61 + 61) / 122][Stage 16:===============================>                      (72 + 50) / 122][Stage 16:======================================>               (86 + 36) / 122][Stage 16:============================================>        (102 + 20) / 122][Stage 16:==================================================>   (114 + 8) / 122][Stage 16:=====================================================>(121 + 1) / 122]                                                                                [Stage 17:===========================>                          (62 + 61) / 123][Stage 17:============================>                         (65 + 58) / 123][Stage 17:==================================>                   (78 + 45) / 123][Stage 17:===========================================>         (101 + 22) / 123][Stage 17:===============================================>     (111 + 12) / 123][Stage 17:===================================================>  (117 + 6) / 123][Stage 17:=====================================================>(121 + 2) / 123]                                                                                Time elapsed: 4.094675554 seconds
res19: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide54"
dataSource: String = /nidan/orc/individualORC/slide54

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR   partitionIndex = 213  OR  partitionIndex = 214 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR  partitionIndex = 213  OR  partitionIndex = 214 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.471458225 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 18:================================>                     (71 + 46) / 117][Stage 18:===================================>                  (77 + 40) / 117][Stage 18:=============================================>        (98 + 19) / 117][Stage 18:==================================================>   (109 + 8) / 117][Stage 18:=====================================================>(115 + 2) / 117]                                                                                [Stage 19:================================>                     (72 + 46) / 118][Stage 19:=================================>                    (74 + 44) / 118][Stage 19:======================================>               (85 + 33) / 118][Stage 19:================================================>    (107 + 11) / 118][Stage 19:====================================================> (114 + 4) / 118][Stage 19:====================================================> (115 + 3) / 118]                                                                                Time elapsed: 3.693710795 seconds
res21: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide21"
dataSource: String = /nidan/orc/individualORC/slide21

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  pa rtitionIndex = 28  OR  partitionIndex = 29 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  partitionIndex = 28  OR  partitionIndex = 29 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.591906548 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 20:==========================>                           (60 + 62) / 122][Stage 20:===========================>                          (63 + 59) / 122][Stage 20:==============================>                       (69 + 53) / 122][Stage 20:===========================================>         (100 + 22) / 122][Stage 20:==================================================>   (115 + 7) / 122][Stage 20:=====================================================>(121 + 1) / 122]                                                                                [Stage 21:===========================>                          (62 + 61) / 123][Stage 21:============================>                         (66 + 57) / 123][Stage 21:======================================>               (88 + 35) / 123][Stage 21:=============================================>       (105 + 18) / 123][Stage 21:====================================================> (119 + 4) / 123][Stage 21:=====================================================>(121 + 2) / 123]                                                                                Time elapsed: 3.72074696 seconds
res23: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide72"
dataSource: String = /nidan/orc/individualORC/slide72

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 103  OR  pa rtitionIndex = 118  OR  partitionIndex = 119 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 103  OR  partitionIndex = 118  OR  partitionIndex = 119 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.457643203 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 22:==================================>                   (73 + 41) / 114][Stage 22:=========================================>            (87 + 27) / 114][Stage 22:==============================================>       (99 + 15) / 114][Stage 22:===================================================>  (109 + 5) / 114][Stage 22:=====================================================>(113 + 1) / 114]                                                                                [Stage 23:===================================>                  (75 + 40) / 115][Stage 23:======================================>               (83 + 32) / 115][Stage 23:==============================================>      (101 + 14) / 115][Stage 23:===================================================>  (109 + 6) / 115][Stage 23:=====================================================>(113 + 2) / 115][Stage 23:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.365187532 seconds
res25: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide79"
dataSource: String = /nidan/orc/individualORC/slide79

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 214  OR  partitionIndex = 215  OR   partitionIndex = 228  OR  partitionIndex = 229 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 214  OR  partitionIndex = 215  OR  partitionIndex = 228  OR  partitionIndex = 229 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.461583547 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 24:=================================>                    (70 + 44) / 114][Stage 24:========================================>             (86 + 28) / 114][Stage 24:=============================================>        (95 + 19) / 114][Stage 24:================================================>    (104 + 10) / 114][Stage 24:===================================================>  (108 + 6) / 114][Stage 24:====================================================> (111 + 3) / 114][Stage 24:=====================================================>(112 + 2) / 114]                                                                                [Stage 25:=====================================>                (80 + 35) / 115][Stage 25:============================================>         (94 + 21) / 115][Stage 25:================================================>    (105 + 10) / 115][Stage 25:==================================================>   (108 + 7) / 115][Stage 25:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.564917932 seconds
res27: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide15"
dataSource: String = /nidan/orc/individualORC/slide15

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 100  OR  partitionIndex = 101  OR   partitionIndex = 116  OR  partitionIndex = 117 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 100  OR  partitionIndex = 101  OR  partitionIndex = 116  OR  partitionIndex = 117 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide15;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 26:======================================>               (82 + 32) / 114][Stage 26:===========================================>          (92 + 22) / 114][Stage 26:================================================>    (104 + 10) / 114][Stage 26:====================================================> (110 + 4) / 114]                                                                                [Stage 27:=====================================>                (79 + 36) / 115][Stage 27:=========================================>            (88 + 27) / 115][Stage 27:==============================================>      (100 + 15) / 115][Stage 27:===================================================>  (110 + 5) / 115][Stage 27:=====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.095805782 seconds
res29: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide76"
dataSource: String = /nidan/orc/individualORC/slide76

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 43  OR  pa rtitionIndex = 58  OR  partitionIndex = 59 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 43  OR  partitionIndex = 58  OR  partitionIndex = 59 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.424942308 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 28:=======================================>              (84 + 31) / 115][Stage 28:============================================>         (94 + 21) / 115][Stage 28:================================================>    (105 + 10) / 115][Stage 28:====================================================> (111 + 4) / 115]                                                                                [Stage 29:=====================================>                (81 + 35) / 116][Stage 29:========================================>             (87 + 29) / 116][Stage 29:==============================================>      (101 + 15) / 116][Stage 29:===================================================>  (110 + 6) / 116][Stage 29:=====================================================>(114 + 2) / 116][Stage 29:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.938666379 seconds
res31: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide20"
dataSource: String = /nidan/orc/individualORC/slide20

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR   partitionIndex = 158  OR  partitionIndex = 159 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR  partitionIndex = 158  OR  partitionIndex = 159 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.417237962 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 30:=====================================>                (80 + 35) / 115][Stage 30:=======================================>              (84 + 31) / 115][Stage 30:==============================================>       (99 + 16) / 115][Stage 30:================================================>    (105 + 10) / 115][Stage 30:=====================================================>(113 + 2) / 115]                                                                                [Stage 31:=====================================>                (80 + 36) / 116][Stage 31:=========================================>            (89 + 27) / 116][Stage 31:=============================================>        (98 + 18) / 116][Stage 31:==================================================>   (109 + 7) / 116][Stage 31:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.148363803 seconds
res33: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide20"
dataSource: String = /nidan/orc/individualORC/slide20

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  part itionIndex = 118  OR  partitionIndex = 119 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  partitionIndex = 118  OR  partitionIndex = 119 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.430905944 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 32:======================================>               (82 + 33) / 115][Stage 32:=========================================>            (88 + 27) / 115][Stage 32:===============================================>     (103 + 12) / 115][Stage 32:===================================================>  (110 + 5) / 115][Stage 32:=====================================================>(113 + 2) / 115][Stage 32:=====================================================>(114 + 1) / 115]                                                                                [Stage 33:=====================================>                (81 + 35) / 116][Stage 33:========================================>             (88 + 28) / 116][Stage 33:===============================================>     (104 + 12) / 116][Stage 33:====================================================> (112 + 4) / 116][Stage 33:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.498842307 seconds
res35: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide86"
dataSource: String = /nidan/orc/individualORC/slide86

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 234  OR  partitionIndex = 235  OR   partitionIndex = 249  OR  partitionIndex = 250 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 234  OR  partitionIndex = 235  OR  partitionIndex = 249  OR  partitionIndex = 250 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.443677321 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 34:=================================>                    (71 + 43) / 114][Stage 34:=====================================>                (80 + 34) / 114][Stage 34:==========================================>           (90 + 24) / 114][Stage 34:===============================================>     (102 + 12) / 114][Stage 34:===================================================>  (108 + 6) / 114][Stage 34:=====================================================>(112 + 2) / 114]                                                                                [Stage 35:==================================>                   (73 + 42) / 115][Stage 35:=====================================>                (80 + 35) / 115][Stage 35:============================================>         (95 + 20) / 115][Stage 35:===============================================>     (104 + 11) / 115][Stage 35:====================================================> (111 + 4) / 115][Stage 35:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.312404371 seconds
res37: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide94"
dataSource: String = /nidan/orc/individualORC/slide94

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 141  OR  partitionIndex = 142  OR   partitionIndex = 156  OR  partitionIndex = 157 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 141  OR  partitionIndex = 142  OR  partitionIndex = 156  OR  partitionIndex = 157 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.637797646 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 36:===========================>                          (61 + 60) / 121][Stage 36:==============================>                       (69 + 52) / 121][Stage 36:=======================================>              (89 + 32) / 121][Stage 36:===============================================>     (109 + 12) / 121][Stage 36:=================================================>    (112 + 9) / 121][Stage 36:=====================================================>(119 + 2) / 121]                                                                                [Stage 37:============================>                         (65 + 57) / 122][Stage 37:=====================================>                (85 + 37) / 122][Stage 37:===========================================>         (101 + 21) / 122][Stage 37:================================================>    (111 + 11) / 122][Stage 37:==================================================>   (115 + 7) / 122][Stage 37:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 4.055873795 seconds
res39: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide74"
dataSource: String = /nidan/orc/individualORC/slide74

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 137  OR  partitionIndex = 138  OR   partitionIndex = 152  OR  partitionIndex = 153 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 137  OR  partitionIndex = 138  OR  partitionIndex = 152  OR  partitionIndex = 153 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.451918971 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 38:================================>                     (70 + 45) / 115][Stage 38:======================================>               (81 + 34) / 115][Stage 38:=============================================>        (96 + 19) / 115][Stage 38:==================================================>   (108 + 7) / 115]                                                                                [Stage 39:=================================>                    (72 + 44) / 116][Stage 39:=========================================>            (90 + 26) / 116][Stage 39:===============================================>     (103 + 13) / 116][Stage 39:===================================================>  (111 + 5) / 116]                                                                                Time elapsed: 3.030348984 seconds
res41: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide57"
dataSource: String = /nidan/orc/individualORC/slide57

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 218  OR  partitionIndex = 219  OR   partitionIndex = 232  OR  partitionIndex = 233 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 218  OR  partitionIndex = 219  OR  partitionIndex = 232  OR  partitionIndex = 233 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide57;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 40:==============================>                       (66 + 49) / 115][Stage 40:====================================>                 (78 + 37) / 115][Stage 40:===========================================>          (93 + 22) / 115][Stage 40:===============================================>     (103 + 12) / 115][Stage 40:====================================================> (111 + 4) / 115][Stage 40:=====================================================>(114 + 1) / 115]                                                                                [Stage 41:=====================================>                (80 + 36) / 116][Stage 41:=============================================>        (97 + 19) / 116][Stage 41:===================================================>  (110 + 6) / 116][Stage 41:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.184421131 seconds
res43: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 207  OR  partitionIndex = 222  OR   partitionIndex = 223  OR  partitionIndex = 236 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 207  OR  partitionIndex = 222  OR  partitionIndex = 223  OR  partitionIndex = 236 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 42:==============================>                       (66 + 49) / 115][Stage 42:====================================>                 (78 + 37) / 115][Stage 42:===========================================>          (93 + 22) / 115][Stage 42:================================================>    (105 + 10) / 115][Stage 42:====================================================> (111 + 4) / 115][Stage 42:====================================================> (112 + 3) / 115]                                                                                [Stage 43:==================================>                   (75 + 41) / 116][Stage 43:========================================>             (88 + 28) / 116][Stage 43:=================================================>    (107 + 9) / 116]                                                                                Time elapsed: 3.243151947 seconds
res45: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide43"
dataSource: String = /nidan/orc/individualORC/slide43

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 205  OR  partitionIndex = 206  OR   partitionIndex = 220  OR  partitionIndex = 221 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 205  OR  partitionIndex = 206  OR  partitionIndex = 220  OR  partitionIndex = 221 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide43;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 44:================================>                     (69 + 46) / 115][Stage 44:======================================>               (82 + 33) / 115][Stage 44:==========================================>           (90 + 25) / 115][Stage 44:===============================================>     (102 + 13) / 115][Stage 44:====================================================> (111 + 4) / 115]                                                                                [Stage 45:===================================>                  (76 + 40) / 116][Stage 45:===========================================>          (93 + 23) / 116][Stage 45:===============================================>     (103 + 13) / 116][Stage 45:====================================================> (112 + 4) / 116][Stage 45:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.368925004 seconds
res47: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide49"
dataSource: String = /nidan/orc/individualORC/slide49

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 160  OR  partitionIndex = 161  OR   partitionIndex = 176  OR  partitionIndex = 177 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 160  OR  partitionIndex = 161  OR  partitionIndex = 176  OR  partitionIndex = 177 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.506405721 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 46:==========================>                           (60 + 62) / 122][Stage 46:===========================>                          (63 + 59) / 122][Stage 46:===============================>                      (72 + 50) / 122][Stage 46:==========================================>           (97 + 25) / 122][Stage 46:===================================================>  (116 + 6) / 122]                                                                                [Stage 47:==========================>                           (61 + 62) / 123][Stage 47:================================>                     (75 + 48) / 123][Stage 47:=======================================>              (90 + 33) / 123][Stage 47:=============================================>       (106 + 17) / 123][Stage 47:==================================================>   (116 + 7) / 123][Stage 47:=====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.552049346 seconds
res49: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 75  OR  partitionIndex = 90  OR  pa rtitionIndex = 91  OR  partitionIndex = 104 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 75  OR  partitionIndex = 90  OR  partitionIndex = 91  OR  partitionIndex = 104 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 48:==========================>                           (60 + 62) / 122][Stage 48:===========================>                          (61 + 61) / 122][Stage 48:===============================>                      (72 + 50) / 122][Stage 48:=========================================>            (94 + 28) / 122][Stage 48:==============================================>      (108 + 14) / 122][Stage 48:====================================================> (119 + 3) / 122]                                                                                [Stage 49:===========================>                          (62 + 61) / 123][Stage 49:============================>                         (66 + 57) / 123][Stage 49:====================================>                 (83 + 40) / 123][Stage 49:==================================================>   (114 + 9) / 123][Stage 49:=====================================================>(121 + 2) / 123]                                                                                Time elapsed: 3.514723345 seconds
res51: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide53"
dataSource: String = /nidan/orc/individualORC/slide53

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 47  OR  partitionIndex = 62  OR  pa rtitionIndex = 63  OR  partitionIndex = 72 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 47  OR  partitionIndex = 62  OR  partitionIndex = 63  OR  partitionIndex = 72 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.44956456 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 50:===============================>                      (68 + 47) / 115][Stage 50:=====================================>                (79 + 36) / 115][Stage 50:============================================>         (95 + 20) / 115][Stage 50:=================================================>    (106 + 9) / 115][Stage 50:=====================================================>(113 + 2) / 115][Stage 50:=====================================================>(114 + 1) / 115]                                                                                [Stage 51:===============================>                      (68 + 48) / 116][Stage 51:=====================================>                (81 + 35) / 116][Stage 51:===========================================>          (93 + 23) / 116][Stage 51:===============================================>     (104 + 12) / 116][Stage 51:================================================>    (106 + 10) / 116][Stage 51:===================================================>  (111 + 5) / 116][Stage 51:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.548139475 seconds
res53: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide29"
dataSource: String = /nidan/orc/individualORC/slide29

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 71  OR  partitionIndex = 86  OR  pa rtitionIndex = 87  OR  partitionIndex = 100 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 71  OR  partitionIndex = 86  OR  partitionIndex = 87  OR  partitionIndex = 100 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide29;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 52:===============================>                      (67 + 48) / 115][Stage 52:========================================>             (87 + 28) / 115][Stage 52:==============================================>      (101 + 14) / 115][Stage 52:==================================================>   (108 + 7) / 115][Stage 52:=====================================================>(113 + 2) / 115]                                                                                [Stage 53:=================================>                    (73 + 43) / 116][Stage 53:=====================================>                (80 + 36) / 116][Stage 53:==============================================>      (101 + 15) / 116][Stage 53:====================================================> (112 + 4) / 116]                                                                                Time elapsed: 3.036381918 seconds
res55: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide22"
dataSource: String = /nidan/orc/individualORC/slide22

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 172  OR  partitionIndex = 173  OR   partitionIndex = 188  OR  partitionIndex = 189 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 172  OR  partitionIndex = 173  OR  partitionIndex = 188  OR  partitionIndex = 189 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide22;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 54:==============================>                       (66 + 49) / 115][Stage 54:===================================>                  (76 + 39) / 115][Stage 54:=========================================>            (88 + 27) / 115][Stage 54:==============================================>      (100 + 15) / 115][Stage 54:====================================================> (112 + 3) / 115]                                                                                [Stage 55:==================================>                   (74 + 42) / 116][Stage 55:=========================================>            (90 + 26) / 116][Stage 55:==============================================>      (102 + 14) / 116][Stage 55:====================================================> (112 + 4) / 116]                                                                                Time elapsed: 3.072407056 seconds
res57: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide15"
dataSource: String = /nidan/orc/individualORC/slide15

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 46  OR  partitionIndex = 47  OR  pa rtitionIndex = 61  OR  partitionIndex = 62 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 46  OR  partitionIndex = 47  OR  partitionIndex = 61  OR  partitionIndex = 62 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide15;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 56:==============================>                       (66 + 49) / 115][Stage 56:===================================>                  (75 + 40) / 115][Stage 56:============================================>         (94 + 21) / 115][Stage 56:=================================================>    (106 + 9) / 115][Stage 56:===================================================>  (109 + 6) / 115]                                                                                [Stage 57:=================================>                    (72 + 44) / 116][Stage 57:=======================================>              (84 + 32) / 116][Stage 57:==============================================>      (101 + 15) / 116][Stage 57:====================================================> (112 + 4) / 116][Stage 57:====================================================> (113 + 3) / 116][Stage 57:=====================================================>(114 + 2) / 116][Stage 57:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 5.349270498 seconds
res59: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide88"
dataSource: String = /nidan/orc/individualORC/slide88

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR   partitionIndex = 126  OR  partitionIndex = 127 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR  partitionIndex = 126  OR  partitionIndex = 127 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.479710462 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 58:===============================>                      (67 + 48) / 115][Stage 58:======================================>               (82 + 33) / 115][Stage 58:=============================================>        (96 + 19) / 115][Stage 58:====================================================> (111 + 4) / 115]                                                                                [Stage 59:===================================>                  (76 + 40) / 116][Stage 59:=======================================>              (85 + 31) / 116][Stage 59:==================================================>   (109 + 7) / 116][Stage 59:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.833569427 seconds
res61: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide74"
dataSource: String = /nidan/orc/individualORC/slide74

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 167  OR  partitionIndex = 182  OR   partitionIndex = 183  OR  partitionIndex = 192 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 167  OR  partitionIndex = 182  OR  partitionIndex = 183  OR  partitionIndex = 192 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.45269374 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 60:==================================>                   (73 + 42) / 115][Stage 60:=======================================>              (84 + 31) / 115][Stage 60:===============================================>     (102 + 13) / 115][Stage 60:==================================================>   (108 + 7) / 115][Stage 60:=====================================================>(114 + 1) / 115]                                                                                [Stage 61:=====================================>                (81 + 35) / 116][Stage 61:=============================================>        (97 + 19) / 116][Stage 61:==================================================>   (108 + 8) / 116][Stage 61:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.05354603 seconds
res63: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide12"
dataSource: String = /nidan/orc/individualORC/slide12

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 204  OR  partitionIndex = 235  OR   partitionIndex = 250  OR  partitionIndex = 251 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 204  OR  partitionIndex = 235  OR  partitionIndex = 250  OR  partitionIndex = 251 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.429230379 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 62:================================>                     (71 + 46) / 117][Stage 62:=================================>                    (73 + 44) / 117][Stage 62:=======================================>              (86 + 31) / 117][Stage 62:==============================================>      (102 + 15) / 117][Stage 62:=====================================================>(116 + 1) / 117]                                                                                [Stage 63:=================================>                    (74 + 44) / 118][Stage 63:=======================================>              (87 + 31) / 118][Stage 63:=================================================>    (109 + 9) / 118]                                                                                Time elapsed: 3.121137859 seconds
res65: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide78"
dataSource: String = /nidan/orc/individualORC/slide78

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 9  OR  partitionIndex = 10  OR  par titionIndex = 24  OR  partitionIndex = 25 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 9  OR  partitionIndex = 10  OR  partitionIndex = 24  OR  partitionIndex = 25 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide78;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 64:================================>                     (71 + 46) / 117][Stage 64:=================================>                    (72 + 45) / 117][Stage 64:==========================================>           (92 + 25) / 117][Stage 64:===================================================>  (111 + 6) / 117][Stage 64:=====================================================>(115 + 2) / 117][Stage 64:=====================================================>(116 + 1) / 117]                                                                                [Stage 65:================================>                     (72 + 46) / 118][Stage 65:==================================>                   (75 + 43) / 118][Stage 65:=========================================>            (91 + 27) / 118][Stage 65:====================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.27385878 seconds
res67: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide17"
dataSource: String = /nidan/orc/individualORC/slide17

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  pa rtitionIndex = 58  OR  partitionIndex = 59 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  partitionIndex = 58  OR  partitionIndex = 59 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.457860172 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 66:===========================>                          (62 + 59) / 121][Stage 66:=================================>                    (74 + 47) / 121][Stage 66:============================================>        (101 + 20) / 121][Stage 66:====================================================> (117 + 4) / 121]                                                                                [Stage 67:=============================>                        (66 + 56) / 122][Stage 67:===================================>                  (81 + 41) / 122][Stage 67:===========================================>         (101 + 21) / 122][Stage 67:==================================================>   (114 + 8) / 122][Stage 67:====================================================> (118 + 4) / 122]                                                                                Time elapsed: 3.505809257 seconds
res69: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide92"
dataSource: String = /nidan/orc/individualORC/slide92

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 98  OR  partitionIndex = 99  OR  pa rtitionIndex = 112  OR  partitionIndex = 113 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 98  OR  partitionIndex = 99  OR  partitionIndex = 112  OR  partitionIndex = 113 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.46235068 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 68:============================>                         (59 + 54) / 113][Stage 68:===============================>                      (65 + 48) / 113][Stage 68:========================================>             (84 + 29) / 113][Stage 68:==================================================>   (105 + 8) / 113][Stage 68:=====================================================>(112 + 1) / 113]                                                                                [Stage 69:=============================>                        (63 + 51) / 114][Stage 69:=================================>                    (71 + 43) / 114][Stage 69:=============================================>        (96 + 18) / 114][Stage 69:================================================>    (104 + 10) / 114]                                                                                Time elapsed: 3.412260416 seconds
res71: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide36"
dataSource: String = /nidan/orc/individualORC/slide36

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR   partitionIndex = 214  OR  partitionIndex = 215 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR  partitionIndex = 214  OR  partitionIndex = 215 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide36;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 70:============================>                         (59 + 54) / 113][Stage 70:==============================>                       (63 + 50) / 113][Stage 70:======================================>               (81 + 32) / 113][Stage 70:===============================================>     (101 + 12) / 113][Stage 70:=====================================================>(111 + 2) / 113]                                                                                [Stage 71:============================>                         (60 + 54) / 114][Stage 71:=============================>                        (62 + 52) / 114][Stage 71:======================================>               (82 + 32) / 114][Stage 71:==============================================>      (100 + 14) / 114][Stage 71:=====================================================>(113 + 1) / 114]                                                                                Time elapsed: 3.14141025 seconds
res73: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide19"
dataSource: String = /nidan/orc/individualORC/slide19

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 23  OR  partitionIndex = 36  OR  pa rtitionIndex = 37  OR  partitionIndex = 52 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 23  OR  partitionIndex = 36  OR  partitionIndex = 37  OR  partitionIndex = 52 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.450107247 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 72:=================================>                    (72 + 45) / 117][Stage 72:===================================>                  (77 + 40) / 117][Stage 72:===========================================>          (94 + 23) / 117][Stage 72:===============================================>     (104 + 13) / 117][Stage 72:===================================================>  (111 + 6) / 117]                                                                                [Stage 73:=================================>                    (73 + 45) / 118][Stage 73:=======================================>              (86 + 32) / 118][Stage 73:=============================================>       (102 + 16) / 118][Stage 73:====================================================> (115 + 3) / 118]                                                                                Time elapsed: 3.356512906 seconds
res75: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide49"
dataSource: String = /nidan/orc/individualORC/slide49

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 233  OR  partitionIndex = 234  OR   partitionIndex = 248  OR  partitionIndex = 249 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 233  OR  partitionIndex = 234  OR  partitionIndex = 248  OR  partitionIndex = 249 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.471864118 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 74:==========================>                           (60 + 62) / 122][Stage 74:===========================>                          (63 + 59) / 122][Stage 74:==================================>                   (79 + 43) / 122][Stage 74:==============================================>      (106 + 16) / 122][Stage 74:====================================================> (118 + 4) / 122]                                                                                [Stage 75:============================>                         (64 + 59) / 123][Stage 75:===================================>                  (80 + 43) / 123][Stage 75:===========================================>         (100 + 23) / 123][Stage 75:==================================================>   (115 + 8) / 123]                                                                                Time elapsed: 3.234697076 seconds
res77: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide98"
dataSource: String = /nidan/orc/individualORC/slide98

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 101  OR  partitionIndex = 102  OR   partitionIndex = 116  OR  partitionIndex = 117 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 101  OR  partitionIndex = 102  OR  partitionIndex = 116  OR  partitionIndex = 117 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.451265894 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 76:===========================>                          (62 + 60) / 122][Stage 76:================================>                     (74 + 48) / 122][Stage 76:==========================================>           (97 + 25) / 122][Stage 76:====================================================> (118 + 4) / 122]                                                                                [Stage 77:==========================>                           (61 + 62) / 123][Stage 77:===============================>                      (72 + 51) / 123][Stage 77:======================================>               (87 + 36) / 123][Stage 77:=============================================>       (105 + 18) / 123][Stage 77:===================================================>  (118 + 5) / 123]                                                                                Time elapsed: 3.503477615 seconds
res79: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide72"
dataSource: String = /nidan/orc/individualORC/slide72

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR   partitionIndex = 150  OR  partitionIndex = 151 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR  partitionIndex = 150  OR  partitionIndex = 151 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.39061689 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 78:===================================>                  (75 + 39) / 114][Stage 78:==========================================>           (89 + 25) / 114][Stage 78:==============================================>      (100 + 14) / 114][Stage 78:=====================================================>(112 + 2) / 114]                                                                                [Stage 79:========================================>             (87 + 28) / 115][Stage 79:===========================================>          (92 + 23) / 115][Stage 79:===============================================>     (104 + 11) / 115][Stage 79:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 2.813393126 seconds
res81: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide87"
dataSource: String = /nidan/orc/individualORC/slide87

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 143  OR  partitionIndex = 158  OR   partitionIndex = 159  OR  partitionIndex = 172 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 143  OR  partitionIndex = 158  OR  partitionIndex = 159  OR  partitionIndex = 172 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.478978602 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 80:===========================>                          (61 + 60) / 121][Stage 80:============================>                         (63 + 58) / 121][Stage 80:==================================>                   (77 + 44) / 121][Stage 80:=============================================>       (104 + 17) / 121][Stage 80:===================================================>  (116 + 5) / 121]                                                                                [Stage 81:===========================>                          (62 + 60) / 122][Stage 81:==============================>                       (69 + 53) / 122][Stage 81:====================================>                 (83 + 39) / 122][Stage 81:=============================================>       (104 + 18) / 122]                                                                                Time elapsed: 3.344860146 seconds
res83: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide80"
dataSource: String = /nidan/orc/individualORC/slide80

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 199  OR  partitionIndex = 214  OR   partitionIndex = 215  OR  partitionIndex = 228 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 199  OR  partitionIndex = 214  OR  partitionIndex = 215  OR  partitionIndex = 228 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.439916187 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 82:============================>                         (63 + 58) / 121][Stage 82:===============================>                      (71 + 50) / 121][Stage 82:==========================================>           (95 + 26) / 121][Stage 82:==================================================>   (113 + 8) / 121][Stage 82:=====================================================>(119 + 2) / 121]                                                                                [Stage 83:===========================>                          (62 + 60) / 122][Stage 83:============================>                         (64 + 58) / 122][Stage 83:==================================>                   (79 + 43) / 122][Stage 83:==============================================>      (107 + 15) / 122][Stage 83:====================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.318418929 seconds
res85: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide77"
dataSource: String = /nidan/orc/individualORC/slide77

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 140  OR  partitionIndex = 171  OR   partitionIndex = 186  OR  partitionIndex = 187 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 140  OR  partitionIndex = 171  OR  partitionIndex = 186  OR  partitionIndex = 187 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.485920084 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 84:==========================>                           (60 + 62) / 122][Stage 84:============================>                         (65 + 57) / 122][Stage 84:=====================================>                (85 + 37) / 122][Stage 84:=============================================>       (105 + 17) / 122][Stage 84:==================================================>   (115 + 7) / 122]                                                                                [Stage 85:===========================>                          (63 + 60) / 123][Stage 85:===============================>                      (71 + 52) / 123][Stage 85:=========================================>            (94 + 29) / 123][Stage 85:==================================================>   (114 + 9) / 123][Stage 85:=====================================================>(121 + 2) / 123][Stage 85:=====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.768128798 seconds
res87: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide34"
dataSource: String = /nidan/orc/individualORC/slide34

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 74  OR  partitionIndex = 75  OR  pa rtitionIndex = 88  OR  partitionIndex = 89 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 74  OR  partitionIndex = 75  OR  partitionIndex = 88  OR  partitionIndex = 89 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.36389395 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 86:=======================================>              (85 + 30) / 115][Stage 86:===========================================>          (92 + 23) / 115][Stage 86:================================================>    (105 + 10) / 115][Stage 86:=====================================================>(113 + 2) / 115][Stage 86:=====================================================>(114 + 1) / 115]                                                                                [Stage 87:=======================================>              (85 + 31) / 116][Stage 87:==========================================>           (91 + 25) / 116][Stage 87:=================================================>    (107 + 9) / 116][Stage 87:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 2.920916621 seconds
res89: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide25"
dataSource: String = /nidan/orc/individualORC/slide25

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 44  OR  partitionIndex = 45  OR  pa rtitionIndex = 60  OR  partitionIndex = 61 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 44  OR  partitionIndex = 45  OR  partitionIndex = 60  OR  partitionIndex = 61 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.425568761 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 88:=================================>                    (72 + 43) / 115][Stage 88:=======================================>              (85 + 30) / 115][Stage 88:==============================================>       (99 + 16) / 115][Stage 88:====================================================> (112 + 3) / 115][Stage 88:=====================================================>(114 + 1) / 115]                                                                                [Stage 89:================================>                     (69 + 47) / 116][Stage 89:=========================================>            (90 + 26) / 116][Stage 89:===============================================>     (103 + 13) / 116][Stage 89:===================================================>  (111 + 5) / 116][Stage 89:====================================================> (113 + 3) / 116][Stage 89:=====================================================>(114 + 2) / 116][Stage 89:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 5.104259087 seconds
res91: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide35"
dataSource: String = /nidan/orc/individualORC/slide35

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR   partitionIndex = 188  OR  partitionIndex = 189 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR  partitionIndex = 188  OR  partitionIndex = 189 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.453124508 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 90:===========================>                          (61 + 61) / 122][Stage 90:=============================>                        (66 + 56) / 122][Stage 90:===================================>                  (81 + 41) / 122][Stage 90:===========================================>         (101 + 21) / 122][Stage 90:==================================================>   (114 + 8) / 122]                                                                                [Stage 91:==========================>                           (61 + 62) / 123][Stage 91:============================>                         (66 + 57) / 123][Stage 91:==================================>                   (79 + 44) / 123][Stage 91:==================================================>   (114 + 9) / 123][Stage 91:====================================================> (120 + 3) / 123]                                                                                Time elapsed: 3.470517895 seconds
res93: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide18"
dataSource: String = /nidan/orc/individualORC/slide18

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 204  OR  partitionIndex = 205  OR   partitionIndex = 220  OR  partitionIndex = 251 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 204  OR  partitionIndex = 205  OR  partitionIndex = 220  OR  partitionIndex = 251 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.402607924 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 92:===============================>                      (68 + 47) / 115][Stage 92:====================================>                 (78 + 37) / 115][Stage 92:============================================>         (94 + 21) / 115][Stage 92:===============================================>     (104 + 11) / 115][Stage 92:=====================================================>(113 + 2) / 115]                                                                                [Stage 93:===============================>                      (67 + 49) / 116][Stage 93:====================================>                 (79 + 37) / 116][Stage 93:==========================================>           (91 + 25) / 116][Stage 93:==============================================>      (101 + 15) / 116][Stage 93:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.029879725 seconds
res95: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide87"
dataSource: String = /nidan/orc/individualORC/slide87

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR   partitionIndex = 121  OR  partitionIndex = 122 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR  partitionIndex = 121  OR  partitionIndex = 122 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.437615235 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 94:===========================>                          (61 + 60) / 121][Stage 94:==============================>                       (69 + 52) / 121][Stage 94:======================================>               (86 + 35) / 121][Stage 94:==============================================>      (106 + 15) / 121][Stage 94:=====================================================>(120 + 1) / 121]                                                                                [Stage 95:===========================>                          (62 + 60) / 122][Stage 95:==============================>                       (69 + 53) / 122][Stage 95:===================================>                  (81 + 41) / 122][Stage 95:============================================>        (102 + 20) / 122][Stage 95:====================================================> (119 + 3) / 122][Stage 95:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 3.488829571 seconds
res97: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide36"
dataSource: String = /nidan/orc/individualORC/slide36

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR   partitionIndex = 149  OR  partitionIndex = 150 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR  partitionIndex = 149  OR  partitionIndex = 150 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide36;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 96:=============================>                        (65 + 56) / 121][Stage 96:================================>                     (72 + 49) / 121][Stage 96:=========================================>            (94 + 27) / 121][Stage 96:==================================================>   (113 + 8) / 121]                                                                                [Stage 97:============================>                         (65 + 57) / 122][Stage 97:==================================>                   (77 + 45) / 122][Stage 97:==========================================>           (97 + 25) / 122][Stage 97:====================================================> (118 + 4) / 122]                                                                                Time elapsed: 3.291790386 seconds
res99: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide38"
dataSource: String = /nidan/orc/individualORC/slide38

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 76  OR  partitionIndex = 77  OR  pa rtitionIndex = 122  OR  partitionIndex = 123 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 76  OR  partitionIndex = 77  OR  partitionIndex = 122  OR  partitionIndex = 123 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.429400327 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 98:===========================>                          (61 + 60) / 121][Stage 98:================================>                     (72 + 49) / 121][Stage 98:=========================================>            (94 + 27) / 121][Stage 98:====================================================> (117 + 4) / 121]                                                                                [Stage 99:===========================>                          (62 + 60) / 122][Stage 99:=================================>                    (76 + 46) / 122][Stage 99:===========================================>         (101 + 21) / 122][Stage 99:=====================================================>(120 + 2) / 122]                                                                                Time elapsed: 3.112798931 seconds
res101: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide7"
dataSource: String = /nidan/orc/individualORC/slide7

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 82  OR  partitionIndex = 83  OR  pa rtitionIndex = 96  OR  partitionIndex = 97 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 82  OR  partitionIndex = 83  OR  partitionIndex = 96  OR  partitionIndex = 97 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.434764719 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 100:==========================>                          (61 + 61) / 122][Stage 100:============================>                        (66 + 56) / 122][Stage 100:==================================>                  (80 + 42) / 122][Stage 100:==========================================>          (98 + 24) / 122][Stage 100:====================================================>(121 + 1) / 122]                                                                                [Stage 101:==========================>                          (62 + 61) / 123][Stage 101:===========================>                         (63 + 60) / 123][Stage 101:=================================>                   (78 + 45) / 123][Stage 101:=============================================>      (108 + 15) / 123][Stage 101:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.144710425 seconds
res103: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide76"
dataSource: String = /nidan/orc/individualORC/slide76

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 215  OR  partitionIndex = 228  OR   partitionIndex = 229  OR  partitionIndex = 244 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 215  OR  partitionIndex = 228  OR  partitionIndex = 229  OR  partitionIndex = 244 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.357598715 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 102:====================================>                (79 + 36) / 115][Stage 102:=====================================>               (81 + 34) / 115][Stage 102:=========================================>           (91 + 24) / 115][Stage 102:===============================================>    (105 + 10) / 115][Stage 102:====================================================>(113 + 2) / 115]                                                                                [Stage 103:======================================>              (85 + 31) / 116][Stage 103:===========================================>         (96 + 20) / 116][Stage 103:===============================================>    (106 + 10) / 116][Stage 103:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.793001008 seconds
res105: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide4"
dataSource: String = /nidan/orc/individualORC/slide4

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 15  OR  partitionIndex = 30  OR  pa rtitionIndex = 31  OR  partitionIndex = 44 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 15  OR  partitionIndex = 30  OR  partitionIndex = 31  OR  partitionIndex = 44 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.414038175 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 104:===============================>                     (68 + 47) / 115][Stage 104:===================================>                 (78 + 37) / 115][Stage 104:==========================================>          (93 + 22) / 115][Stage 104:===============================================>    (104 + 11) / 115][Stage 104:===================================================> (111 + 4) / 115]                                                                                [Stage 105:=================================>                   (73 + 43) / 116][Stage 105:======================================>              (84 + 32) / 116][Stage 105:===========================================>         (96 + 20) / 116][Stage 105:==============================================>     (104 + 12) / 116][Stage 105:==================================================>  (110 + 6) / 116][Stage 105:==================================================>  (111 + 5) / 116]                                                                                Time elapsed: 5.831880343 seconds
res107: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide9"
dataSource: String = /nidan/orc/individualORC/slide9

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR   partitionIndex = 153  OR  partitionIndex = 154 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR  partitionIndex = 153  OR  partitionIndex = 154 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.376524669 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 106:=================================>                   (72 + 42) / 114][Stage 106:=======================================>             (84 + 30) / 114][Stage 106:============================================>        (95 + 19) / 114][Stage 106:=================================================>   (106 + 8) / 114][Stage 106:===================================================> (110 + 4) / 114]                                                                                [Stage 107:=======================================>             (86 + 29) / 115][Stage 107:============================================>        (97 + 18) / 115][Stage 107:===============================================>    (104 + 11) / 115][Stage 107:===================================================> (111 + 4) / 115][Stage 107:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.201178173 seconds
res109: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide54"
dataSource: String = /nidan/orc/individualORC/slide54

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 236  OR  partitionIndex = 237  OR   partitionIndex = 252  OR  partitionIndex = 253 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 236  OR  partitionIndex = 237  OR  partitionIndex = 252  OR  partitionIndex = 253 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.381368359 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 108:================================>                    (71 + 46) / 117][Stage 108:==================================>                  (76 + 41) / 117][Stage 108:============================================>        (99 + 18) / 117][Stage 108:====================================================>(115 + 2) / 117]                                                                                [Stage 109:================================>                    (73 + 45) / 118][Stage 109:=======================================>             (87 + 31) / 118][Stage 109:==============================================>     (105 + 13) / 118][Stage 109:====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.210713773 seconds
res111: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide1"
dataSource: String = /nidan/orc/individualORC/slide1

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  pa rtitionIndex = 30  OR  partitionIndex = 31 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  partitionIndex = 30  OR  partitionIndex = 31 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.397898398 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 110:===========================>                         (59 + 54) / 113][Stage 110:============================>                        (61 + 52) / 113][Stage 110:=================================>                   (71 + 42) / 113][Stage 110:=========================================>           (89 + 24) / 113][Stage 110:=================================================>   (106 + 7) / 113]                                                                                [Stage 111:===========================>                         (60 + 54) / 114][Stage 111:===============================>                     (68 + 46) / 114][Stage 111:=======================================>             (86 + 28) / 114][Stage 111:================================================>    (105 + 9) / 114][Stage 111:====================================================>(113 + 1) / 114]                                                                                Time elapsed: 3.553935484 seconds
res113: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide56"
dataSource: String = /nidan/orc/individualORC/slide56

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 36  OR  partitionIndex = 37  OR  pa rtitionIndex = 52  OR  partitionIndex = 53 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 36  OR  partitionIndex = 37  OR  partitionIndex = 52  OR  partitionIndex = 53 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.428122621 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 112:==========================>                          (61 + 61) / 122][Stage 112:=============================>                       (67 + 55) / 122][Stage 112:===================================>                 (82 + 40) / 122][Stage 112:==========================================>         (100 + 22) / 122][Stage 112:====================================================>(121 + 1) / 122]                                                                                [Stage 113:==========================>                          (61 + 62) / 123][Stage 113:=============================>                       (68 + 55) / 123][Stage 113:=================================>                   (78 + 45) / 123][Stage 113:===========================================>        (103 + 20) / 123][Stage 113:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.162865749 seconds
res115: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide1"
dataSource: String = /nidan/orc/individualORC/slide1

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR   partitionIndex = 154  OR  partitionIndex = 155 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR  partitionIndex = 154  OR  partitionIndex = 155 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.516042472 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 114:===========================>                         (59 + 54) / 113][Stage 114:===============================>                     (67 + 46) / 113][Stage 114:========================================>            (86 + 27) / 113][Stage 114:===================================================> (109 + 4) / 113]                                                                                [Stage 115:============================>                        (62 + 52) / 114][Stage 115:=================================>                   (73 + 41) / 114][Stage 115:============================================>        (96 + 18) / 114][Stage 115:===================================================> (111 + 3) / 114]                                                                                Time elapsed: 3.138637945 seconds
res117: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide31"
dataSource: String = /nidan/orc/individualORC/slide31

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 161  OR  partitionIndex = 162  OR   partitionIndex = 176  OR  partitionIndex = 177 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 161  OR  partitionIndex = 162  OR  partitionIndex = 176  OR  partitionIndex = 177 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.426300671 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 116:==========================>                          (60 + 61) / 121][Stage 116:===========================>                         (62 + 59) / 121][Stage 116:===================================>                 (80 + 41) / 121][Stage 116:==========================================>          (98 + 23) / 121][Stage 116:=================================================>   (114 + 7) / 121]                                                                                [Stage 117:===========================>                         (63 + 59) / 122][Stage 117:=============================>                       (69 + 53) / 122][Stage 117:====================================>                (84 + 38) / 122][Stage 117:============================================>       (104 + 18) / 122]                                                                                Time elapsed: 3.232132011 seconds
res119: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide44"
dataSource: String = /nidan/orc/individualORC/slide44

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 34  OR  partitionIndex = 35  OR  pa rtitionIndex = 49  OR  partitionIndex = 50 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 34  OR  partitionIndex = 35  OR  partitionIndex = 49  OR  partitionIndex = 50 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.365983367 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 118:==================================>                  (75 + 39) / 114][Stage 118:=========================================>           (90 + 24) / 114][Stage 118:==============================================>     (101 + 13) / 114][Stage 118:=================================================>   (106 + 8) / 114][Stage 118:====================================================>(112 + 2) / 114]                                                                                [Stage 119:==================================>                  (74 + 41) / 115][Stage 119:========================================>            (88 + 27) / 115][Stage 119:============================================>        (97 + 18) / 115][Stage 119:=================================================>   (107 + 8) / 115][Stage 119:==================================================>  (110 + 5) / 115][Stage 119:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 5.728349149 seconds
res121: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide7"
dataSource: String = /nidan/orc/individualORC/slide7

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 38  OR  partitionIndex = 39  OR  pa rtitionIndex = 53  OR  partitionIndex = 54 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 38  OR  partitionIndex = 39  OR  partitionIndex = 53  OR  partitionIndex = 54 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.420706178 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 120:==========================>                          (62 + 60) / 122][Stage 120:=============================>                       (67 + 55) / 122][Stage 120:=================================>                   (78 + 44) / 122][Stage 120:==========================================>         (100 + 22) / 122][Stage 120:====================================================>(121 + 1) / 122]                                                                                [Stage 121:==========================>                          (62 + 61) / 123][Stage 121:============================>                        (66 + 57) / 123][Stage 121:=================================>                   (78 + 45) / 123][Stage 121:============================================>       (106 + 17) / 123]                                                                                Time elapsed: 3.705029229 seconds
res123: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide82"
dataSource: String = /nidan/orc/individualORC/slide82

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 182  OR  partitionIndex = 183  OR   partitionIndex = 192  OR  partitionIndex = 193 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 182  OR  partitionIndex = 183  OR  partitionIndex = 192  OR  partitionIndex = 193 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.388066321 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 122:================================>                    (71 + 46) / 117][Stage 122:=================================>                   (75 + 42) / 117][Stage 122:========================================>            (89 + 28) / 117][Stage 122:==============================================>     (105 + 12) / 117]                                                                                [Stage 123:=================================>                   (74 + 44) / 118][Stage 123:===================================>                 (80 + 38) / 118][Stage 123:=========================================>           (93 + 25) / 118][Stage 123:================================================>    (109 + 9) / 118]                                                                                Time elapsed: 3.040744764 seconds
res125: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide28"
dataSource: String = /nidan/orc/individualORC/slide28

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 45  OR  partitionIndex = 46  OR  pa rtitionIndex = 60  OR  partitionIndex = 61 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 45  OR  partitionIndex = 46  OR  partitionIndex = 60  OR  partitionIndex = 61 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.418735627 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 124:==========================>                          (62 + 60) / 122][Stage 124:=============================>                       (68 + 54) / 122][Stage 124:========================================>            (93 + 29) / 122][Stage 124:==============================================>     (110 + 12) / 122]                                                                                [Stage 125:==========================>                          (62 + 61) / 123][Stage 125:==============================>                      (71 + 52) / 123][Stage 125:=====================================>               (88 + 35) / 123][Stage 125:============================================>       (106 + 17) / 123][Stage 125:===================================================> (120 + 3) / 123]                                                                                Time elapsed: 3.204926177 seconds
res127: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide32"
dataSource: String = /nidan/orc/individualORC/slide32

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  part itionIndex = 21  OR  partitionIndex = 22 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  partitionIndex = 21  OR  partitionIndex = 22 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.401327802 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 126:==================================>                  (74 + 41) / 115][Stage 126:=======================================>             (86 + 29) / 115][Stage 126:============================================>        (97 + 18) / 115][Stage 126:=============================================>      (100 + 15) / 115][Stage 126:====================================================>(113 + 2) / 115]                                                                                [Stage 127:===============================>                     (69 + 47) / 116][Stage 127:===================================>                 (77 + 39) / 116][Stage 127:=========================================>           (91 + 25) / 116][Stage 127:=============================================>      (102 + 14) / 116][Stage 127:===================================================> (113 + 3) / 116][Stage 127:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 4.56574523 seconds
res129: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide10"
dataSource: String = /nidan/orc/individualORC/slide10

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  pa rtitionIndex = 57  OR  partitionIndex = 58 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  partitionIndex = 57  OR  partitionIndex = 58 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.41262009 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 128:==========================>                          (61 + 60) / 121][Stage 128:==============================>                      (70 + 51) / 121][Stage 128:=====================================>               (86 + 35) / 121][Stage 128:=============================================>      (107 + 14) / 121][Stage 128:====================================================>(119 + 2) / 121]                                                                                [Stage 129:==========================>                          (62 + 60) / 122][Stage 129:==============================>                      (71 + 51) / 122][Stage 129:==================================>                  (80 + 42) / 122][Stage 129:==============================================>     (109 + 13) / 122][Stage 129:===================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.269728133 seconds
res131: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide9"
dataSource: String = /nidan/orc/individualORC/slide9

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 83  OR  partitionIndex = 96  OR  pa rtitionIndex = 97  OR  partitionIndex = 112 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 83  OR  partitionIndex = 96  OR  partitionIndex = 97  OR  partitionIndex = 112 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.377364777 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 130:=================================>                   (73 + 41) / 114][Stage 130:======================================>              (83 + 31) / 114][Stage 130:==============================================>     (101 + 13) / 114][Stage 130:==================================================>  (108 + 6) / 114][Stage 130:===================================================> (110 + 4) / 114]                                                                                [Stage 131:=================================>                   (72 + 43) / 115][Stage 131:=======================================>             (86 + 29) / 115][Stage 131:=============================================>      (100 + 15) / 115][Stage 131:================================================>    (106 + 9) / 115][Stage 131:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.070163571 seconds
res133: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide48"
dataSource: String = /nidan/orc/individualORC/slide48

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 195  OR  partitionIndex = 210  OR   partitionIndex = 211  OR  partitionIndex = 224 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 195  OR  partitionIndex = 210  OR  partitionIndex = 211  OR  partitionIndex = 224 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.332874649 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 132:====================================>                (80 + 35) / 115][Stage 132:=======================================>             (86 + 29) / 115][Stage 132:=============================================>       (98 + 17) / 115][Stage 132:===================================================> (112 + 3) / 115][Stage 132:====================================================>(114 + 1) / 115]                                                                                [Stage 133:=====================================>               (83 + 33) / 116][Stage 133:=========================================>           (91 + 25) / 116][Stage 133:============================================>        (98 + 18) / 116][Stage 133:==================================================>  (111 + 5) / 116][Stage 133:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.861726374 seconds
res135: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide100"
dataSource: String = /nidan/orc/individualORC/slide100

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 69  OR  partitionIndex = 70  OR  pa rtitionIndex = 84  OR  partitionIndex = 85 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 69  OR  partitionIndex = 70  OR  partitionIndex = 84  OR  partitionIndex = 85 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.361799864 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 134:=================================>                   (73 + 41) / 114][Stage 134:========================================>            (87 + 27) / 114][Stage 134:============================================>        (95 + 19) / 114][Stage 134:===================================================> (111 + 3) / 114][Stage 134:====================================================>(113 + 1) / 114]                                                                                [Stage 135:===================================>                 (77 + 38) / 115][Stage 135:========================================>            (88 + 27) / 115][Stage 135:=============================================>      (100 + 15) / 115][Stage 135:==================================================>  (110 + 5) / 115][Stage 135:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.207080321 seconds
res137: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide18"
dataSource: String = /nidan/orc/individualORC/slide18

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR   partitionIndex = 177  OR  partitionIndex = 178 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR  partitionIndex = 177  OR  partitionIndex = 178 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.372026146 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 136:=================================>                   (73 + 42) / 115][Stage 136:=====================================>               (81 + 34) / 115][Stage 136:============================================>        (96 + 19) / 115][Stage 136:=================================================>   (108 + 7) / 115]                                                                                [Stage 137:==================================>                  (76 + 40) / 116][Stage 137:========================================>            (88 + 28) / 116][Stage 137:=============================================>      (102 + 14) / 116][Stage 137:==================================================>  (110 + 6) / 116]                                                                                Time elapsed: 2.951789281 seconds
res139: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide19"
dataSource: String = /nidan/orc/individualORC/slide19

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR   partitionIndex = 242  OR  partitionIndex = 243 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR  partitionIndex = 242  OR  partitionIndex = 243 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.357324417 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 138:================================>                    (71 + 46) / 117][Stage 138:=================================>                   (75 + 42) / 117][Stage 138:=========================================>           (92 + 25) / 117][Stage 138:==============================================>     (105 + 12) / 117]                                                                                [Stage 139:================================>                    (72 + 46) / 118][Stage 139:==================================>                  (77 + 41) / 118][Stage 139:========================================>            (91 + 27) / 118][Stage 139:================================================>    (109 + 9) / 118][Stage 139:===================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.29225066 seconds
res141: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide78"
dataSource: String = /nidan/orc/individualORC/slide78

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 95  OR  partitionIndex = 108  OR  p artitionIndex = 109  OR  partitionIndex = 124 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 95  OR  partitionIndex = 108  OR  partitionIndex = 109  OR  partitionIndex = 124 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide78;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 140:================================>                    (71 + 46) / 117][Stage 140:====================================>                (80 + 37) / 117][Stage 140:=========================================>           (91 + 26) / 117][Stage 140:=================================================>   (110 + 7) / 117]                                                                                [Stage 141:================================>                    (72 + 46) / 118][Stage 141:==================================>                  (76 + 42) / 118][Stage 141:=======================================>             (89 + 29) / 118][Stage 141:===============================================>    (107 + 11) / 118][Stage 141:===================================================> (115 + 3) / 118][Stage 141:====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.591779271 seconds
res143: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide79"
dataSource: String = /nidan/orc/individualORC/slide79

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR   partitionIndex = 184  OR  partitionIndex = 185 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR  partitionIndex = 184  OR  partitionIndex = 185 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.353554855 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 142:==================================>                  (75 + 39) / 114][Stage 142:==========================================>          (91 + 23) / 114][Stage 142:=============================================>      (100 + 14) / 114][Stage 142:=================================================>   (107 + 7) / 114][Stage 142:====================================================>(112 + 2) / 114]                                                                                [Stage 143:===================================>                 (76 + 39) / 115][Stage 143:=========================================>           (89 + 26) / 115][Stage 143:=============================================>      (101 + 14) / 115][Stage 143:==================================================>  (110 + 5) / 115][Stage 143:====================================================>(113 + 2) / 115][Stage 143:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.217946455 seconds
res145: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide32"
dataSource: String = /nidan/orc/individualORC/slide32

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  pa rtitionIndex = 56  OR  partitionIndex = 57 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  partitionIndex = 56  OR  partitionIndex = 57 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.368231584 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 144:==============================>                      (67 + 48) / 115][Stage 144:==================================>                  (75 + 40) / 115][Stage 144:=========================================>           (90 + 25) / 115][Stage 144:=============================================>      (100 + 15) / 115][Stage 144:===================================================> (112 + 3) / 115]                                                                                [Stage 145:==================================>                  (76 + 40) / 116][Stage 145:==========================================>          (92 + 24) / 116][Stage 145:=============================================>       (99 + 17) / 116][Stage 145:=================================================>   (108 + 8) / 116][Stage 145:===================================================> (113 + 3) / 116][Stage 145:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.867955684 seconds
res147: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide39"
dataSource: String = /nidan/orc/individualORC/slide39

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 77  OR  partitionIndex = 78  OR  pa rtitionIndex = 92  OR  partitionIndex = 93 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 77  OR  partitionIndex = 78  OR  partitionIndex = 92  OR  partitionIndex = 93 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.371938327 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 146:==============================>                      (66 + 49) / 115][Stage 146:=====================================>               (81 + 34) / 115][Stage 146:=============================================>      (100 + 15) / 115][Stage 146:===================================================> (112 + 3) / 115]                                                                                [Stage 147:====================================>                (80 + 36) / 116][Stage 147:==========================================>          (92 + 24) / 116][Stage 147:==============================================>     (103 + 13) / 116][Stage 147:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.709287567 seconds
res149: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide100"
dataSource: String = /nidan/orc/individualORC/slide100

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 168  OR  partitionIndex = 169  OR   partitionIndex = 184  OR  partitionIndex = 185 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 168  OR  partitionIndex = 169  OR  partitionIndex = 184  OR  partitionIndex = 185 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.365278987 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 148:======================================>              (82 + 32) / 114][Stage 148:=========================================>           (90 + 24) / 114][Stage 148:===============================================>    (104 + 10) / 114][Stage 148:====================================================>(113 + 1) / 114]                                                                                [Stage 149:==================================>                  (75 + 40) / 115][Stage 149:=========================================>           (89 + 26) / 115][Stage 149:============================================>        (97 + 18) / 115][Stage 149:=================================================>   (107 + 8) / 115][Stage 149:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.058916801 seconds
res151: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide61"
dataSource: String = /nidan/orc/individualORC/slide61

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR   partitionIndex = 208  OR  partitionIndex = 209 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR  partitionIndex = 208  OR  partitionIndex = 209 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.371413844 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 150:================================>                    (71 + 46) / 117][Stage 150:=================================>                   (75 + 42) / 117][Stage 150:========================================>            (89 + 28) / 117][Stage 150:===============================================>    (106 + 11) / 117][Stage 150:====================================================>(116 + 1) / 117]                                                                                [Stage 151:================================>                    (72 + 46) / 118][Stage 151:=================================>                   (74 + 44) / 118][Stage 151:======================================>              (86 + 32) / 118][Stage 151:=================================================>   (110 + 8) / 118][Stage 151:====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.168085723 seconds
res153: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide34"
dataSource: String = /nidan/orc/individualORC/slide34

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 128  OR  partitionIndex = 129  OR   partitionIndex = 144  OR  partitionIndex = 145 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 128  OR  partitionIndex = 129  OR  partitionIndex = 144  OR  partitionIndex = 145 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.34419356 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 152:====================================>                (80 + 35) / 115][Stage 152:=======================================>             (86 + 29) / 115][Stage 152:============================================>        (96 + 19) / 115][Stage 152:=================================================>   (108 + 7) / 115][Stage 152:====================================================>(114 + 1) / 115]                                                                                [Stage 153:======================================>              (85 + 31) / 116][Stage 153:==========================================>          (92 + 24) / 116][Stage 153:=============================================>       (99 + 17) / 116][Stage 153:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.767263823 seconds
res155: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide64"
dataSource: String = /nidan/orc/individualORC/slide64

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 34  OR  partitionIndex = 35  OR  pa rtitionIndex = 50  OR  partitionIndex = 51 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 34  OR  partitionIndex = 35  OR  partitionIndex = 50  OR  partitionIndex = 51 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide64;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 154:====================================>                (80 + 35) / 115][Stage 154:======================================>              (84 + 31) / 115][Stage 154:============================================>        (97 + 18) / 115][Stage 154:=================================================>   (108 + 7) / 115][Stage 154:==================================================>  (110 + 5) / 115]                                                                                [Stage 155:======================================>              (85 + 31) / 116][Stage 155:===========================================>         (95 + 21) / 116][Stage 155:=================================================>   (108 + 8) / 116][Stage 155:===================================================> (113 + 3) / 116][Stage 155:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.268671099 seconds
res157: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide41"
dataSource: String = /nidan/orc/individualORC/slide41

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 46  OR  partitionIndex = 47  OR  pa rtitionIndex = 60  OR  partitionIndex = 61 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 46  OR  partitionIndex = 47  OR  partitionIndex = 60  OR  partitionIndex = 61 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.335999611 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 156:======================================>              (84 + 31) / 115][Stage 156:===========================================>         (94 + 21) / 115][Stage 156:===================================================> (111 + 4) / 115]                                                                                [Stage 157:=====================================>               (81 + 35) / 116][Stage 157:==========================================>          (92 + 24) / 116][Stage 157:==============================================>     (104 + 12) / 116][Stage 157:===================================================> (112 + 4) / 116][Stage 157:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.714998275 seconds
res159: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide36"
dataSource: String = /nidan/orc/individualORC/slide36

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR   partitionIndex = 152  OR  partitionIndex = 153 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR  partitionIndex = 152  OR  partitionIndex = 153 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide36;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 158:=======================================>             (85 + 30) / 115][Stage 158:=============================================>       (98 + 17) / 115][Stage 158:===============================================>    (105 + 10) / 115][Stage 158:===================================================> (112 + 3) / 115]                                                                                [Stage 159:======================================>              (85 + 31) / 116][Stage 159:==========================================>          (93 + 23) / 116][Stage 159:=================================================>   (108 + 8) / 116][Stage 159:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 2.87151672 seconds
res161: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide52"
dataSource: String = /nidan/orc/individualORC/slide52

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 31  OR  partitionIndex = 44  OR  pa rtitionIndex = 45  OR  partitionIndex = 60 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 31  OR  partitionIndex = 44  OR  partitionIndex = 45  OR  partitionIndex = 60 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.418818112 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 160:==========================>                          (61 + 60) / 121][Stage 160:==============================>                      (70 + 51) / 121][Stage 160:=======================================>             (90 + 31) / 121][Stage 160:==============================================>     (109 + 12) / 121][Stage 160:====================================================>(120 + 1) / 121]                                                                                [Stage 161:==========================>                          (62 + 60) / 122][Stage 161:================================>                    (74 + 48) / 122][Stage 161:=======================================>             (92 + 30) / 122][Stage 161:=================================================>   (115 + 7) / 122][Stage 161:====================================================>(121 + 1) / 122]                                                                                Time elapsed: 3.223215287 seconds
res163: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide83"
dataSource: String = /nidan/orc/individualORC/slide83

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  pa rtitionIndex = 81  OR  partitionIndex = 82 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  partitionIndex = 81  OR  partitionIndex = 82 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.337977623 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 162:=====================================>               (82 + 33) / 115][Stage 162:=========================================>           (89 + 26) / 115][Stage 162:=============================================>       (99 + 16) / 115][Stage 162:====================================================>(114 + 1) / 115]                                                                                [Stage 163:======================================>              (85 + 31) / 116][Stage 163:============================================>       (100 + 16) / 116][Stage 163:=================================================>   (108 + 8) / 116][Stage 163:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.813519892 seconds
res165: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide88"
dataSource: String = /nidan/orc/individualORC/slide88

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 133  OR   partitionIndex = 178  OR  partitionIndex = 179 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 133  OR  partitionIndex = 178  OR  partitionIndex = 179 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.367010219 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 164:=================================>                   (73 + 42) / 115][Stage 164:========================================>            (88 + 27) / 115][Stage 164:================================================>    (106 + 9) / 115]                                                                                [Stage 165:=================================>                   (73 + 43) / 116][Stage 165:==========================================>          (92 + 24) / 116][Stage 165:================================================>    (107 + 9) / 116]                                                                                Time elapsed: 2.593796385 seconds
res167: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide30"
dataSource: String = /nidan/orc/individualORC/slide30

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 150  OR  partitionIndex = 151  OR   partitionIndex = 164  OR  partitionIndex = 165 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 150  OR  partitionIndex = 151  OR  partitionIndex = 164  OR  partitionIndex = 165 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.364045401 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 166:===================================>                 (77 + 37) / 114][Stage 166:========================================>            (87 + 27) / 114][Stage 166:==============================================>     (102 + 12) / 114][Stage 166:===================================================> (110 + 4) / 114][Stage 166:====================================================>(112 + 2) / 114]                                                                                [Stage 167:=======================================>             (85 + 30) / 115][Stage 167:=============================================>      (100 + 15) / 115][Stage 167:================================================>    (106 + 9) / 115][Stage 167:===================================================> (111 + 4) / 115]                                                                                Time elapsed: 3.097367072 seconds
res169: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide40"
dataSource: String = /nidan/orc/individualORC/slide40

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 154  OR  partitionIndex = 155  OR   partitionIndex = 168  OR  partitionIndex = 169 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 154  OR  partitionIndex = 155  OR  partitionIndex = 168  OR  partitionIndex = 169 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.361292366 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 168:================================>                    (72 + 45) / 117][Stage 168:=====================================>               (82 + 35) / 117][Stage 168:==========================================>          (93 + 24) / 117][Stage 168:=================================================>   (109 + 8) / 117][Stage 168:====================================================>(116 + 1) / 117]                                                                                [Stage 169:=================================>                   (74 + 44) / 118][Stage 169:======================================>              (86 + 32) / 118][Stage 169:============================================>       (101 + 17) / 118][Stage 169:====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.357564908 seconds
res171: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide39"
dataSource: String = /nidan/orc/individualORC/slide39

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 169  OR  partitionIndex = 170  OR   partitionIndex = 184  OR  partitionIndex = 185 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 169  OR  partitionIndex = 170  OR  partitionIndex = 184  OR  partitionIndex = 185 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.374081563 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 170:================================>                    (71 + 44) / 115][Stage 170:====================================>                (79 + 36) / 115][Stage 170:=============================================>      (100 + 15) / 115][Stage 170:===================================================> (112 + 3) / 115]                                                                                [Stage 171:====================================>                (79 + 37) / 116][Stage 171:=========================================>           (91 + 25) / 116][Stage 171:==============================================>     (104 + 12) / 116][Stage 171:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.924278069 seconds
res173: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide34"
dataSource: String = /nidan/orc/individualORC/slide34

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 70  OR  partitionIndex = 71  OR  pa rtitionIndex = 84  OR  partitionIndex = 85 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 70  OR  partitionIndex = 71  OR  partitionIndex = 84  OR  partitionIndex = 85 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.332598633 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 172:=======================================>             (85 + 30) / 115][Stage 172:============================================>        (96 + 19) / 115][Stage 172:===============================================>    (104 + 11) / 115][Stage 172:===================================================> (112 + 3) / 115]                                                                                [Stage 173:=======================================>             (86 + 30) / 116][Stage 173:==========================================>          (93 + 23) / 116][Stage 173:============================================>       (100 + 16) / 116][Stage 173:===================================================> (112 + 4) / 116]                                                                                Time elapsed: 2.974645176 seconds
res175: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide2"
dataSource: String = /nidan/orc/individualORC/slide2

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  pa rtitionIndex = 80  OR  partitionIndex = 81 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  partitionIndex = 80  OR  partitionIndex = 81 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.353990582 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 174:==================================>                  (74 + 40) / 114][Stage 174:=======================================>             (86 + 28) / 114][Stage 174:=============================================>       (98 + 16) / 114][Stage 174:=================================================>   (107 + 7) / 114][Stage 174:====================================================>(113 + 1) / 114]                                                                                [Stage 175:===================================>                 (76 + 39) / 115][Stage 175:=========================================>           (89 + 26) / 115][Stage 175:=============================================>      (101 + 14) / 115][Stage 175:=================================================>   (107 + 8) / 115][Stage 175:===================================================> (112 + 3) / 115][Stage 175:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.155751894 seconds
res177: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide4"
dataSource: String = /nidan/orc/individualORC/slide4

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 73  OR  partitionIndex = 74  OR  pa rtitionIndex = 88  OR  partitionIndex = 89 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 73  OR  partitionIndex = 74  OR  partitionIndex = 88  OR  partitionIndex = 89 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.383937863 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 176:==============================>                      (66 + 49) / 115][Stage 176:===================================>                 (78 + 37) / 115][Stage 176:========================================>            (88 + 27) / 115][Stage 176:=============================================>       (99 + 16) / 115][Stage 176:================================================>    (106 + 9) / 115][Stage 176:====================================================>(114 + 1) / 115]                                                                                [Stage 177:===============================>                     (69 + 47) / 116][Stage 177:======================================>              (84 + 32) / 116][Stage 177:===========================================>         (96 + 20) / 116][Stage 177:=================================================>   (109 + 7) / 116]                                                                                Time elapsed: 3.026792315 seconds
res179: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide40"
dataSource: String = /nidan/orc/individualORC/slide40

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 230  OR  partitionIndex = 231  OR   partitionIndex = 244  OR  partitionIndex = 245 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 230  OR  partitionIndex = 231  OR  partitionIndex = 244  OR  partitionIndex = 245 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.356567538 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 178:================================>                    (72 + 45) / 117][Stage 178:===================================>                 (79 + 38) / 117][Stage 178:==========================================>          (93 + 24) / 117][Stage 178:================================================>    (108 + 9) / 117][Stage 178:====================================================>(116 + 1) / 117]                                                                                [Stage 179:================================>                    (73 + 45) / 118][Stage 179:=================================>                   (74 + 44) / 118][Stage 179:======================================>              (85 + 33) / 118][Stage 179:============================================>        (99 + 19) / 118][Stage 179:===================================================> (115 + 3) / 118][Stage 179:====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.472200092 seconds
res181: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide86"
dataSource: String = /nidan/orc/individualORC/slide86

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 210  OR  partitionIndex = 211  OR   partitionIndex = 224  OR  partitionIndex = 225 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 210  OR  partitionIndex = 211  OR  partitionIndex = 224  OR  partitionIndex = 225 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.361346547 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 180:==================================>                  (75 + 39) / 114][Stage 180:=========================================>           (90 + 24) / 114][Stage 180:==============================================>     (101 + 13) / 114][Stage 180:==================================================>  (109 + 5) / 114]                                                                                [Stage 181:=====================================>               (81 + 34) / 115][Stage 181:=========================================>           (91 + 24) / 115][Stage 181:=================================================>   (107 + 8) / 115][Stage 181:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 2.843438949 seconds
res183: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide21"
dataSource: String = /nidan/orc/individualORC/slide21

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 11  OR  partitionIndex = 26  OR  pa rtitionIndex = 27  OR  partitionIndex = 40 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 11  OR  partitionIndex = 26  OR  partitionIndex = 27  OR  partitionIndex = 40 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.422308416 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 182:==========================>                          (62 + 60) / 122][Stage 182:=============================>                       (68 + 54) / 122][Stage 182:======================================>              (88 + 34) / 122][Stage 182:==============================================>     (108 + 14) / 122]                                                                                [Stage 183:==========================>                          (62 + 61) / 123][Stage 183:===============================>                     (74 + 49) / 123][Stage 183:========================================>            (93 + 30) / 123][Stage 183:==============================================>     (110 + 13) / 123][Stage 183:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.408061849 seconds
res185: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide1"
dataSource: String = /nidan/orc/individualORC/slide1

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 38  OR  partitionIndex = 39  OR  pa rtitionIndex = 52  OR  partitionIndex = 53 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 38  OR  partitionIndex = 39  OR  partitionIndex = 52  OR  partitionIndex = 53 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.37997506 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 184:===========================>                         (59 + 54) / 113][Stage 184:================================>                    (70 + 43) / 113][Stage 184:===========================================>         (93 + 20) / 113][Stage 184:===================================================> (109 + 4) / 113]                                                                                [Stage 185:===========================>                         (60 + 54) / 114][Stage 185:================================>                    (69 + 45) / 114][Stage 185:=========================================>           (89 + 25) / 114][Stage 185:===============================================>    (104 + 10) / 114][Stage 185:===================================================> (111 + 3) / 114]                                                                                Time elapsed: 3.430304366 seconds
res187: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide46"
dataSource: String = /nidan/orc/individualORC/slide46

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 163  OR   partitionIndex = 178  OR  partitionIndex = 179 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 163  OR  partitionIndex = 178  OR  partitionIndex = 179 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.36999078 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 186:===============================>                     (68 + 47) / 115][Stage 186:====================================>                (80 + 35) / 115][Stage 186:=========================================>           (91 + 24) / 115][Stage 186:==================================================>  (110 + 5) / 115][Stage 186:====================================================>(113 + 2) / 115]                                                                                [Stage 187:===============================>                     (69 + 47) / 116][Stage 187:====================================>                (80 + 36) / 116][Stage 187:============================================>       (100 + 16) / 116][Stage 187:=================================================>   (109 + 7) / 116]                                                                                Time elapsed: 2.827557079 seconds
res189: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide12"
dataSource: String = /nidan/orc/individualORC/slide12

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR   partitionIndex = 144  OR  partitionIndex = 145 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR  partitionIndex = 144  OR  partitionIndex = 145 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.359608297 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 188:================================>                    (71 + 46) / 117][Stage 188:================================>                    (72 + 45) / 117][Stage 188:======================================>              (84 + 33) / 117][Stage 188:================================================>    (108 + 9) / 117][Stage 188:====================================================>(115 + 2) / 117]                                                                                [Stage 189:================================>                    (72 + 46) / 118][Stage 189:=================================>                   (75 + 43) / 118][Stage 189:=======================================>             (87 + 31) / 118][Stage 189:===============================================>    (108 + 10) / 118]                                                                                Time elapsed: 3.000163645 seconds
res191: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide90"
dataSource: String = /nidan/orc/individualORC/slide90

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR   partitionIndex = 221  OR  partitionIndex = 222 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR  partitionIndex = 221  OR  partitionIndex = 222 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.335503631 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 190:======================================>              (83 + 32) / 115][Stage 190:=========================================>           (91 + 24) / 115][Stage 190:==============================================>     (102 + 13) / 115][Stage 190:===================================================> (112 + 3) / 115]                                                                                [Stage 191:=====================================>               (82 + 34) / 116][Stage 191:==========================================>          (92 + 24) / 116][Stage 191:==============================================>     (104 + 12) / 116][Stage 191:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 2.714163496 seconds
res193: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide32"
dataSource: String = /nidan/orc/individualORC/slide32

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 230  OR  partitionIndex = 231  OR   partitionIndex = 246  OR  partitionIndex = 247 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 230  OR  partitionIndex = 231  OR  partitionIndex = 246  OR  partitionIndex = 247 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.365836095 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 192:===================================>                 (78 + 37) / 115][Stage 192:========================================>            (88 + 27) / 115][Stage 192:=============================================>      (100 + 15) / 115][Stage 192:=================================================>   (107 + 8) / 115]                                                                                [Stage 193:====================================>                (79 + 37) / 116][Stage 193:==========================================>          (92 + 24) / 116][Stage 193:============================================>       (100 + 16) / 116][Stage 193:===================================================> (112 + 4) / 116]                                                                                Time elapsed: 3.00186688 seconds
res195: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide43"
dataSource: String = /nidan/orc/individualORC/slide43

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR   partitionIndex = 185  OR  partitionIndex = 186 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR  partitionIndex = 185  OR  partitionIndex = 186 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide43;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 194:==============================>                      (67 + 48) / 115][Stage 194:=================================>                   (73 + 42) / 115][Stage 194:========================================>            (87 + 28) / 115][Stage 194:=============================================>       (99 + 16) / 115][Stage 194:===================================================> (111 + 4) / 115]                                                                                [Stage 195:===============================>                     (69 + 47) / 116][Stage 195:=======================================>             (86 + 30) / 116][Stage 195:=============================================>       (99 + 17) / 116][Stage 195:===============================================>    (105 + 11) / 116][Stage 195:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 2.884097268 seconds
res197: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide95"
dataSource: String = /nidan/orc/individualORC/slide95

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  pa rtitionIndex = 82  OR  partitionIndex = 83 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 66  OR  partitionIndex = 67  OR  partitionIndex = 82  OR  partitionIndex = 83 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.366943343 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 196:==============================>                      (66 + 49) / 115][Stage 196:==================================>                  (74 + 41) / 115][Stage 196:=========================================>           (90 + 25) / 115][Stage 196:=============================================>      (100 + 15) / 115][Stage 196:====================================================>(114 + 1) / 115]                                                                                [Stage 197:================================>                    (71 + 45) / 116][Stage 197:=====================================>               (83 + 33) / 116][Stage 197:===========================================>         (95 + 21) / 116][Stage 197:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.818219971 seconds
res199: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide7"
dataSource: String = /nidan/orc/individualORC/slide7

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 193  OR  partitionIndex = 194  OR   partitionIndex = 208  OR  partitionIndex = 209 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 193  OR  partitionIndex = 194  OR  partitionIndex = 208  OR  partitionIndex = 209 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.428515756 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 198:==========================>                          (62 + 60) / 122][Stage 198:=================================>                   (76 + 46) / 122][Stage 198:========================================>            (93 + 29) / 122][Stage 198:=================================================>   (115 + 7) / 122]                                                                                [Stage 199:===========================>                         (63 + 60) / 123][Stage 199:=============================>                       (68 + 55) / 123][Stage 199:========================================>            (93 + 30) / 123][Stage 199:===============================================>    (112 + 11) / 123][Stage 199:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.374963546 seconds
res201: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide90"
dataSource: String = /nidan/orc/individualORC/slide90

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 5  OR  partitionIndex = 6  OR  part itionIndex = 20  OR  partitionIndex = 21 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 5  OR  partitionIndex = 6  OR  partitionIndex = 20  OR  partitionIndex = 21 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.37138945 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 200:=====================================>               (81 + 34) / 115][Stage 200:========================================>            (88 + 27) / 115][Stage 200:=============================================>       (98 + 17) / 115][Stage 200:===================================================> (111 + 4) / 115]                                                                                [Stage 201:=======================================>             (86 + 30) / 116][Stage 201:==========================================>          (92 + 24) / 116][Stage 201:============================================>       (100 + 16) / 116][Stage 201:===================================================> (113 + 3) / 116][Stage 201:====================================================>(114 + 2) / 116][Stage 201:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.858191676 seconds
res203: Int = 0

scala> 

scala> :quit
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.12:49286) dropped. RpcEnv already stopped.
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.16:34972) dropped. RpcEnv already stopped.
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.43:41902) dropped. RpcEnv already stopped.
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.16:34972) dropped. RpcEnv already stopped.
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.12:49286) dropped. RpcEnv already stopped.
17/05/30 02:36:23 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.43:41902) dropped. RpcEnv already stopped.

real	10m22.583s
user	11m58.104s
sys	0m52.204s
