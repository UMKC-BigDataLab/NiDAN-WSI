Warning: Ignoring non-spark config property: hive.exec.reducers.bytes.per.reducer=67108864
Warning: Ignoring non-spark config property: hive.fetch.task.aggr=false
Warning: Ignoring non-spark config property: hive.merge.sparkfiles=false
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask=true
Warning: Ignoring non-spark config property: hive.merge.size.per.task=256000000
Warning: Ignoring non-spark config property: hive.smbjoin.cache.rows=10000
Warning: Ignoring non-spark config property: hive.merge.smallfiles.avgsize=16000000
Warning: Ignoring non-spark config property: hive.optimize.sort.dynamic.partition=false
Warning: Ignoring non-spark config property: hive.exec.orc.default.stripe.size=67108864
Warning: Ignoring non-spark config property: hive.vectorized.execution.enabled=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication.min.reducer=4
Warning: Ignoring non-spark config property: hive.orc.splits.include.file.footer=false
Warning: Ignoring non-spark config property: hive.merge.mapfiles=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.list-status.num-threads=5
Warning: Ignoring non-spark config property: hive.vectorized.groupby.checkinterval=4096
Warning: Ignoring non-spark config property: hive.compute.query.using.stats=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.split.maxsize=750000000
Warning: Ignoring non-spark config property: hive.merge.orcfile.stripe.level=true
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask.size=894435328
Warning: Ignoring non-spark config property: hive.fetch.task.conversion.threshold=1073741824
Warning: Ignoring non-spark config property: hive.auto.convert.join=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication=true
Warning: Ignoring non-spark config property: hive.vectorized.groupby.flush.percent=0.1
Warning: Ignoring non-spark config property: hive.fetch.task.conversion=more
Warning: Ignoring non-spark config property: hive.limit.pushdown.memory.usage=0.4
Warning: Ignoring non-spark config property: hive.vectorized.execution.reduce.enabled=false
Warning: Ignoring non-spark config property: hive.map.aggr=true
Warning: Ignoring non-spark config property: hive.stats.autogather=true
Warning: Ignoring non-spark config property: hive.stats.fetch.column.stats=true
Warning: Ignoring non-spark config property: hive.cbo.enable=true
Warning: Ignoring non-spark config property: hive.map.aggr.hash.percentmemory=0.5
Warning: Ignoring non-spark config property: hive.optimize.index.filter=true
Warning: Ignoring non-spark config property: hive.optimize.bucketmapjoin.sortedmerge=false
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/30 01:44:00 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 01:44:14 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 01:44:14 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 01:44:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/30 01:44:17 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/30 01:44:27 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://128.110.152.45:4040
Spark context available as 'sc' (master = spark://ctl:7077, app id = app-20170530014417-0709).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_121)
Type in expressions to have them evaluated.
Type :help for more information.

scala> import java.io.File
import java.io.File

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> import org.apache.spark.sql._
import org.apache.spark.sql._

scala> 

scala> val queryMsg = "#QUERY "
queryMsg: String = "#QUERY "

scala> val loadDBMsg = "#LOAD_DB "
loadDBMsg: String = "#LOAD_DB "

scala> val loadTable = "#LOAD_TABLE "
loadTable: String = "#LOAD_TABLE "

scala> val loadsqlHive = "#LOAD_SQL_CONTEXT "
loadsqlHive: String = "#LOAD_SQL_CONTEXT "

scala> 

scala> def show_timing[T](proc: => T): T = {
     |     val start=System.nanoTime()
     |     val res = proc
     |     val end = System.nanoTime()
     |     println("Time elapsed: " + (end-start)/1000000000.0 + " seconds")
     |     res
     | }
show_timing: [T](proc: => T)T

scala> 

scala> val writeToLocal = (in:(Array[Byte], Long, String)) =>{
     |     val bytes = in._1
     |     val output = in._3
     |     
     |     val writer = new FileOutputStream(output)
     |     writer.write(bytes)
     |     writer.close
     |     1
     |   }
writeToLocal: ((Array[Byte], Long, String)) => Int = <function1>

scala>   
     | val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@52737c1

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide4"
dataSource: String = /nidan/orc/individualORC/slide4

scala> 

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 4.35575439 seconds

scala> val queries = List(("SELECT imageBytes FROM data WHERE partitionZIndex>=100 AND partitionZIndex<=107", 8))
queries: List[(String, Int)] = List((SELECT imageBytes FROM data WHERE partitionZIndex>=100 AND partitionZIndex<=107,8))

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 0:>                                                      (0 + 112) / 115][Stage 0:===================>                                   (41 + 74) / 115][Stage 0:===========================>                           (58 + 57) / 115][Stage 0:=============================>                         (62 + 53) / 115][Stage 0:===============================>                       (66 + 49) / 115][Stage 0:=================================>                     (69 + 46) / 115][Stage 0:==================================>                    (72 + 43) / 115][Stage 0:===================================>                   (75 + 40) / 115][Stage 0:=====================================>                 (79 + 36) / 115][Stage 0:============================================>          (93 + 22) / 115][Stage 0:=============================================>         (95 + 20) / 115][Stage 0:=============================================>         (96 + 19) / 115][Stage 0:===============================================>      (101 + 14) / 115][Stage 0:================================================>     (104 + 11) / 115][Stage 0:====================================================>  (110 + 5) / 115][Stage 0:=====================================================> (111 + 4) / 115][Stage 0:======================================================>(114 + 1) / 115]                                                                                [Stage 1:==============================>                        (64 + 52) / 116][Stage 1:===============================>                       (66 + 50) / 116][Stage 1:===============================>                       (67 + 49) / 116][Stage 1:==================================>                    (72 + 44) / 116][Stage 1:====================================>                  (76 + 40) / 116][Stage 1:=======================================>               (84 + 32) / 116][Stage 1:==========================================>            (89 + 27) / 116][Stage 1:============================================>          (93 + 23) / 116][Stage 1:==============================================>        (98 + 18) / 116][Stage 1:===============================================>      (103 + 13) / 116][Stage 1:=====================================================> (112 + 4) / 116][Stage 1:======================================================>(115 + 1) / 116]                                                                                Time elapsed: 13.724376111 seconds
res2: Int = 0

scala> 

scala>  
     | val dataSource = "/nidan/orc/individualORC/slide4"
dataSource: String = /nidan/orc/individualORC/slide4

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 167  OR  partitionIndex = 182  OR   partitionIndex = 183  OR  partitionIndex = 192 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 167  OR  partitionIndex = 182  OR  partitionIndex = 183  OR  partitionIndex = 192 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.732960075 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 2:==========================>                            (55 + 60) / 115][Stage 2:=============================>                         (62 + 53) / 115][Stage 2:================================>                      (67 + 48) / 115][Stage 2:=================================>                     (70 + 45) / 115][Stage 2:=================================>                     (71 + 44) / 115][Stage 2:====================================>                  (77 + 38) / 115][Stage 2:========================================>              (84 + 31) / 115][Stage 2:==========================================>            (89 + 26) / 115][Stage 2:============================================>          (93 + 22) / 115][Stage 2:===================================================>   (107 + 8) / 115][Stage 2:======================================================>(114 + 1) / 115]                                                                                [Stage 3:================================>                      (68 + 48) / 116][Stage 3:===================================>                   (74 + 42) / 116][Stage 3:====================================>                  (77 + 39) / 116][Stage 3:=========================================>             (87 + 29) / 116][Stage 3:=========================================>             (88 + 28) / 116][Stage 3:===========================================>           (92 + 24) / 116][Stage 3:===============================================>      (103 + 13) / 116][Stage 3:====================================================>  (111 + 5) / 116][Stage 3:=====================================================> (112 + 4) / 116]                                                                                Time elapsed: 6.079541667 seconds
res5: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 196  OR  partitionIndex = 197  OR   partitionIndex = 242  OR  partitionIndex = 243 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 196  OR  partitionIndex = 197  OR  partitionIndex = 242  OR  partitionIndex = 243 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 4:==================>                                    (39 + 76) / 115][Stage 4:==============================>                        (63 + 52) / 115][Stage 4:=================================>                     (69 + 46) / 115][Stage 4:=================================>                     (71 + 44) / 115][Stage 4:=====================================>                 (79 + 36) / 115][Stage 4:=======================================>               (83 + 32) / 115][Stage 4:==========================================>            (88 + 27) / 115][Stage 4:=============================================>         (95 + 20) / 115][Stage 4:==============================================>       (100 + 15) / 115][Stage 4:================================================>     (103 + 12) / 115][Stage 4:=================================================>    (105 + 10) / 115][Stage 4:====================================================>  (110 + 5) / 115][Stage 4:======================================================>(114 + 1) / 115]                                                                                [Stage 5:==============================>                        (64 + 52) / 116][Stage 5:================================>                      (69 + 47) / 116][Stage 5:====================================>                  (77 + 39) / 116][Stage 5:======================================>                (82 + 34) / 116][Stage 5:=========================================>             (88 + 28) / 116][Stage 5:==============================================>        (99 + 17) / 116][Stage 5:===============================================>      (103 + 13) / 116][Stage 5:==================================================>    (107 + 9) / 116][Stage 5:=====================================================> (113 + 3) / 116]                                                                                Time elapsed: 5.745759566 seconds
res7: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide72"
dataSource: String = /nidan/orc/individualORC/slide72

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  pa rtitionIndex = 28  OR  partitionIndex = 29 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 13  OR  partitionIndex = 28  OR  partitionIndex = 29 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.585693284 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 6:================================>                      (67 + 47) / 114][Stage 6:=================================>                     (70 + 44) / 114][Stage 6:===================================>                   (74 + 40) / 114][Stage 6:========================================>              (83 + 31) / 114][Stage 6:============================================>          (92 + 22) / 114][Stage 6:===============================================>      (101 + 13) / 114][Stage 6:===================================================>   (106 + 8) / 114][Stage 6:=====================================================> (110 + 4) / 114][Stage 6:======================================================>(113 + 1) / 114]                                                                                [Stage 7:==================================>                    (72 + 43) / 115][Stage 7:======================================>                (81 + 34) / 115][Stage 7:========================================>              (85 + 30) / 115][Stage 7:==========================================>            (89 + 26) / 115][Stage 7:==============================================>        (97 + 18) / 115][Stage 7:===============================================>      (102 + 13) / 115][Stage 7:===================================================>   (108 + 7) / 115][Stage 7:====================================================>  (109 + 6) / 115]                                                                                Time elapsed: 5.751156716 seconds
res9: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR   partitionIndex = 210  OR  partitionIndex = 211 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR  partitionIndex = 210  OR  partitionIndex = 211 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 8:=================================>                     (69 + 45) / 114][Stage 8:========================================>              (83 + 31) / 114][Stage 8:============================================>          (93 + 21) / 114][Stage 8:===============================================>       (98 + 16) / 114][Stage 8:=================================================>    (104 + 10) / 114][Stage 8:====================================================>  (108 + 6) / 114][Stage 8:=====================================================> (111 + 3) / 114]                                                                                [Stage 9:===================================>                   (74 + 41) / 115][Stage 9:========================================>              (85 + 30) / 115][Stage 9:============================================>          (92 + 23) / 115][Stage 9:===============================================>      (101 + 14) / 115][Stage 9:==================================================>    (106 + 9) / 115][Stage 9:=====================================================> (112 + 3) / 115]                                                                                Time elapsed: 4.093740508 seconds
res11: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide64"
dataSource: String = /nidan/orc/individualORC/slide64

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR   partitionIndex = 222  OR  partitionIndex = 223 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR  partitionIndex = 222  OR  partitionIndex = 223 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide64;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 10:=================================>                    (70 + 44) / 114][Stage 10:===================================>                  (74 + 40) / 114][Stage 10:========================================>             (85 + 29) / 114][Stage 10:===========================================>          (92 + 22) / 114][Stage 10:=============================================>        (96 + 18) / 114][Stage 10:==================================================>   (106 + 8) / 114][Stage 10:====================================================> (111 + 3) / 114]                                                                                [Stage 11:===================================>                  (76 + 39) / 115][Stage 11:===========================================>          (92 + 23) / 115][Stage 11:==============================================>      (101 + 14) / 115][Stage 11:===============================================>     (104 + 11) / 115][Stage 11:=================================================>    (106 + 9) / 115][Stage 11:===================================================>  (109 + 6) / 115][Stage 11:=====================================================>(113 + 2) / 115]                                                                                Time elapsed: 4.137502148 seconds
res13: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide8"
dataSource: String = /nidan/orc/individualORC/slide8

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 173  OR  partitionIndex = 174  OR   partitionIndex = 188  OR  partitionIndex = 189 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 173  OR  partitionIndex = 174  OR  partitionIndex = 188  OR  partitionIndex = 189 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide8;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 12:>                                                       (0 + 0) / 114][Stage 12:================================>                     (68 + 46) / 114][Stage 12:=====================================>                (79 + 35) / 114][Stage 12:=======================================>              (83 + 31) / 114][Stage 12:===========================================>          (92 + 22) / 114][Stage 12:==============================================>      (100 + 14) / 114][Stage 12:====================================================> (111 + 3) / 114][Stage 12:=====================================================>(113 + 1) / 114]                                                                                [Stage 13:=================================>                    (72 + 43) / 115][Stage 13:=======================================>              (84 + 31) / 115][Stage 13:=============================================>        (96 + 19) / 115][Stage 13:===============================================>     (102 + 13) / 115][Stage 13:================================================>    (105 + 10) / 115][Stage 13:===================================================>  (109 + 6) / 115][Stage 13:=====================================================>(113 + 2) / 115]                                                                                Time elapsed: 4.141329631 seconds
res15: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide82"
dataSource: String = /nidan/orc/individualORC/slide82

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 32  OR  partitionIndex = 33  OR  pa rtitionIndex = 48  OR  partitionIndex = 49 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 32  OR  partitionIndex = 33  OR  partitionIndex = 48  OR  partitionIndex = 49 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.545974245 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 14:================================>                     (71 + 46) / 117][Stage 14:=====================================>                (82 + 35) / 117][Stage 14:==============================================>      (103 + 14) / 117][Stage 14:==================================================>   (110 + 7) / 117][Stage 14:=====================================================>(116 + 1) / 117]                                                                                [Stage 15:===============================>                      (68 + 50) / 118][Stage 15:================================>                     (72 + 46) / 118][Stage 15:======================================>               (85 + 33) / 118][Stage 15:========================================>             (89 + 29) / 118][Stage 15:================================================>    (108 + 10) / 118][Stage 15:===================================================>  (113 + 5) / 118]                                                                                Time elapsed: 3.698078194 seconds
res17: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide24"
dataSource: String = /nidan/orc/individualORC/slide24

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR   partitionIndex = 178  OR  partitionIndex = 179 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR  partitionIndex = 178  OR  partitionIndex = 179 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.582401933 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 16:===========================>                          (61 + 60) / 121][Stage 16:==============================>                       (69 + 52) / 121][Stage 16:======================================>               (86 + 35) / 121][Stage 16:==============================================>      (107 + 14) / 121][Stage 16:=====================================================>(120 + 1) / 121]                                                                                [Stage 17:===========================>                          (62 + 60) / 122][Stage 17:============================>                         (64 + 58) / 122][Stage 17:================================>                     (73 + 49) / 122][Stage 17:===========================================>          (98 + 24) / 122][Stage 17:==============================================>      (108 + 14) / 122][Stage 17:====================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.923480633 seconds
res19: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide23"
dataSource: String = /nidan/orc/individualORC/slide23

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR   partitionIndex = 185  OR  partitionIndex = 186 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR  partitionIndex = 185  OR  partitionIndex = 186 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.508150964 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 18:=================================>                    (70 + 44) / 114][Stage 18:=========================================>            (87 + 27) / 114][Stage 18:==============================================>      (100 + 14) / 114][Stage 18:=================================================>    (105 + 9) / 114][Stage 18:====================================================> (111 + 3) / 114]                                                                                [Stage 19:====================================>                 (78 + 37) / 115][Stage 19:========================================>             (86 + 29) / 115][Stage 19:=============================================>        (97 + 18) / 115][Stage 19:==================================================>   (107 + 8) / 115][Stage 19:====================================================> (111 + 4) / 115][Stage 19:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.410512106 seconds
res21: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide73"
dataSource: String = /nidan/orc/individualORC/slide73

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR   partitionIndex = 208  OR  partitionIndex = 209 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR  partitionIndex = 208  OR  partitionIndex = 209 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.605737876 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 20:===========================>                          (61 + 60) / 121][Stage 20:============================>                         (63 + 58) / 121][Stage 20:===============================>                      (71 + 50) / 121][Stage 20:=======================================>              (89 + 32) / 121][Stage 20:==============================================>      (106 + 15) / 121][Stage 20:===================================================>  (116 + 5) / 121][Stage 20:====================================================> (118 + 3) / 121]                                                                                [Stage 21:===========================>                          (63 + 59) / 122][Stage 21:=================================>                    (76 + 46) / 122][Stage 21:=======================================>              (90 + 32) / 122][Stage 21:===============================================>     (110 + 12) / 122][Stage 21:====================================================> (118 + 4) / 122][Stage 21:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 4.000175029 seconds
res23: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide42"
dataSource: String = /nidan/orc/individualORC/slide42

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 127  OR  partitionIndex = 128  OR   partitionIndex = 129  OR  partitionIndex = 144 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 127  OR  partitionIndex = 128  OR  partitionIndex = 129  OR  partitionIndex = 144 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.566640305 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 22:===========================>                          (61 + 61) / 122][Stage 22:=============================>                        (67 + 55) / 122][Stage 22:=====================================>                (84 + 38) / 122][Stage 22:===============================================>     (110 + 12) / 122][Stage 22:=====================================================>(121 + 1) / 122]                                                                                [Stage 23:===========================>                          (62 + 61) / 123][Stage 23:===========================>                          (63 + 60) / 123][Stage 23:=================================>                    (76 + 47) / 123][Stage 23:===========================================>         (102 + 21) / 123][Stage 23:==================================================>   (114 + 9) / 123][Stage 23:=====================================================>(121 + 2) / 123]                                                                                Time elapsed: 3.522945846 seconds
res25: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide18"
dataSource: String = /nidan/orc/individualORC/slide18

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 78  OR  partitionIndex = 79  OR  pa rtitionIndex = 93  OR  partitionIndex = 94 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 78  OR  partitionIndex = 79  OR  partitionIndex = 93  OR  partitionIndex = 94 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.515348499 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 24:================================>                     (69 + 46) / 115][Stage 24:======================================>               (82 + 33) / 115][Stage 24:===========================================>          (92 + 23) / 115][Stage 24:==============================================>      (101 + 14) / 115][Stage 24:=====================================================>(114 + 1) / 115]                                                                                [Stage 25:===============================>                      (68 + 48) / 116][Stage 25:=====================================>                (80 + 36) / 116][Stage 25:===========================================>          (94 + 22) / 116][Stage 25:===============================================>     (104 + 12) / 116][Stage 25:===================================================>  (111 + 5) / 116][Stage 25:=====================================================>(114 + 2) / 116][Stage 25:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.556665767 seconds
res27: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide28"
dataSource: String = /nidan/orc/individualORC/slide28

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 233  OR  partitionIndex = 234  OR   partitionIndex = 248  OR  partitionIndex = 249 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 233  OR  partitionIndex = 234  OR  partitionIndex = 248  OR  partitionIndex = 249 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.560639616 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 26:==========================>                           (60 + 62) / 122][Stage 26:===========================>                          (63 + 59) / 122][Stage 26:================================>                     (74 + 48) / 122][Stage 26:=========================================>            (94 + 28) / 122][Stage 26:===============================================>     (110 + 12) / 122][Stage 26:=====================================================>(121 + 1) / 122]                                                                                [Stage 27:===========================>                          (62 + 61) / 123][Stage 27:==============================>                       (69 + 54) / 123][Stage 27:======================================>               (88 + 35) / 123][Stage 27:============================================>        (104 + 19) / 123][Stage 27:===================================================>  (117 + 6) / 123][Stage 27:=====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.529341046 seconds
res29: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide12"
dataSource: String = /nidan/orc/individualORC/slide12

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR   partitionIndex = 125  OR  partitionIndex = 126 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR  partitionIndex = 125  OR  partitionIndex = 126 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.517419214 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 28:================================>                     (71 + 46) / 117][Stage 28:=================================>                    (72 + 45) / 117][Stage 28:======================================>               (84 + 33) / 117][Stage 28:===========================================>          (95 + 22) / 117][Stage 28:====================================================> (113 + 4) / 117][Stage 28:====================================================> (114 + 3) / 117]                                                                                [Stage 29:=================================>                    (73 + 45) / 118][Stage 29:======================================>               (85 + 33) / 118][Stage 29:==============================================>      (103 + 15) / 118][Stage 29:====================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.432399174 seconds
res31: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide82"
dataSource: String = /nidan/orc/individualORC/slide82

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  part itionIndex = 24  OR  partitionIndex = 119 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  partitionIndex = 24  OR  partitionIndex = 119 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.474391633 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 30:================================>                     (71 + 46) / 117][Stage 30:=================================>                    (72 + 45) / 117][Stage 30:=====================================>                (82 + 35) / 117][Stage 30:=============================================>        (99 + 18) / 117][Stage 30:==================================================>   (109 + 8) / 117]                                                                                [Stage 31:=================================>                    (74 + 44) / 118][Stage 31:====================================>                 (79 + 39) / 118][Stage 31:===============================================>     (106 + 12) / 118][Stage 31:===================================================>  (113 + 5) / 118]                                                                                Time elapsed: 3.235560532 seconds
res33: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide81"
dataSource: String = /nidan/orc/individualORC/slide81

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR   partitionIndex = 184  OR  partitionIndex = 185 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 170  OR  partitionIndex = 171  OR  partitionIndex = 184  OR  partitionIndex = 185 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.498376381 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 32:==================================>                   (74 + 41) / 115][Stage 32:======================================>               (83 + 32) / 115][Stage 32:============================================>         (95 + 20) / 115][Stage 32:==================================================>   (107 + 8) / 115][Stage 32:=====================================================>(114 + 1) / 115]                                                                                [Stage 33:================================>                     (69 + 47) / 116][Stage 33:======================================>               (82 + 34) / 116][Stage 33:===========================================>          (94 + 22) / 116][Stage 33:===============================================>     (104 + 12) / 116][Stage 33:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.10678475 seconds
res35: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide8"
dataSource: String = /nidan/orc/individualORC/slide8

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 4  OR  partitionIndex = 5  OR  part itionIndex = 20  OR  partitionIndex = 51 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 4  OR  partitionIndex = 5  OR  partitionIndex = 20  OR  partitionIndex = 51 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide8;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 34:==================================>                   (74 + 41) / 115][Stage 34:=========================================>            (88 + 27) / 115][Stage 34:============================================>         (95 + 20) / 115][Stage 34:====================================================> (111 + 4) / 115][Stage 34:=====================================================>(113 + 2) / 115]                                                                                [Stage 35:================================>                     (69 + 47) / 116][Stage 35:======================================>               (82 + 34) / 116][Stage 35:==========================================>           (91 + 25) / 116][Stage 35:===============================================>     (104 + 12) / 116][Stage 35:==================================================>   (109 + 7) / 116][Stage 35:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 5.00451897 seconds
res37: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 161  OR  partitionIndex = 162  OR   partitionIndex = 176  OR  partitionIndex = 177 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 161  OR  partitionIndex = 162  OR  partitionIndex = 176  OR  partitionIndex = 177 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 36:=================================>                    (72 + 43) / 115][Stage 36:========================================>             (86 + 29) / 115][Stage 36:=============================================>        (97 + 18) / 115][Stage 36:===================================================>  (110 + 5) / 115][Stage 36:=====================================================>(114 + 1) / 115]                                                                                [Stage 37:=====================================>                (81 + 35) / 116][Stage 37:===========================================>          (93 + 23) / 116][Stage 37:==============================================>      (102 + 14) / 116][Stage 37:====================================================> (113 + 3) / 116]                                                                                Time elapsed: 3.281930585 seconds
res39: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide66"
dataSource: String = /nidan/orc/individualORC/slide66

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 163  OR   partitionIndex = 178  OR  partitionIndex = 179 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 163  OR  partitionIndex = 178  OR  partitionIndex = 179 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.506547644 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 38:===========================>                          (61 + 60) / 121][Stage 38:==============================>                       (68 + 53) / 121][Stage 38:=====================================>                (84 + 37) / 121][Stage 38:===========================================>          (97 + 24) / 121][Stage 38:===================================================>  (116 + 5) / 121][Stage 38:=====================================================>(120 + 1) / 121]                                                                                [Stage 39:===========================>                          (62 + 60) / 122][Stage 39:==============================>                       (68 + 54) / 122][Stage 39:=========================================>            (94 + 28) / 122][Stage 39:================================================>    (111 + 11) / 122][Stage 39:====================================================> (119 + 3) / 122][Stage 39:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 3.795837302 seconds
res41: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide90"
dataSource: String = /nidan/orc/individualORC/slide90

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 131  OR  partitionIndex = 146  OR   partitionIndex = 147  OR  partitionIndex = 160 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 131  OR  partitionIndex = 146  OR  partitionIndex = 147  OR  partitionIndex = 160 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.410114602 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 40:=====================================>                (80 + 35) / 115][Stage 40:======================================>               (83 + 32) / 115][Stage 40:=============================================>        (97 + 18) / 115][Stage 40:================================================>    (105 + 10) / 115][Stage 40:===================================================>  (110 + 5) / 115][Stage 40:=====================================================>(113 + 2) / 115]                                                                                [Stage 41:=====================================>                (81 + 35) / 116][Stage 41:=========================================>            (90 + 26) / 116][Stage 41:==============================================>      (102 + 14) / 116][Stage 41:====================================================> (113 + 3) / 116]                                                                                Time elapsed: 3.220201028 seconds
res43: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide11"
dataSource: String = /nidan/orc/individualORC/slide11

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 11  OR  partitionIndex = 26  OR  pa rtitionIndex = 27  OR  partitionIndex = 40 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 11  OR  partitionIndex = 26  OR  partitionIndex = 27  OR  partitionIndex = 40 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.617167356 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 42:================================>                     (70 + 45) / 115][Stage 42:======================================>               (81 + 34) / 115][Stage 42:============================================>         (94 + 21) / 115][Stage 42:===================================================>  (110 + 5) / 115]                                                                                [Stage 43:=================================>                    (73 + 43) / 116][Stage 43:=======================================>              (84 + 32) / 116][Stage 43:==============================================>      (102 + 14) / 116][Stage 43:==================================================>   (109 + 7) / 116][Stage 43:====================================================> (112 + 4) / 116][Stage 43:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.672967162 seconds
res45: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide75"
dataSource: String = /nidan/orc/individualORC/slide75

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 76  OR  partitionIndex = 77  OR  pa rtitionIndex = 92  OR  partitionIndex = 93 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 76  OR  partitionIndex = 77  OR  partitionIndex = 92  OR  partitionIndex = 93 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.513705618 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 44:================================>                     (71 + 46) / 117][Stage 44:===================================>                  (76 + 41) / 117][Stage 44:============================================>         (96 + 21) / 117][Stage 44:====================================================> (114 + 3) / 117]                                                                                [Stage 45:================================>                     (72 + 46) / 118][Stage 45:====================================>                 (80 + 38) / 118][Stage 45:===========================================>          (96 + 22) / 118][Stage 45:====================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.169233575 seconds
res47: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide22"
dataSource: String = /nidan/orc/individualORC/slide22

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 63  OR  partitionIndex = 72  OR  pa rtitionIndex = 73  OR  partitionIndex = 88 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 63  OR  partitionIndex = 72  OR  partitionIndex = 73  OR  partitionIndex = 88 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide22;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 46:================================>                     (71 + 46) / 117][Stage 46:===================================>                  (77 + 40) / 117][Stage 46:===========================================>          (94 + 23) / 117][Stage 46:==================================================>   (109 + 8) / 117]                                                                                [Stage 47:=================================>                    (73 + 45) / 118][Stage 47:=====================================>                (83 + 35) / 118][Stage 47:=============================================>       (102 + 16) / 118][Stage 47:===================================================>  (113 + 5) / 118][Stage 47:=====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.328222827 seconds
res49: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide3"
dataSource: String = /nidan/orc/individualORC/slide3

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 87  OR  partitionIndex = 100  OR  p artitionIndex = 101  OR  partitionIndex = 116 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 87  OR  partitionIndex = 100  OR  partitionIndex = 101  OR  partitionIndex = 116 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.527129402 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 48:===========================>                          (61 + 60) / 121][Stage 48:=============================>                        (65 + 56) / 121][Stage 48:====================================>                 (82 + 39) / 121][Stage 48:============================================>        (101 + 20) / 121][Stage 48:=====================================================>(120 + 1) / 121]                                                                                [Stage 49:===========================>                          (63 + 59) / 122][Stage 49:==============================>                       (68 + 54) / 122][Stage 49:======================================>               (87 + 35) / 122][Stage 49:=============================================>       (105 + 17) / 122][Stage 49:=====================================================>(121 + 1) / 122]                                                                                Time elapsed: 3.406270179 seconds
res51: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide46"
dataSource: String = /nidan/orc/individualORC/slide46

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR   partitionIndex = 189  OR  partitionIndex = 190 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR  partitionIndex = 189  OR  partitionIndex = 190 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.453926485 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 50:==================================>                   (74 + 41) / 115][Stage 50:======================================>               (83 + 32) / 115][Stage 50:==============================================>       (98 + 17) / 115][Stage 50:===================================================>  (110 + 5) / 115][Stage 50:=====================================================>(114 + 1) / 115]                                                                                [Stage 51:===============================>                      (68 + 48) / 116][Stage 51:=======================================>              (84 + 32) / 116][Stage 51:==============================================>      (101 + 15) / 116][Stage 51:===================================================>  (110 + 6) / 116]                                                                                Time elapsed: 3.064421015 seconds
res53: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 39  OR  partitionIndex = 54  OR  pa rtitionIndex = 55  OR  partitionIndex = 64 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 39  OR  partitionIndex = 54  OR  partitionIndex = 55  OR  partitionIndex = 64 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 52:===============================>                      (68 + 47) / 115][Stage 52:=======================================>              (85 + 30) / 115][Stage 52:==============================================>       (98 + 17) / 115][Stage 52:====================================================> (112 + 3) / 115]                                                                                [Stage 53:=================================>                    (73 + 43) / 116][Stage 53:=====================================>                (80 + 36) / 116][Stage 53:============================================>         (96 + 20) / 116][Stage 53:================================================>    (106 + 10) / 116][Stage 53:====================================================> (112 + 4) / 116][Stage 53:=====================================================>(114 + 2) / 116][Stage 53:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 5.081515754 seconds
res55: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide61"
dataSource: String = /nidan/orc/individualORC/slide61

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 205  OR  partitionIndex = 206  OR   partitionIndex = 220  OR  partitionIndex = 221 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 205  OR  partitionIndex = 206  OR  partitionIndex = 220  OR  partitionIndex = 221 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.440203155 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 54:================================>                     (71 + 46) / 117][Stage 54:=================================>                    (72 + 45) / 117][Stage 54:=======================================>              (86 + 31) / 117][Stage 54:================================================>    (106 + 11) / 117][Stage 54:=====================================================>(116 + 1) / 117]                                                                                [Stage 55:================================>                     (72 + 46) / 118][Stage 55:===================================>                  (77 + 41) / 118][Stage 55:===========================================>          (94 + 24) / 118][Stage 55:==================================================>   (110 + 8) / 118]                                                                                Time elapsed: 3.18399537 seconds
res57: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide56"
dataSource: String = /nidan/orc/individualORC/slide56

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR   partitionIndex = 209  OR  partitionIndex = 210 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 195  OR  partitionIndex = 209  OR  partitionIndex = 210 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.567970962 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 56:==========================>                           (60 + 62) / 122][Stage 56:===========================>                          (63 + 59) / 122][Stage 56:===============================>                      (71 + 51) / 122][Stage 56:=========================================>            (93 + 29) / 122][Stage 56:==============================================>      (108 + 14) / 122]                                                                                [Stage 57:===========================>                          (63 + 60) / 123][Stage 57:================================>                     (75 + 48) / 123][Stage 57:===========================================>          (98 + 25) / 123][Stage 57:====================================================> (119 + 4) / 123]                                                                                Time elapsed: 3.160222658 seconds
res59: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide16"
dataSource: String = /nidan/orc/individualORC/slide16

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 218  OR  partitionIndex = 219  OR   partitionIndex = 232  OR  partitionIndex = 233 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 218  OR  partitionIndex = 219  OR  partitionIndex = 232  OR  partitionIndex = 233 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.45759471 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 58:===================================>                  (74 + 40) / 114][Stage 58:=========================================>            (87 + 27) / 114][Stage 58:============================================>         (94 + 20) / 114][Stage 58:==================================================>   (107 + 7) / 114][Stage 58:====================================================> (111 + 3) / 114][Stage 58:=====================================================>(113 + 1) / 114]                                                                                [Stage 59:======================================>               (81 + 34) / 115][Stage 59:===========================================>          (93 + 22) / 115][Stage 59:===============================================>     (104 + 11) / 115][Stage 59:=====================================================>(113 + 2) / 115][Stage 59:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.583402274 seconds
res61: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide82"
dataSource: String = /nidan/orc/individualORC/slide82

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 69  OR  pa rtitionIndex = 114  OR  partitionIndex = 115 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 69  OR  partitionIndex = 114  OR  partitionIndex = 115 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.421511505 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 60:================================>                     (71 + 46) / 117][Stage 60:=================================>                    (72 + 45) / 117][Stage 60:======================================>               (83 + 34) / 117][Stage 60:==============================================>      (102 + 15) / 117]                                                                                [Stage 61:================================>                     (72 + 46) / 118][Stage 61:====================================>                 (79 + 39) / 118][Stage 61:=============================================>        (99 + 19) / 118][Stage 61:====================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.039929621 seconds
res63: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide71"
dataSource: String = /nidan/orc/individualORC/slide71

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 40  OR  partitionIndex = 41  OR  pa rtitionIndex = 56  OR  partitionIndex = 57 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 40  OR  partitionIndex = 41  OR  partitionIndex = 56  OR  partitionIndex = 57 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide71;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 62:================================>                     (71 + 46) / 117][Stage 62:====================================>                 (80 + 37) / 117][Stage 62:==========================================>           (91 + 26) / 117][Stage 62:====================================================> (113 + 4) / 117]                                                                                [Stage 63:================================>                     (72 + 46) / 118][Stage 63:==================================>                   (76 + 42) / 118][Stage 63:==========================================>           (92 + 26) / 118][Stage 63:==================================================>   (111 + 7) / 118][Stage 63:=====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.031568132 seconds
res65: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR   partitionIndex = 152  OR  partitionIndex = 247 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR  partitionIndex = 152  OR  partitionIndex = 247 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 64:================================>                     (71 + 46) / 117][Stage 64:======================================>               (83 + 34) / 117][Stage 64:==============================================>      (102 + 15) / 117][Stage 64:===================================================>  (112 + 5) / 117]                                                                                [Stage 65:================================>                     (72 + 46) / 118][Stage 65:===================================>                  (77 + 41) / 118][Stage 65:==========================================>           (92 + 26) / 118][Stage 65:====================================================> (114 + 4) / 118][Stage 65:=====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.12951276 seconds
res67: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide50"
dataSource: String = /nidan/orc/individualORC/slide50

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 237  OR  partitionIndex = 238  OR   partitionIndex = 252  OR  partitionIndex = 253 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 237  OR  partitionIndex = 238  OR  partitionIndex = 252  OR  partitionIndex = 253 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide50;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 66:================================>                     (71 + 46) / 117][Stage 66:====================================>                 (79 + 38) / 117][Stage 66:==============================================>      (102 + 15) / 117][Stage 66:=====================================================>(116 + 1) / 117]                                                                                [Stage 67:=================================>                    (73 + 45) / 118][Stage 67:=====================================>                (82 + 36) / 118][Stage 67:================================================>    (107 + 11) / 118][Stage 67:=====================================================>(116 + 2) / 118][Stage 67:=====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.196325224 seconds
res69: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide78"
dataSource: String = /nidan/orc/individualORC/slide78

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR   partitionIndex = 214  OR  partitionIndex = 215 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR  partitionIndex = 214  OR  partitionIndex = 215 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide78;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 68:================================>                     (71 + 46) / 117][Stage 68:=======================================>              (85 + 32) / 117][Stage 68:===============================================>     (104 + 13) / 117]                                                                                [Stage 69:=================================>                    (73 + 45) / 118][Stage 69:=======================================>              (87 + 31) / 118][Stage 69:==============================================>      (103 + 15) / 118][Stage 69:====================================================> (115 + 3) / 118]                                                                                Time elapsed: 3.052888049 seconds
res71: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide5"
dataSource: String = /nidan/orc/individualORC/slide5

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 62  OR  partitionIndex = 63  OR  pa rtitionIndex = 72  OR  partitionIndex = 73 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 62  OR  partitionIndex = 63  OR  partitionIndex = 72  OR  partitionIndex = 73 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.434375324 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 70:================================>                     (71 + 46) / 117][Stage 70:==================================>                   (75 + 42) / 117][Stage 70:=========================================>            (89 + 28) / 117][Stage 70:================================================>    (107 + 10) / 117]                                                                                [Stage 71:=================================>                    (73 + 45) / 118][Stage 71:==================================>                   (75 + 43) / 118][Stage 71:==========================================>           (92 + 26) / 118][Stage 71:================================================>    (108 + 10) / 118]                                                                                Time elapsed: 3.123895405 seconds
res73: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide20"
dataSource: String = /nidan/orc/individualORC/slide20

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR   partitionIndex = 241  OR  partitionIndex = 242 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR  partitionIndex = 241  OR  partitionIndex = 242 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.368823767 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 72:=====================================>                (80 + 35) / 115][Stage 72:========================================>             (87 + 28) / 115][Stage 72:===========================================>          (93 + 22) / 115][Stage 72:=================================================>    (106 + 9) / 115][Stage 72:====================================================> (111 + 4) / 115]                                                                                [Stage 73:========================================>             (87 + 29) / 116][Stage 73:=============================================>        (97 + 19) / 116][Stage 73:===================================================>  (110 + 6) / 116][Stage 73:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.903403184 seconds
res75: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide85"
dataSource: String = /nidan/orc/individualORC/slide85

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 166  OR  partitionIndex = 167  OR   partitionIndex = 182  OR  partitionIndex = 183 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 166  OR  partitionIndex = 167  OR  partitionIndex = 182  OR  partitionIndex = 183 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide85;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 74:======================================>               (81 + 34) / 115][Stage 74:=========================================>            (89 + 26) / 115][Stage 74:===============================================>     (104 + 11) / 115][Stage 74:=====================================================>(113 + 2) / 115]                                                                                [Stage 75:========================================>             (86 + 30) / 116][Stage 75:==============================================>      (101 + 15) / 116][Stage 75:====================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.67621093 seconds
res77: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide44"
dataSource: String = /nidan/orc/individualORC/slide44

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR   partitionIndex = 120  OR  partitionIndex = 121 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR  partitionIndex = 120  OR  partitionIndex = 121 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.424420944 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 76:==================================>                   (73 + 41) / 114][Stage 76:=========================================>            (88 + 26) / 114][Stage 76:=============================================>        (95 + 19) / 114][Stage 76:================================================>    (104 + 10) / 114][Stage 76:=====================================================>(112 + 2) / 114]                                                                                [Stage 77:=====================================>                (79 + 36) / 115][Stage 77:==========================================>           (91 + 24) / 115][Stage 77:==============================================>      (101 + 14) / 115][Stage 77:====================================================> (111 + 4) / 115][Stage 77:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.11700364 seconds
res79: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide61"
dataSource: String = /nidan/orc/individualORC/slide61

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 43  OR  pa rtitionIndex = 58  OR  partitionIndex = 59 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 43  OR  partitionIndex = 58  OR  partitionIndex = 59 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.410792896 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 78:================================>                     (71 + 46) / 117][Stage 78:==================================>                   (75 + 42) / 117][Stage 78:============================================>         (97 + 20) / 117][Stage 78:====================================================> (114 + 3) / 117]                                                                                [Stage 79:================================>                     (72 + 46) / 118][Stage 79:===================================>                  (78 + 40) / 118][Stage 79:===========================================>          (95 + 23) / 118][Stage 79:================================================>    (108 + 10) / 118][Stage 79:=====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.349624429 seconds
res81: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide37"
dataSource: String = /nidan/orc/individualORC/slide37

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR   partitionIndex = 152  OR  partitionIndex = 153 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR  partitionIndex = 152  OR  partitionIndex = 153 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.401920966 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 80:========================================>             (85 + 29) / 114][Stage 80:=============================================>        (95 + 19) / 114][Stage 80:==================================================>   (106 + 8) / 114]                                                                                [Stage 81:======================================>               (82 + 33) / 115][Stage 81:==============================================>       (98 + 17) / 115][Stage 81:==================================================>   (107 + 8) / 115][Stage 81:=====================================================>(114 + 1) / 115]                                                                                Time elapsed: 2.704854866 seconds
res83: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide16"
dataSource: String = /nidan/orc/individualORC/slide16

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 192  OR  partitionIndex = 193  OR   partitionIndex = 208  OR  partitionIndex = 209 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 192  OR  partitionIndex = 193  OR  partitionIndex = 208  OR  partitionIndex = 209 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.398898782 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 82:====================================>                 (76 + 38) / 114][Stage 82:=========================================>            (87 + 27) / 114][Stage 82:============================================>         (93 + 21) / 114][Stage 82:================================================>    (104 + 10) / 114][Stage 82:====================================================> (111 + 3) / 114]                                                                                [Stage 83:======================================>               (82 + 33) / 115][Stage 83:==========================================>           (90 + 25) / 115][Stage 83:===============================================>     (103 + 12) / 115][Stage 83:====================================================> (111 + 4) / 115]                                                                                Time elapsed: 3.144023863 seconds
res85: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide88"
dataSource: String = /nidan/orc/individualORC/slide88

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 2  OR  partitionIndex = 3  OR  part itionIndex = 18  OR  partitionIndex = 19 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 2  OR  partitionIndex = 3  OR  partitionIndex = 18  OR  partitionIndex = 19 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.474756939 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 84:=================================>                    (72 + 43) / 115][Stage 84:=========================================>            (88 + 27) / 115][Stage 84:==============================================>      (100 + 15) / 115][Stage 84:=====================================================>(113 + 2) / 115]                                                                                [Stage 85:===============================>                      (68 + 48) / 116][Stage 85:====================================>                 (78 + 38) / 116][Stage 85:============================================>         (95 + 21) / 116][Stage 85:==================================================>   (109 + 7) / 116][Stage 85:=====================================================>(114 + 2) / 116]                                                                                Time elapsed: 4.969732154 seconds
res87: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide75"
dataSource: String = /nidan/orc/individualORC/slide75

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  pa rtitionIndex = 58  OR  partitionIndex = 59 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  partitionIndex = 58  OR  partitionIndex = 59 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.414760645 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 86:================================>                     (71 + 46) / 117][Stage 86:====================================>                 (79 + 38) / 117][Stage 86:==============================================>      (103 + 14) / 117][Stage 86:=====================================================>(115 + 2) / 117][Stage 86:=====================================================>(116 + 1) / 117]                                                                                [Stage 87:================================>                     (72 + 46) / 118][Stage 87:====================================>                 (80 + 38) / 118][Stage 87:==============================================>      (103 + 15) / 118][Stage 87:=====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.257090283 seconds
res89: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide3"
dataSource: String = /nidan/orc/individualORC/slide3

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 201  OR  partitionIndex = 202  OR   partitionIndex = 216  OR  partitionIndex = 217 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 201  OR  partitionIndex = 202  OR  partitionIndex = 216  OR  partitionIndex = 217 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.444010355 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 88:===========================>                          (62 + 59) / 121][Stage 88:=================================>                    (75 + 46) / 121][Stage 88:========================================>             (90 + 31) / 121][Stage 88:==================================================>   (114 + 7) / 121]                                                                                [Stage 89:============================>                         (64 + 58) / 122][Stage 89:=================================>                    (75 + 47) / 122][Stage 89:==========================================>           (95 + 27) / 122][Stage 89:===================================================>  (116 + 6) / 122]                                                                                Time elapsed: 3.242198902 seconds
res91: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide62"
dataSource: String = /nidan/orc/individualORC/slide62

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR   partitionIndex = 149  OR  partitionIndex = 150 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 134  OR  partitionIndex = 135  OR  partitionIndex = 149  OR  partitionIndex = 150 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.378085096 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 90:======================================>               (82 + 33) / 115][Stage 90:=============================================>        (97 + 18) / 115][Stage 90:===================================================>  (109 + 6) / 115]                                                                                [Stage 91:=======================================>              (84 + 32) / 116][Stage 91:============================================>         (96 + 20) / 116][Stage 91:===================================================>  (111 + 5) / 116][Stage 91:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.629183414 seconds
res93: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide28"
dataSource: String = /nidan/orc/individualORC/slide28

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 26  OR  partitionIndex = 27  OR  pa rtitionIndex = 40  OR  partitionIndex = 41 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 26  OR  partitionIndex = 27  OR  partitionIndex = 40  OR  partitionIndex = 41 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.470201761 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 92:===========================>                          (62 + 60) / 122][Stage 92:==================================>                   (77 + 45) / 122][Stage 92:=========================================>            (94 + 28) / 122][Stage 92:==================================================>   (113 + 9) / 122]                                                                                [Stage 93:===========================>                          (63 + 60) / 123][Stage 93:================================>                     (73 + 50) / 123][Stage 93:========================================>             (92 + 31) / 123][Stage 93:==============================================>      (108 + 15) / 123][Stage 93:====================================================> (120 + 3) / 123][Stage 93:=====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.449512846 seconds
res95: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide88"
dataSource: String = /nidan/orc/individualORC/slide88

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 99  OR  pa rtitionIndex = 114  OR  partitionIndex = 115 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 99  OR  partitionIndex = 114  OR  partitionIndex = 115 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.398906939 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 94:==============================>                       (66 + 49) / 115][Stage 94:===================================>                  (76 + 39) / 115][Stage 94:============================================>         (94 + 21) / 115][Stage 94:====================================================> (111 + 4) / 115][Stage 94:=====================================================>(114 + 1) / 115]                                                                                [Stage 95:===============================>                      (68 + 48) / 116][Stage 95:==================================>                   (75 + 41) / 116][Stage 95:============================================>         (95 + 21) / 116][Stage 95:==================================================>   (109 + 7) / 116][Stage 95:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.912235575 seconds
res97: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide45"
dataSource: String = /nidan/orc/individualORC/slide45

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 175  OR  partitionIndex = 190  OR   partitionIndex = 191  OR  partitionIndex = 200 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 175  OR  partitionIndex = 190  OR  partitionIndex = 191  OR  partitionIndex = 200 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.449272635 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 96:===========================>                          (62 + 59) / 121][Stage 96:================================>                     (73 + 48) / 121][Stage 96:==========================================>           (95 + 26) / 121][Stage 96:==================================================>   (114 + 7) / 121]                                                                                [Stage 97:===========================>                          (61 + 61) / 122][Stage 97:=============================>                        (67 + 55) / 122][Stage 97:========================================>             (91 + 31) / 122][Stage 97:==================================================>   (115 + 7) / 122][Stage 97:====================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.382676872 seconds
res99: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide13"
dataSource: String = /nidan/orc/individualORC/slide13

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 13  OR  partitionIndex = 14  OR  pa rtitionIndex = 28  OR  partitionIndex = 29 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 13  OR  partitionIndex = 14  OR  partitionIndex = 28  OR  partitionIndex = 29 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.362737593 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 98:======================================>               (82 + 33) / 115][Stage 98:===========================================>          (93 + 22) / 115][Stage 98:================================================>    (105 + 10) / 115][Stage 98:=====================================================>(114 + 1) / 115]                                                                                [Stage 99:======================================>               (83 + 33) / 116][Stage 99:========================================>             (88 + 28) / 116][Stage 99:==============================================>      (101 + 15) / 116][Stage 99:===================================================>  (110 + 6) / 116][Stage 99:=====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.938920923 seconds
res101: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide81"
dataSource: String = /nidan/orc/individualORC/slide81

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR   partitionIndex = 242  OR  partitionIndex = 243 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 226  OR  partitionIndex = 227  OR  partitionIndex = 242  OR  partitionIndex = 243 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.408978477 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 100:==================================>                  (75 + 40) / 115][Stage 100:========================================>            (87 + 28) / 115][Stage 100:=============================================>      (100 + 15) / 115][Stage 100:=================================================>   (108 + 7) / 115]                                                                                [Stage 101:===================================>                 (77 + 39) / 116][Stage 101:=========================================>           (91 + 25) / 116][Stage 101:=============================================>       (99 + 17) / 116][Stage 101:=================================================>   (109 + 7) / 116]                                                                                Time elapsed: 2.896295478 seconds
res103: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide29"
dataSource: String = /nidan/orc/individualORC/slide29

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR   partitionIndex = 121  OR  partitionIndex = 122 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 106  OR  partitionIndex = 107  OR  partitionIndex = 121  OR  partitionIndex = 122 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide29;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 102:==============================>                      (66 + 49) / 115][Stage 102:====================================>                (79 + 36) / 115][Stage 102:===========================================>         (95 + 20) / 115][Stage 102:=================================================>   (108 + 7) / 115][Stage 102:====================================================>(114 + 1) / 115]                                                                                [Stage 103:===============================>                     (68 + 48) / 116][Stage 103:=====================================>               (83 + 33) / 116][Stage 103:=============================================>       (99 + 17) / 116][Stage 103:==============================================>     (104 + 12) / 116][Stage 103:===================================================> (113 + 3) / 116]                                                                                Time elapsed: 2.942208476 seconds
res105: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide34"
dataSource: String = /nidan/orc/individualORC/slide34

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 102  OR  partitionIndex = 103  OR   partitionIndex = 116  OR  partitionIndex = 117 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 102  OR  partitionIndex = 103  OR  partitionIndex = 116  OR  partitionIndex = 117 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.351372762 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 104:=====================================>               (82 + 33) / 115][Stage 104:=========================================>           (90 + 25) / 115][Stage 104:=============================================>       (99 + 16) / 115][Stage 104:==================================================>  (110 + 5) / 115]                                                                                [Stage 105:======================================>              (85 + 31) / 116][Stage 105:==========================================>          (94 + 22) / 116][Stage 105:===============================================>    (106 + 10) / 116]                                                                                Time elapsed: 2.699049081 seconds
res107: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide30"
dataSource: String = /nidan/orc/individualORC/slide30

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 155  OR  partitionIndex = 168  OR   partitionIndex = 169  OR  partitionIndex = 184 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 155  OR  partitionIndex = 168  OR  partitionIndex = 169  OR  partitionIndex = 184 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.38030065 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 106:=================================>                   (72 + 42) / 114][Stage 106:=======================================>             (84 + 30) / 114][Stage 106:=============================================>       (98 + 16) / 114][Stage 106:==================================================>  (108 + 6) / 114][Stage 106:===================================================> (111 + 3) / 114]                                                                                [Stage 107:=================================>                   (72 + 43) / 115][Stage 107:=======================================>             (85 + 30) / 115][Stage 107:===========================================>         (95 + 20) / 115][Stage 107:==============================================>     (103 + 12) / 115][Stage 107:==================================================>  (110 + 5) / 115]                                                                                Time elapsed: 3.093988363 seconds
res109: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide70"
dataSource: String = /nidan/orc/individualORC/slide70

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 5  OR  partitionIndex = 6  OR  part itionIndex = 20  OR  partitionIndex = 21 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 5  OR  partitionIndex = 6  OR  partitionIndex = 20  OR  partitionIndex = 21 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.425167642 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 108:==========================>                          (60 + 62) / 122][Stage 108:===========================>                         (63 + 59) / 122][Stage 108:==================================>                  (79 + 43) / 122][Stage 108:===========================================>        (102 + 20) / 122][Stage 108:===================================================> (118 + 4) / 122]                                                                                [Stage 109:===========================>                         (63 + 60) / 123][Stage 109:=================================>                   (78 + 45) / 123][Stage 109:==========================================>         (100 + 23) / 123][Stage 109:=================================================>   (115 + 8) / 123][Stage 109:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.433031285 seconds
res111: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide59"
dataSource: String = /nidan/orc/individualORC/slide59

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR   partitionIndex = 158  OR  partitionIndex = 159 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 143  OR  partitionIndex = 158  OR  partitionIndex = 159 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.425837107 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 110:==========================>                          (61 + 60) / 121][Stage 110:============================>                        (64 + 57) / 121][Stage 110:===================================>                 (81 + 40) / 121][Stage 110:============================================>       (104 + 17) / 121][Stage 110:====================================================>(119 + 2) / 121]                                                                                [Stage 111:==========================>                          (62 + 60) / 122][Stage 111:=============================>                       (69 + 53) / 122][Stage 111:==================================>                  (80 + 42) / 122][Stage 111:============================================>       (105 + 17) / 122][Stage 111:====================================================>(120 + 2) / 122]                                                                                Time elapsed: 3.310153795 seconds
res113: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide35"
dataSource: String = /nidan/orc/individualORC/slide35

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 96  OR  partitionIndex = 97  OR  pa rtitionIndex = 112  OR  partitionIndex = 113 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 96  OR  partitionIndex = 97  OR  partitionIndex = 112  OR  partitionIndex = 113 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.419113973 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 112:==========================>                          (61 + 61) / 122][Stage 112:===========================>                         (63 + 59) / 122][Stage 112:=================================>                   (78 + 44) / 122][Stage 112:===========================================>         (99 + 23) / 122][Stage 112:===================================================> (118 + 4) / 122]                                                                                [Stage 113:==========================>                          (62 + 61) / 123][Stage 113:=============================>                       (68 + 55) / 123][Stage 113:==================================>                  (81 + 42) / 123][Stage 113:=============================================>      (108 + 15) / 123][Stage 113:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.113252063 seconds
res115: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide70"
dataSource: String = /nidan/orc/individualORC/slide70

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR   partitionIndex = 154  OR  partitionIndex = 155 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 139  OR  partitionIndex = 154  OR  partitionIndex = 155 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.423374467 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 114:==========================>                          (62 + 60) / 122][Stage 114:==============================>                      (71 + 51) / 122][Stage 114:======================================>              (89 + 33) / 122][Stage 114:==============================================>     (109 + 13) / 122][Stage 114:====================================================>(121 + 1) / 122]                                                                                [Stage 115:============================>                        (67 + 56) / 123][Stage 115:=====================================>               (86 + 37) / 123][Stage 115:==============================================>     (111 + 12) / 123][Stage 115:===================================================> (120 + 3) / 123]                                                                                Time elapsed: 3.371584069 seconds
res117: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide40"
dataSource: String = /nidan/orc/individualORC/slide40

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 90  OR  partitionIndex = 91  OR  pa rtitionIndex = 104  OR  partitionIndex = 105 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 90  OR  partitionIndex = 91  OR  partitionIndex = 104  OR  partitionIndex = 105 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.374945785 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 116:================================>                    (71 + 46) / 117][Stage 116:=================================>                   (75 + 42) / 117][Stage 116:=========================================>           (92 + 25) / 117][Stage 116:==============================================>     (104 + 13) / 117][Stage 116:====================================================>(115 + 2) / 117]                                                                                [Stage 117:================================>                    (72 + 46) / 118][Stage 117:================================>                    (73 + 45) / 118][Stage 117:=======================================>             (89 + 29) / 118][Stage 117:=============================================>      (104 + 14) / 118][Stage 117:==================================================>  (113 + 5) / 118]                                                                                Time elapsed: 3.462703181 seconds
res119: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide51"
dataSource: String = /nidan/orc/individualORC/slide51

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 103  OR  pa rtitionIndex = 118  OR  partitionIndex = 119 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 103  OR  partitionIndex = 118  OR  partitionIndex = 119 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.388112749 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 118:==================================>                  (75 + 39) / 114][Stage 118:========================================>            (88 + 26) / 114][Stage 118:=============================================>       (97 + 17) / 114][Stage 118:=================================================>   (107 + 7) / 114][Stage 118:====================================================>(113 + 1) / 114]                                                                                [Stage 119:========================================>            (87 + 28) / 115][Stage 119:============================================>        (97 + 18) / 115][Stage 119:==============================================>     (103 + 12) / 115][Stage 119:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.194570291 seconds
res121: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide52"
dataSource: String = /nidan/orc/individualORC/slide52

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 154  OR  partitionIndex = 155  OR   partitionIndex = 168  OR  partitionIndex = 169 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 154  OR  partitionIndex = 155  OR  partitionIndex = 168  OR  partitionIndex = 169 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.422899462 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 120:===========================>                         (63 + 58) / 121][Stage 120:===============================>                     (73 + 48) / 121][Stage 120:==========================================>          (98 + 23) / 121][Stage 120:==================================================>  (115 + 6) / 121]                                                                                [Stage 121:==========================>                          (62 + 60) / 122][Stage 121:============================>                        (66 + 56) / 122][Stage 121:======================================>              (88 + 34) / 122][Stage 121:=============================================>      (107 + 15) / 122][Stage 121:===================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.243201549 seconds
res123: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide46"
dataSource: String = /nidan/orc/individualORC/slide46

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 203  OR  partitionIndex = 218  OR   partitionIndex = 219  OR  partitionIndex = 232 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 203  OR  partitionIndex = 218  OR  partitionIndex = 219  OR  partitionIndex = 232 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.39090029 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 122:================================>                    (70 + 45) / 115][Stage 122:=========================================>           (91 + 24) / 115][Stage 122:==============================================>     (103 + 12) / 115][Stage 122:===================================================> (111 + 4) / 115]                                                                                [Stage 123:=================================>                   (74 + 42) / 116][Stage 123:=====================================>               (81 + 35) / 116][Stage 123:===========================================>         (95 + 21) / 116][Stage 123:=================================================>   (108 + 8) / 116]                                                                                Time elapsed: 2.931866921 seconds
res125: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide66"
dataSource: String = /nidan/orc/individualORC/slide66

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 129  OR  partitionIndex = 130  OR   partitionIndex = 144  OR  partitionIndex = 145 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 129  OR  partitionIndex = 130  OR  partitionIndex = 144  OR  partitionIndex = 145 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.489372063 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 124:==========================>                          (61 + 60) / 121][Stage 124:==============================>                      (70 + 51) / 121][Stage 124:========================================>            (92 + 29) / 121][Stage 124:==================================================>  (116 + 5) / 121]                                                                                [Stage 125:============================>                        (65 + 57) / 122][Stage 125:==================================>                  (79 + 43) / 122][Stage 125:==========================================>         (100 + 22) / 122][Stage 125:====================================================>(120 + 2) / 122]                                                                                Time elapsed: 3.029981408 seconds
res127: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide13"
dataSource: String = /nidan/orc/individualORC/slide13

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  part itionIndex = 118  OR  partitionIndex = 119 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  partitionIndex = 118  OR  partitionIndex = 119 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.342838671 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 126:======================================>              (84 + 31) / 115][Stage 126:==============================================>     (102 + 13) / 115][Stage 126:====================================================>(114 + 1) / 115]                                                                                [Stage 127:=====================================>               (83 + 33) / 116][Stage 127:==========================================>          (92 + 24) / 116][Stage 127:================================================>    (107 + 9) / 116][Stage 127:===================================================> (113 + 3) / 116][Stage 127:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.298784374 seconds
res129: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide22"
dataSource: String = /nidan/orc/individualORC/slide22

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR   partitionIndex = 144  OR  partitionIndex = 145 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR  partitionIndex = 144  OR  partitionIndex = 145 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide22;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 128:>                                                      (0 + 0) / 115][Stage 128:=====================================>               (82 + 33) / 115][Stage 128:=========================================>           (90 + 25) / 115][Stage 128:==================================================>  (110 + 5) / 115][Stage 128:====================================================>(113 + 2) / 115]                                                                                [Stage 129:=====================================>               (82 + 34) / 116][Stage 129:=======================================>             (86 + 30) / 116][Stage 129:=============================================>      (101 + 15) / 116][Stage 129:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.581485501 seconds
res131: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide70"
dataSource: String = /nidan/orc/individualORC/slide70

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 1  OR  partitionIndex = 2  OR  part itionIndex = 16  OR  partitionIndex = 17 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 1  OR  partitionIndex = 2  OR  partitionIndex = 16  OR  partitionIndex = 17 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.418971608 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 130:==========================>                          (60 + 62) / 122][Stage 130:===========================>                         (63 + 59) / 122][Stage 130:=================================>                   (76 + 46) / 122][Stage 130:========================================>            (94 + 28) / 122][Stage 130:===================================================> (118 + 4) / 122]                                                                                [Stage 131:==========================>                          (61 + 62) / 123][Stage 131:===========================>                         (64 + 59) / 123][Stage 131:====================================>                (84 + 39) / 123][Stage 131:==============================================>     (111 + 12) / 123][Stage 131:===================================================> (119 + 4) / 123]                                                                                Time elapsed: 3.877118746 seconds
res133: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide16"
dataSource: String = /nidan/orc/individualORC/slide16

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR   partitionIndex = 221  OR  partitionIndex = 222 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 206  OR  partitionIndex = 207  OR  partitionIndex = 221  OR  partitionIndex = 222 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.373266329 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 132:====================================>                (79 + 35) / 114][Stage 132:========================================>            (88 + 26) / 114][Stage 132:============================================>        (95 + 19) / 114][Stage 132:===============================================>    (104 + 10) / 114][Stage 132:====================================================>(113 + 1) / 114]                                                                                [Stage 133:==================================>                  (75 + 40) / 115][Stage 133:=======================================>             (85 + 30) / 115][Stage 133:=========================================>           (90 + 25) / 115][Stage 133:=============================================>       (99 + 16) / 115][Stage 133:==================================================>  (110 + 5) / 115]                                                                                Time elapsed: 3.253080324 seconds
res135: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide63"
dataSource: String = /nidan/orc/individualORC/slide63

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR   partitionIndex = 145  OR  partitionIndex = 146 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 131  OR  partitionIndex = 145  OR  partitionIndex = 146 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.43091028 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 134:==========================>                          (60 + 62) / 122][Stage 134:===============================>                     (72 + 50) / 122][Stage 134:=====================================>               (87 + 35) / 122][Stage 134:===============================================>    (111 + 11) / 122]                                                                                [Stage 135:===========================>                         (64 + 59) / 123][Stage 135:==============================>                      (71 + 52) / 123][Stage 135:======================================>              (90 + 33) / 123][Stage 135:==============================================>     (110 + 13) / 123][Stage 135:===================================================> (120 + 3) / 123]                                                                                Time elapsed: 3.352001037 seconds
res137: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide11"
dataSource: String = /nidan/orc/individualORC/slide11

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 69  OR  pa rtitionIndex = 84  OR  partitionIndex = 115 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 69  OR  partitionIndex = 84  OR  partitionIndex = 115 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.449233684 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 136:===================================>                 (76 + 39) / 115][Stage 136:==========================================>          (92 + 23) / 115][Stage 136:==============================================>     (103 + 12) / 115][Stage 136:====================================================>(114 + 1) / 115]                                                                                [Stage 137:==================================>                  (76 + 40) / 116][Stage 137:=========================================>           (91 + 25) / 116][Stage 137:================================================>    (107 + 9) / 116][Stage 137:====================================================>(114 + 2) / 116][Stage 137:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.042166982 seconds
res139: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide89"
dataSource: String = /nidan/orc/individualORC/slide89

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 147  OR  partitionIndex = 160  OR   partitionIndex = 161  OR  partitionIndex = 176 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 147  OR  partitionIndex = 160  OR  partitionIndex = 161  OR  partitionIndex = 176 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.378451708 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 138:================================>                    (71 + 46) / 117][Stage 138:===================================>                 (78 + 39) / 117][Stage 138:==========================================>          (94 + 23) / 117][Stage 138:==================================================>  (111 + 6) / 117]                                                                                [Stage 139:=================================>                   (74 + 44) / 118][Stage 139:=====================================>               (84 + 34) / 118][Stage 139:=============================================>      (103 + 15) / 118][Stage 139:====================================================>(116 + 2) / 118]                                                                                Time elapsed: 2.929209793 seconds
res141: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide52"
dataSource: String = /nidan/orc/individualORC/slide52

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 31  OR  partitionIndex = 44  OR  pa rtitionIndex = 45  OR  partitionIndex = 60 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 31  OR  partitionIndex = 44  OR  partitionIndex = 45  OR  partitionIndex = 60 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.409524952 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 140:==========================>                          (61 + 60) / 121][Stage 140:=============================>                       (67 + 54) / 121][Stage 140:=======================================>             (90 + 31) / 121][Stage 140:===============================================>    (110 + 11) / 121][Stage 140:====================================================>(119 + 2) / 121]                                                                                [Stage 141:==========================>                          (62 + 60) / 122][Stage 141:==============================>                      (70 + 52) / 122][Stage 141:=======================================>             (92 + 30) / 122][Stage 141:===============================================>    (112 + 10) / 122][Stage 141:===================================================> (119 + 3) / 122]                                                                                Time elapsed: 3.25697264 seconds
res143: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide19"
dataSource: String = /nidan/orc/individualORC/slide19

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 160  OR  partitionIndex = 161  OR   partitionIndex = 176  OR  partitionIndex = 177 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 160  OR  partitionIndex = 161  OR  partitionIndex = 176  OR  partitionIndex = 177 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.363878153 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 142:================================>                    (71 + 46) / 117][Stage 142:===================================>                 (78 + 39) / 117][Stage 142:===========================================>         (95 + 22) / 117][Stage 142:=================================================>   (109 + 8) / 117][Stage 142:====================================================>(116 + 1) / 117]                                                                                [Stage 143:================================>                    (72 + 46) / 118][Stage 143:==================================>                  (77 + 41) / 118][Stage 143:============================================>        (99 + 19) / 118][Stage 143:=================================================>   (110 + 8) / 118][Stage 143:===================================================> (114 + 4) / 118][Stage 143:====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.567781192 seconds
res145: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide56"
dataSource: String = /nidan/orc/individualORC/slide56

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR   partitionIndex = 152  OR  partitionIndex = 153 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 136  OR  partitionIndex = 137  OR  partitionIndex = 152  OR  partitionIndex = 153 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.400783862 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 144:===========================>                         (63 + 59) / 122][Stage 144:=============================>                       (69 + 53) / 122][Stage 144:==================================>                  (80 + 42) / 122][Stage 144:============================================>       (105 + 17) / 122][Stage 144:===================================================> (119 + 3) / 122]                                                                                [Stage 145:===========================>                         (64 + 59) / 123][Stage 145:================================>                    (76 + 47) / 123][Stage 145:========================================>            (95 + 28) / 123][Stage 145:==================================================>  (117 + 6) / 123][Stage 145:====================================================>(122 + 1) / 123]                                                                                Time elapsed: 3.534295846 seconds
res147: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide84"
dataSource: String = /nidan/orc/individualORC/slide84

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  part itionIndex = 22  OR  partitionIndex = 23 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  partitionIndex = 22  OR  partitionIndex = 23 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.40316526 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 146:==========================>                          (61 + 61) / 122][Stage 146:==============================>                      (71 + 51) / 122][Stage 146:======================================>              (89 + 33) / 122][Stage 146:===============================================>    (111 + 11) / 122][Stage 146:====================================================>(121 + 1) / 122]                                                                                [Stage 147:==========================>                          (62 + 61) / 123][Stage 147:=============================>                       (69 + 54) / 123][Stage 147:====================================>                (85 + 38) / 123][Stage 147:==============================================>     (110 + 13) / 123]                                                                                Time elapsed: 3.240437558 seconds
res149: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide82"
dataSource: String = /nidan/orc/individualORC/slide82

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 23  OR  partitionIndex = 36  OR  pa rtitionIndex = 37  OR  partitionIndex = 52 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 23  OR  partitionIndex = 36  OR  partitionIndex = 37  OR  partitionIndex = 52 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.361632954 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 148:=================================>                   (73 + 44) / 117][Stage 148:======================================>              (84 + 33) / 117][Stage 148:================================================>    (108 + 9) / 117][Stage 148:====================================================>(116 + 1) / 117]                                                                                [Stage 149:================================>                    (72 + 46) / 118][Stage 149:==================================>                  (76 + 42) / 118][Stage 149:===========================================>         (96 + 22) / 118][Stage 149:================================================>    (109 + 9) / 118]                                                                                Time elapsed: 2.950514502 seconds
res151: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide36"
dataSource: String = /nidan/orc/individualORC/slide36

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 210  OR  partitionIndex = 211  OR   partitionIndex = 224  OR  partitionIndex = 225 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 210  OR  partitionIndex = 211  OR  partitionIndex = 224  OR  partitionIndex = 225 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide36;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 150:================================>                    (71 + 46) / 117][Stage 150:=================================>                   (74 + 43) / 117][Stage 150:============================================>        (98 + 19) / 117][Stage 150:====================================================>(115 + 2) / 117]                                                                                [Stage 151:=================================>                   (74 + 44) / 118][Stage 151:=====================================>               (83 + 35) / 118][Stage 151:============================================>       (101 + 17) / 118][Stage 151:===================================================> (114 + 4) / 118]                                                                                Time elapsed: 2.93654505 seconds
res153: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide71"
dataSource: String = /nidan/orc/individualORC/slide71

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 214  OR  partitionIndex = 215  OR   partitionIndex = 228  OR  partitionIndex = 229 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 214  OR  partitionIndex = 215  OR  partitionIndex = 228  OR  partitionIndex = 229 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide71;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 152:================================>                    (72 + 45) / 117][Stage 152:=====================================>               (82 + 35) / 117][Stage 152:============================================>        (99 + 18) / 117][Stage 152:===================================================> (113 + 4) / 117]                                                                                [Stage 153:================================>                    (72 + 46) / 118][Stage 153:==================================>                  (77 + 41) / 118][Stage 153:==========================================>          (95 + 23) / 118][Stage 153:===================================================> (114 + 4) / 118]                                                                                Time elapsed: 3.21905334 seconds
res155: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide30"
dataSource: String = /nidan/orc/individualORC/slide30

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 229  OR  partitionIndex = 230  OR   partitionIndex = 244  OR  partitionIndex = 245 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 229  OR  partitionIndex = 230  OR  partitionIndex = 244  OR  partitionIndex = 245 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.352978785 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 154:====================================>                (78 + 36) / 114][Stage 154:==========================================>          (92 + 22) / 114][Stage 154:==============================================>     (102 + 12) / 114][Stage 154:=================================================>   (107 + 7) / 114][Stage 154:====================================================>(112 + 2) / 114]                                                                                [Stage 155:=================================>                   (73 + 42) / 115][Stage 155:========================================>            (87 + 28) / 115][Stage 155:=============================================>      (100 + 15) / 115][Stage 155:================================================>    (106 + 9) / 115][Stage 155:====================================================>(113 + 2) / 115][Stage 155:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.207910209 seconds
res157: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide22"
dataSource: String = /nidan/orc/individualORC/slide22

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 193  OR  partitionIndex = 194  OR   partitionIndex = 208  OR  partitionIndex = 209 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 193  OR  partitionIndex = 194  OR  partitionIndex = 208  OR  partitionIndex = 209 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide22;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 156:===================================>                 (77 + 37) / 114][Stage 156:==========================================>          (92 + 22) / 114][Stage 156:==============================================>     (101 + 13) / 114][Stage 156:=================================================>   (107 + 7) / 114][Stage 156:===================================================> (111 + 3) / 114]                                                                                [Stage 157:=====================================>               (81 + 34) / 115][Stage 157:=============================================>       (99 + 16) / 115][Stage 157:==============================================>     (103 + 12) / 115][Stage 157:=================================================>   (108 + 7) / 115][Stage 157:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.294172681 seconds
res159: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide81"
dataSource: String = /nidan/orc/individualORC/slide81

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 137  OR  partitionIndex = 138  OR   partitionIndex = 152  OR  partitionIndex = 153 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 137  OR  partitionIndex = 138  OR  partitionIndex = 152  OR  partitionIndex = 153 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.371270947 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 158:=================================>                   (72 + 43) / 115][Stage 158:======================================>              (84 + 31) / 115][Stage 158:=============================================>      (100 + 15) / 115][Stage 158:===================================================> (112 + 3) / 115]                                                                                [Stage 159:================================>                    (72 + 44) / 116][Stage 159:======================================>              (85 + 31) / 116][Stage 159:===========================================>         (95 + 21) / 116][Stage 159:==================================================>  (110 + 6) / 116]                                                                                Time elapsed: 2.690115707 seconds
res161: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide81"
dataSource: String = /nidan/orc/individualORC/slide81

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  part itionIndex = 24  OR  partitionIndex = 25 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9  OR  partitionIndex = 24  OR  partitionIndex = 25 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.375803062 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 160:==================================>                  (74 + 41) / 115][Stage 160:=======================================>             (86 + 29) / 115][Stage 160:=============================================>       (98 + 17) / 115][Stage 160:===============================================>    (105 + 10) / 115][Stage 160:===================================================> (112 + 3) / 115]                                                                                [Stage 161:=================================>                   (74 + 42) / 116][Stage 161:======================================>              (85 + 31) / 116][Stage 161:============================================>        (97 + 19) / 116][Stage 161:===============================================>    (105 + 11) / 116][Stage 161:====================================================>(114 + 2) / 116][Stage 161:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.256320888 seconds
res163: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide50"
dataSource: String = /nidan/orc/individualORC/slide50

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 211  OR  partitionIndex = 224  OR   partitionIndex = 225  OR  partitionIndex = 240 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 211  OR  partitionIndex = 224  OR  partitionIndex = 225  OR  partitionIndex = 240 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide50;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 162:=================================>                   (72 + 43) / 115][Stage 162:=======================================>             (86 + 29) / 115][Stage 162:=============================================>       (99 + 16) / 115][Stage 162:=================================================>   (107 + 8) / 115]                                                                                [Stage 163:==================================>                  (75 + 41) / 116][Stage 163:=======================================>             (86 + 30) / 116][Stage 163:==========================================>          (94 + 22) / 116][Stage 163:===============================================>    (106 + 10) / 116][Stage 163:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 2.989165641 seconds
res165: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide33"
dataSource: String = /nidan/orc/individualORC/slide33

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR   partitionIndex = 176  OR  partitionIndex = 177 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 162  OR  partitionIndex = 163  OR  partitionIndex = 176  OR  partitionIndex = 177 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.373781066 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 164:================================>                    (71 + 46) / 117][Stage 164:================================>                    (72 + 45) / 117][Stage 164:=====================================>               (83 + 34) / 117][Stage 164:===========================================>         (95 + 22) / 117][Stage 164:==============================================>     (104 + 13) / 117]                                                                                [Stage 165:================================>                    (72 + 46) / 118][Stage 165:===================================>                 (80 + 38) / 118][Stage 165:=======================================>             (89 + 29) / 118][Stage 165:=================================================>   (110 + 8) / 118][Stage 165:====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.34070863 seconds
res167: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide74"
dataSource: String = /nidan/orc/individualORC/slide74

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR   partitionIndex = 190  OR  partitionIndex = 191 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 174  OR  partitionIndex = 175  OR  partitionIndex = 190  OR  partitionIndex = 191 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.37173971 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 166:==============================>                      (66 + 49) / 115][Stage 166:======================================>              (83 + 32) / 115][Stage 166:=============================================>      (101 + 14) / 115][Stage 166:==================================================>  (110 + 5) / 115][Stage 166:====================================================>(114 + 1) / 115]                                                                                [Stage 167:================================>                    (72 + 44) / 116][Stage 167:======================================>              (84 + 32) / 116][Stage 167:============================================>       (100 + 16) / 116][Stage 167:=================================================>   (109 + 7) / 116][Stage 167:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 2.985110804 seconds
res169: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide20"
dataSource: String = /nidan/orc/individualORC/slide20

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 41  OR  partitionIndex = 42  OR  pa rtitionIndex = 56  OR  partitionIndex = 57 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 41  OR  partitionIndex = 42  OR  partitionIndex = 56  OR  partitionIndex = 57 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.345162262 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 168:=====================================>               (81 + 34) / 115][Stage 168:=======================================>             (86 + 29) / 115][Stage 168:============================================>        (96 + 19) / 115][Stage 168:=================================================>   (108 + 7) / 115]                                                                                [Stage 169:======================================>              (84 + 32) / 116][Stage 169:=========================================>           (90 + 26) / 116][Stage 169:=============================================>      (102 + 14) / 116][Stage 169:================================================>    (107 + 9) / 116][Stage 169:===================================================> (113 + 3) / 116][Stage 169:====================================================>(114 + 2) / 116]                                                                                Time elapsed: 3.646492315 seconds
res171: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide11"
dataSource: String = /nidan/orc/individualORC/slide11

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 10  OR  partitionIndex = 11  OR  pa rtitionIndex = 26  OR  partitionIndex = 27 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 10  OR  partitionIndex = 11  OR  partitionIndex = 26  OR  partitionIndex = 27 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.37441831 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 170:=====================================>               (81 + 34) / 115][Stage 170:=========================================>           (89 + 26) / 115][Stage 170:================================================>    (106 + 9) / 115]                                                                                [Stage 171:================================>                    (72 + 44) / 116][Stage 171:=======================================>             (87 + 29) / 116][Stage 171:==========================================>          (92 + 24) / 116][Stage 171:=================================================>   (109 + 7) / 116][Stage 171:===================================================> (113 + 3) / 116][Stage 171:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.424971802 seconds
res173: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide17"
dataSource: String = /nidan/orc/individualORC/slide17

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR   partitionIndex = 212  OR  partitionIndex = 213 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 199  OR  partitionIndex = 212  OR  partitionIndex = 213 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.405960456 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 172:===========================>                         (63 + 58) / 121][Stage 172:================================>                    (75 + 46) / 121][Stage 172:============================================>       (103 + 18) / 121][Stage 172:====================================================>(119 + 2) / 121]                                                                                [Stage 173:===========================>                         (64 + 58) / 122][Stage 173:===================================>                 (81 + 41) / 122][Stage 173:===========================================>        (102 + 20) / 122]                                                                                Time elapsed: 3.124843226 seconds
res175: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide47"
dataSource: String = /nidan/orc/individualORC/slide47

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 224  OR  partitionIndex = 225  OR   partitionIndex = 240  OR  partitionIndex = 241 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 224  OR  partitionIndex = 225  OR  partitionIndex = 240  OR  partitionIndex = 241 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.376625966 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 174:================================>                    (72 + 45) / 117][Stage 174:======================================>              (84 + 33) / 117][Stage 174:============================================>       (100 + 17) / 117][Stage 174:=================================================>   (110 + 7) / 117][Stage 174:====================================================>(116 + 1) / 117]                                                                                [Stage 175:=================================>                   (74 + 44) / 118][Stage 175:=====================================>               (84 + 34) / 118][Stage 175:============================================>        (99 + 19) / 118][Stage 175:==================================================>  (113 + 5) / 118][Stage 175:====================================================>(117 + 1) / 118]                                                                                Time elapsed: 3.543534917 seconds
res177: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide36"
dataSource: String = /nidan/orc/individualORC/slide36

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 109  OR  partitionIndex = 110  OR   partitionIndex = 124  OR  partitionIndex = 125 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 109  OR  partitionIndex = 110  OR  partitionIndex = 124  OR  partitionIndex = 125 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide36;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 176:================================>                    (71 + 46) / 117][Stage 176:=================================>                   (74 + 43) / 117][Stage 176:==========================================>          (94 + 23) / 117][Stage 176:==================================================>  (112 + 5) / 117][Stage 176:====================================================>(116 + 1) / 117]                                                                                [Stage 177:================================>                    (72 + 46) / 118][Stage 177:==================================>                  (76 + 42) / 118][Stage 177:=======================================>             (87 + 31) / 118][Stage 177:============================================>       (102 + 16) / 118][Stage 177:==================================================>  (112 + 6) / 118][Stage 177:====================================================>(116 + 2) / 118]                                                                                Time elapsed: 3.375415498 seconds
res179: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide3"
dataSource: String = /nidan/orc/individualORC/slide3

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 94  OR  partitionIndex = 95  OR  pa rtitionIndex = 108  OR  partitionIndex = 109 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 94  OR  partitionIndex = 95  OR  partitionIndex = 108  OR  partitionIndex = 109 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.398153773 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 178:==========================>                          (61 + 60) / 121][Stage 178:============================>                        (66 + 55) / 121][Stage 178:=================================>                   (77 + 44) / 121][Stage 178:==========================================>          (97 + 24) / 121][Stage 178:==================================================>  (116 + 5) / 121]                                                                                [Stage 179:===========================>                         (64 + 58) / 122][Stage 179:=================================>                   (77 + 45) / 122][Stage 179:=========================================>           (95 + 27) / 122][Stage 179:==============================================>     (109 + 13) / 122][Stage 179:====================================================>(120 + 2) / 122]                                                                                Time elapsed: 3.296133374 seconds
res181: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide55"
dataSource: String = /nidan/orc/individualORC/slide55

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 64  OR  partitionIndex = 65  OR  pa rtitionIndex = 80  OR  partitionIndex = 81 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 64  OR  partitionIndex = 65  OR  partitionIndex = 80  OR  partitionIndex = 81 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.337260897 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 180:=====================================>               (82 + 33) / 115][Stage 180:=========================================>           (89 + 26) / 115][Stage 180:===============================================>    (104 + 11) / 115][Stage 180:==================================================>  (110 + 5) / 115]                                                                                [Stage 181:======================================>              (84 + 32) / 116][Stage 181:===========================================>         (95 + 21) / 116][Stage 181:==============================================>     (104 + 12) / 116][Stage 181:===================================================> (112 + 4) / 116][Stage 181:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.174218697 seconds
res183: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide56"
dataSource: String = /nidan/orc/individualORC/slide56

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 9  OR  partitionIndex = 10  OR  par titionIndex = 24  OR  partitionIndex = 25 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 9  OR  partitionIndex = 10  OR  partitionIndex = 24  OR  partitionIndex = 25 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.397753029 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 182:==========================>                          (60 + 62) / 122][Stage 182:=============================>                       (67 + 55) / 122][Stage 182:===================================>                 (82 + 40) / 122][Stage 182:=============================================>      (107 + 15) / 122][Stage 182:====================================================>(120 + 2) / 122]                                                                                [Stage 183:============================>                        (66 + 57) / 123][Stage 183:===================================>                 (82 + 41) / 123][Stage 183:==========================================>          (99 + 24) / 123][Stage 183:=================================================>   (115 + 8) / 123]                                                                                Time elapsed: 3.217791815 seconds
res185: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide6"
dataSource: String = /nidan/orc/individualORC/slide6

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 22  OR  partitionIndex = 23  OR  pa rtitionIndex = 36  OR  partitionIndex = 37 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 22  OR  partitionIndex = 23  OR  partitionIndex = 36  OR  partitionIndex = 37 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.332911803 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 184:=====================================>               (81 + 34) / 115][Stage 184:========================================>            (88 + 27) / 115][Stage 184:===============================================>    (104 + 11) / 115]                                                                                [Stage 185:=====================================>               (82 + 34) / 116][Stage 185:==========================================>          (94 + 22) / 116][Stage 185:================================================>    (107 + 9) / 116][Stage 185:==================================================>  (110 + 6) / 116][Stage 185:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.93931435 seconds
res187: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide48"
dataSource: String = /nidan/orc/individualORC/slide48

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  part itionIndex = 21  OR  partitionIndex = 22 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 6  OR  partitionIndex = 7  OR  partitionIndex = 21  OR  partitionIndex = 22 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.340251679 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 186:====================================>                (80 + 35) / 115][Stage 186:=======================================>             (86 + 29) / 115][Stage 186:===========================================>         (94 + 21) / 115][Stage 186:===============================================>    (105 + 10) / 115][Stage 186:====================================================>(113 + 2) / 115]                                                                                [Stage 187:=====================================>               (81 + 35) / 116][Stage 187:=========================================>           (90 + 26) / 116][Stage 187:=============================================>      (102 + 14) / 116][Stage 187:==================================================>  (110 + 6) / 116][Stage 187:====================================================>(114 + 2) / 116][Stage 187:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 3.864809422 seconds
res189: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide2"
dataSource: String = /nidan/orc/individualORC/slide2

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR   partitionIndex = 126  OR  partitionIndex = 127 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 110  OR  partitionIndex = 111  OR  partitionIndex = 126  OR  partitionIndex = 127 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.357368373 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 188:=================================>                   (73 + 41) / 114][Stage 188:======================================>              (82 + 32) / 114][Stage 188:=============================================>      (100 + 14) / 114][Stage 188:==================================================>  (108 + 6) / 114][Stage 188:===================================================> (111 + 3) / 114]                                                                                [Stage 189:====================================>                (79 + 36) / 115][Stage 189:========================================>            (87 + 28) / 115][Stage 189:=============================================>       (98 + 17) / 115][Stage 189:=================================================>   (108 + 7) / 115][Stage 189:===================================================> (112 + 3) / 115]                                                                                Time elapsed: 3.091033072 seconds
res191: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide29"
dataSource: String = /nidan/orc/individualORC/slide29

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 225  OR  partitionIndex = 226  OR   partitionIndex = 240  OR  partitionIndex = 241 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 225  OR  partitionIndex = 226  OR  partitionIndex = 240  OR  partitionIndex = 241 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide29;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 190:===================================>                 (77 + 37) / 114][Stage 190:=========================================>           (89 + 25) / 114][Stage 190:==============================================>      (99 + 15) / 114][Stage 190:==================================================>  (108 + 6) / 114][Stage 190:====================================================>(112 + 2) / 114][Stage 190:====================================================>(113 + 1) / 114]                                                                                [Stage 191:==================================>                  (74 + 41) / 115][Stage 191:========================================>            (88 + 27) / 115][Stage 191:=============================================>      (100 + 15) / 115][Stage 191:=================================================>   (107 + 8) / 115][Stage 191:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.193194987 seconds
res193: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide43"
dataSource: String = /nidan/orc/individualORC/slide43

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 202  OR  partitionIndex = 203  OR   partitionIndex = 217  OR  partitionIndex = 218 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 202  OR  partitionIndex = 203  OR  partitionIndex = 217  OR  partitionIndex = 218 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
org.apache.spark.sql.AnalysisException: Path does not exist: hdfs://ctl:9000/nidan/orc/individualORC/slide43;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:382)
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:370)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
  at scala.collection.immutable.List.flatMap(List.scala:344)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:152)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:464)
  at org.apache.spark.sql.DataFrameReader.orc(DataFrameReader.scala:453)
  at $anonfun$1.apply$mcV$sp(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at $anonfun$1.apply(<console>:36)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 192:===================================>                 (77 + 37) / 114][Stage 192:===========================================>         (93 + 21) / 114][Stage 192:==============================================>     (102 + 12) / 114][Stage 192:==================================================>  (109 + 5) / 114]                                                                                [Stage 193:====================================>                (80 + 35) / 115][Stage 193:============================================>        (96 + 19) / 115][Stage 193:=================================================>   (107 + 8) / 115][Stage 193:==================================================>  (109 + 6) / 115][Stage 193:====================================================>(113 + 2) / 115]                                                                                Time elapsed: 3.103446483 seconds
res195: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide3"
dataSource: String = /nidan/orc/individualORC/slide3

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  pa rtitionIndex = 56  OR  partitionIndex = 57 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  partitionIndex = 56  OR  partitionIndex = 57 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.490192829 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 194:==========================>                          (61 + 60) / 121][Stage 194:==============================>                      (69 + 52) / 121][Stage 194:======================================>              (87 + 34) / 121][Stage 194:=============================================>      (107 + 14) / 121][Stage 194:===================================================> (117 + 4) / 121]                                                                                [Stage 195:==========================>                          (61 + 61) / 122][Stage 195:============================>                        (66 + 56) / 122][Stage 195:======================================>              (88 + 34) / 122][Stage 195:==============================================>     (109 + 13) / 122][Stage 195:==================================================>  (117 + 5) / 122]                                                                                Time elapsed: 3.329220122 seconds
res197: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide34"
dataSource: String = /nidan/orc/individualORC/slide34

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  pa rtitionIndex = 30  OR  partitionIndex = 31 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15  OR  partitionIndex = 30  OR  partitionIndex = 31 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.338205221 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 196:=======================================>             (85 + 30) / 115][Stage 196:===========================================>         (94 + 21) / 115][Stage 196:==============================================>     (102 + 13) / 115][Stage 196:==================================================>  (110 + 5) / 115][Stage 196:====================================================>(113 + 2) / 115]                                                                                [Stage 197:=====================================>               (82 + 34) / 116][Stage 197:=========================================>           (90 + 26) / 116][Stage 197:============================================>        (98 + 18) / 116][Stage 197:==================================================>  (110 + 6) / 116][Stage 197:====================================================>(114 + 2) / 116][Stage 197:====================================================>(115 + 1) / 116]                                                                                Time elapsed: 4.378434352 seconds
res199: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide9"
dataSource: String = /nidan/orc/individualORC/slide9

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 199  OR  partitionIndex = 214  OR   partitionIndex = 215  OR  partitionIndex = 228 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 199  OR  partitionIndex = 214  OR  partitionIndex = 215  OR  partitionIndex = 228 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.377329006 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 198:=================================>                   (71 + 43) / 114][Stage 198:=======================================>             (85 + 29) / 114][Stage 198:=============================================>      (100 + 14) / 114][Stage 198:==================================================>  (108 + 6) / 114][Stage 198:====================================================>(113 + 1) / 114]                                                                                [Stage 199:=====================================>               (82 + 33) / 115][Stage 199:============================================>        (96 + 19) / 115][Stage 199:==============================================>     (103 + 12) / 115][Stage 199:====================================================>(113 + 2) / 115][Stage 199:====================================================>(114 + 1) / 115]                                                                                Time elapsed: 3.10192932 seconds
res201: Int = 0

scala> 

scala> val dataSource = "/nidan/orc/individualORC/slide84"
dataSource: String = /nidan/orc/individualORC/slide84

scala> val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  pa rtitionIndex = 57  OR  partitionIndex = 58 ", 4))
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 42  OR  partitionIndex = 43  OR  partitionIndex = 57  OR  partitionIndex = 58 ",4))

scala> 

scala> // query

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 0.391313035 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 200:==========================>                          (61 + 61) / 122][Stage 200:=============================>                       (67 + 55) / 122][Stage 200:=======================================>             (90 + 32) / 122][Stage 200:=================================================>   (114 + 8) / 122]                                                                                [Stage 201:============================>                        (66 + 57) / 123][Stage 201:=================================>                   (77 + 46) / 123][Stage 201:==========================================>         (100 + 23) / 123][Stage 201:===================================================> (120 + 3) / 123]                                                                                Time elapsed: 3.128465144 seconds
res203: Int = 0

scala> 

scala> :quit
17/05/30 01:54:13 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.31:46752) dropped. RpcEnv already stopped.
17/05/30 01:54:13 WARN netty.Dispatcher: Message RemoteProcessDisconnected(128.110.152.31:46752) dropped. RpcEnv already stopped.

real	10m16.617s
user	11m35.324s
sys	0m51.928s
