Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/04/27 01:40:01 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 01:40:15 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 01:40:15 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 01:40:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/04/27 01:40:18 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 01:40:29 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://128.110.152.45:4040
Spark context available as 'sc' (master = spark://ctl:7077, app id = app-20170427014018-0130).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_121)
Type in expressions to have them evaluated.
Type :help for more information.

scala> //spark-shell --master spark://ctl:7077 --driver-memory 28G  --executor-memory 28G  --executor-core s 8  --num-executors 16  --conf spark.io.compression.codec=lzf  --conf spark.akka.frameSize=1024  --conf s park.driver.maxResultSize=2g

scala> 

scala> 

scala> import java.io.File
import java.io.File

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> 

scala> val queryMsg = "#QUERY "
queryMsg: String = "#QUERY "

scala> val loadDBMsg = "#LOAD_DB "
loadDBMsg: String = "#LOAD_DB "

scala> val loadTable = "#LOAD_TABLE "
loadTable: String = "#LOAD_TABLE "

scala> val loadSqlContext = "#LOAD_SQL_CONTEXT "
loadSqlContext: String = "#LOAD_SQL_CONTEXT "

scala> val dataSource = "/nidan/parquet/slide10.prqt"
dataSource: String = /nidan/parquet/slide10.prqt

scala> 

scala> def show_timing[T](proc: => T): T = {
     |     val start=System.nanoTime()
     |     val res = proc
     |     val end = System.nanoTime()
     |     println("Time elapsed: " + (end-start)/1000000000.0 + " seconds")
     |     res
     | }
show_timing: [T](proc: => T)T

scala> 

scala> val writeToLocal = (in:(Array[Byte], Long, String)) =>{
     |     val bytes = in._1
     |     val output = in._3
     |     
     |     val writer = new FileOutputStream(output)
     |     writer.write(bytes)
     |     writer.close
     |   }
writeToLocal: ((Array[Byte], Long, String)) => Unit = <function1>

scala> 

scala> val queries = List(
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0  and imageId = '1.svs'",1),
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0  and imageId = '1.svs'",2),
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0  and imageId = '1.svs'",4),
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0  and imageId = '1.svs'",8)
     | )
queries: List[(String, Int)] = List((SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0 and imageId = '1.svs',1), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0 and imageId = '1.svs',2), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0 and imageId = '1.svs',4), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0 and imageId = '1.svs',8))

scala> 

scala> 

scala> val sqlContext = show_timing{new org.apache.spark.sql.SQLContext(sc)}
warning: there was one deprecation warning; re-run with -deprecation for details
Time elapsed: 0.001351964 seconds
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@664217a8

scala> val pf = show_timing{sqlContext.read.parquet(dataSource)}
Time elapsed: 6.722301438 seconds
pf: org.apache.spark.sql.DataFrame = [imageId: string, imageLevel: int ... 8 more fields]

scala> show_timing{pf.createOrReplaceTempView("data")}
Time elapsed: 0.756201283 seconds

scala> 

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (b ytes, index) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 1:>                                                        (0 + 0) / 120][Stage 1:>                                                      (0 + 112) / 120][Stage 1:===>                                                   (8 + 112) / 120][Stage 1:======>                                               (14 + 106) / 120][Stage 1:======>                                               (15 + 105) / 120][Stage 1:=====================>                                 (46 + 74) / 120][Stage 1:=================================>                     (74 + 46) / 120][Stage 1:==========================================>            (93 + 27) / 120][Stage 1:======================================================>(118 + 2) / 120]                                                                                [Stage 2:======>                                               (14 + 107) / 121][Stage 2:==========================>                            (58 + 63) / 121][Stage 2:===============================================>      (107 + 14) / 121][Stage 2:====================================================>  (116 + 5) / 121][Stage 2:=====================================================> (117 + 4) / 121][Stage 2:=====================================================> (118 + 3) / 121][Stage 2:======================================================>(119 + 2) / 121][Stage 2:======================================================>(120 + 1) / 121]                                                                                Time elapsed: 11.816064707 seconds
res1: Int = 0

scala> 

scala> for (query <- queries){
     | println(s">> Running query: ${query._1}")
     | show_timing{sqlContext.sql(query._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes,  index) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
     | }
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0 and imageId = '1.svs'
[Stage 3:========>                                             (19 + 101) / 120][Stage 3:============================>                          (62 + 58) / 120][Stage 3:==============================================>       (104 + 16) / 120][Stage 3:=====================================================> (116 + 4) / 120][Stage 3:=====================================================> (117 + 3) / 120][Stage 3:======================================================>(119 + 1) / 120]                                                                                [Stage 4:===============>                                       (34 + 87) / 121][Stage 4:=======================================>               (86 + 35) / 121][Stage 4:====================================================>  (115 + 6) / 121][Stage 4:====================================================>  (116 + 5) / 121][Stage 4:=====================================================> (117 + 4) / 121][Stage 4:======================================================>(119 + 2) / 121][Stage 4:======================================================>(120 + 1) / 121]                                                                                Time elapsed: 7.209489483 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0 and imageId = '1.svs'
[Stage 5:=======>                                              (17 + 103) / 120][Stage 5:=============================>                         (65 + 55) / 120][Stage 5:=============================================>        (100 + 20) / 120][Stage 5:=====================================================> (116 + 4) / 120][Stage 5:======================================================>(118 + 2) / 120][Stage 5:======================================================>(119 + 1) / 120]                                                                                [Stage 6:=================================>                     (74 + 47) / 121][Stage 6:===============================================>      (107 + 14) / 121][Stage 6:===================================================>   (114 + 7) / 121][Stage 6:====================================================>  (116 + 5) / 121][Stage 6:======================================================>(119 + 2) / 121][Stage 6:======================================================>(120 + 1) / 121]                                                                                Time elapsed: 6.751756858 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0 and imageId = '1.svs'
[Stage 7:====>                                                  (9 + 111) / 120][Stage 7:======================>                                (48 + 72) / 120][Stage 7:============================================>          (96 + 24) / 120][Stage 7:=====================================================> (116 + 4) / 120][Stage 7:======================================================>(118 + 2) / 120][Stage 7:======================================================>(119 + 1) / 120]                                                                                [Stage 8:======================================>                (85 + 36) / 121][Stage 8:===================================================>   (114 + 7) / 121][Stage 8:=====================================================> (117 + 4) / 121][Stage 8:=====================================================> (118 + 3) / 121][Stage 8:======================================================>(119 + 2) / 121][Stage 8:======================================================>(120 + 1) / 121]                                                                                Time elapsed: 6.461758769 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0 and imageId = '1.svs'
[Stage 9:================>                                      (36 + 84) / 120][Stage 9:======================================>                (83 + 37) / 120][Stage 9:=================================================>    (110 + 10) / 120][Stage 9:====================================================>  (115 + 5) / 120][Stage 9:=====================================================> (117 + 3) / 120][Stage 9:======================================================>(118 + 2) / 120][Stage 9:======================================================>(119 + 1) / 120]                                                                                [Stage 10:====================>                                 (47 + 74) / 121][Stage 10:========================================>             (91 + 30) / 121][Stage 10:==============================================>      (107 + 14) / 121][Stage 10:===================================================>  (115 + 6) / 121][Stage 10:====================================================> (118 + 3) / 121][Stage 10:=====================================================>(119 + 2) / 121][Stage 10:=====================================================>(120 + 1) / 121]                                                                                Time elapsed: 6.855964935 seconds

scala> 

scala> 

scala> :quit
17/04/27 01:41:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
11.2 G  /nidan/parquet/slide1.prqt
12.8 G  /nidan/parquet/slide10.prqt
14.9 G  /nidan/parquet/slide2.prqt
12.8 G  /nidan/parquet/slide3.prqt
18.9 G  /nidan/parquet/slide4.prqt
9.3 G   /nidan/parquet/slide5.prqt
11.6 G  /nidan/parquet/slide6.prqt
13.0 G  /nidan/parquet/slide7.prqt
11.2 G  /nidan/parquet/slide8.prqt
14.9 G  /nidan/parquet/slide9.prqt
