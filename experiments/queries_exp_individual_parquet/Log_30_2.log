Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/04/27 10:28:33 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 10:28:47 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 10:28:47 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 10:28:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/04/27 10:28:50 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/04/27 10:29:04 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://128.110.152.45:4040
Spark context available as 'sc' (master = spark://ctl:7077, app id = app-20170427102850-0161).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_121)
Type in expressions to have them evaluated.
Type :help for more information.

scala> //spark-shell --master spark://ctl:7077 --driver-memory 28G  --executor-memory 28G  --executor-core s 8  --num-executors 16  --conf spark.io.compression.codec=lzf  --conf spark.akka.frameSize=1024  --conf s park.driver.maxResultSize=2g

scala> 

scala> 

scala> 

scala> 

scala> 

scala> import java.io.File
import java.io.File

scala> 

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> 

scala> 

scala> 

scala> val queryMsg = "#QUERY "
queryMsg: String = "#QUERY "

scala> 

scala> val loadDBMsg = "#LOAD_DB "
loadDBMsg: String = "#LOAD_DB "

scala> 

scala> val loadTable = "#LOAD_TABLE "
loadTable: String = "#LOAD_TABLE "

scala> 

scala> val loadSqlContext = "#LOAD_SQL_CONTEXT "
loadSqlContext: String = "#LOAD_SQL_CONTEXT "

scala> 

scala> val dataSource = "/nidan/parquet/slide30.prqt"
dataSource: String = /nidan/parquet/slide30.prqt

scala> 

scala> 

scala> 

scala> def show_timing[T](proc: => T): T = {
     | 
     |     val start=System.nanoTime()
     | 
     |     val res = proc
     | 
     |     val end = System.nanoTime()
     | 
     |     println("Time elapsed: " + (end-start)/1000000000.0 + " seconds")
     | 
     |     res
     | 
     | }
show_timing: [T](proc: => T)T

scala> 

scala> 

scala> 

scala> val writeToLocal = (in:(Array[Byte], Long, String)) =>{
     | 
     |     val bytes = in._1
     | 
     |     val output = in._3
     | 
     |     
     | 
     |     val writer = new FileOutputStream(output)
     | 
     |     writer.write(bytes)
     | 
     |     writer.close
     | 
     |   }
writeToLocal: ((Array[Byte], Long, String)) => Unit = <function1>

scala> 

scala> 

scala> 

scala> val queries = List(
     | 
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0  and imageId = '30.svs'",1),
     | 
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0  and imageId = '30.svs'",2),
     | 
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0  and imageId = '30.svs'",4),
     | 
     | ("SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0  and imageId = '30.svs'",8)
     | 
     | )
queries: List[(String, Int)] = List((SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0 and imageId = '30.svs',1), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0 and imageId = '30.svs',2), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0 and imageId = '30.svs',4), (SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0 and imageId = '30.svs',8))

scala> 

scala> 

scala> 

scala> 

scala> 

scala> val sqlContext = show_timing{new org.apache.spark.sql.SQLContext(sc)}
warning: there was one deprecation warning; re-run with -deprecation for details
Time elapsed: 0.001312602 seconds
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@4af5c14c

scala> 

scala> val pf = show_timing{sqlContext.read.parquet(dataSource).createOrReplaceTempView("data")}
Time elapsed: 9.646219898 seconds
pf: Unit = ()

scala> 

scala> 

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (b ytes, index) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
[Stage 1:>                                                      (0 + 104) / 125][Stage 1:=>                                                     (4 + 104) / 125][Stage 1:==>                                                    (6 + 104) / 125][Stage 1:===>                                                   (8 + 104) / 125][Stage 1:====>                                                 (11 + 104) / 125][Stage 1:=====>                                                (12 + 104) / 125][Stage 1:======>                                               (14 + 104) / 125][Stage 1:======>                                               (15 + 104) / 125][Stage 1:======>                                               (16 + 104) / 125][Stage 1:=========>                                            (23 + 102) / 125][Stage 1:========================>                              (56 + 69) / 125][Stage 1:========================================>              (93 + 32) / 125][Stage 1:============================================>         (103 + 22) / 125][Stage 1:=================================================>    (114 + 11) / 125][Stage 1:===================================================>   (118 + 7) / 125][Stage 1:====================================================>  (119 + 6) / 125][Stage 1:=====================================================> (121 + 4) / 125][Stage 1:=====================================================> (122 + 3) / 125][Stage 1:======================================================>(123 + 2) / 125][Stage 1:======================================================>(124 + 1) / 125]                                                                                [Stage 2:>                                                      (0 + 104) / 126][Stage 2:>                                                      (1 + 104) / 126][Stage 2:===>                                                   (7 + 104) / 126][Stage 2:========>                                             (19 + 104) / 126][Stage 2:=============>                                         (31 + 95) / 126][Stage 2:=======================>                               (54 + 72) / 126][Stage 2:=================================>                     (76 + 50) / 126][Stage 2:========================================>              (92 + 34) / 126][Stage 2:============================================>         (103 + 23) / 126][Stage 2:===============================================>      (111 + 15) / 126][Stage 2:===================================================>   (117 + 9) / 126][Stage 2:====================================================>  (120 + 6) / 126][Stage 2:=====================================================> (123 + 3) / 126][Stage 2:======================================================>(125 + 1) / 126]                                                                                Time elapsed: 15.954125058 seconds
res0: Int = 0

scala> 

scala> 

scala> 

scala> for (query <- queries){
     | 
     | println(s">> Running query: ${query._1}")
     | 
     | show_timing{sqlContext.sql(query._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes,  index) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
     | 
     | }
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=1 and imageLevel = 0 and imageId = '30.svs'
[Stage 3:>                                                      (0 + 104) / 125][Stage 3:>                                                      (1 + 104) / 125][Stage 3:===>                                                   (8 + 104) / 125][Stage 3:=========>                                            (22 + 103) / 125][Stage 3:===============>                                       (35 + 90) / 125][Stage 3:========================>                              (56 + 69) / 125][Stage 3:=============================>                         (68 + 57) / 125][Stage 3:======================================>                (88 + 37) / 125][Stage 3:===========================================>           (99 + 26) / 125][Stage 3:==============================================>       (108 + 17) / 125][Stage 3:=================================================>    (114 + 11) / 125][Stage 3:====================================================>  (120 + 5) / 125][Stage 3:=====================================================> (122 + 3) / 125][Stage 3:======================================================>(123 + 2) / 125][Stage 3:======================================================>(124 + 1) / 125]                                                                                [Stage 4:>                                                      (1 + 104) / 126][Stage 4:==>                                                    (5 + 104) / 126][Stage 4:===>                                                   (8 + 104) / 126][Stage 4:=======>                                              (18 + 104) / 126][Stage 4:===============>                                       (36 + 90) / 126][Stage 4:===========================>                           (62 + 64) / 126][Stage 4:==================================>                    (78 + 48) / 126][Stage 4:==========================================>            (97 + 29) / 126][Stage 4:============================================>         (103 + 23) / 126][Stage 4:==============================================>       (109 + 17) / 126][Stage 4:================================================>     (112 + 14) / 126][Stage 4:===================================================>   (118 + 8) / 126][Stage 4:====================================================>  (120 + 6) / 126][Stage 4:=====================================================> (123 + 3) / 126][Stage 4:======================================================>(125 + 1) / 126]                                                                                Time elapsed: 9.548438599 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=2 and imageLevel = 0 and imageId = '30.svs'
[Stage 5:>                                                      (0 + 104) / 125][Stage 5:>                                                      (2 + 104) / 125][Stage 5:===>                                                   (7 + 104) / 125][Stage 5:========>                                             (19 + 104) / 125][Stage 5:================>                                      (37 + 88) / 125][Stage 5:=======================>                               (54 + 71) / 125][Stage 5:===============================>                       (71 + 54) / 125][Stage 5:=====================================>                 (86 + 39) / 125][Stage 5:===========================================>          (101 + 24) / 125][Stage 5:===============================================>      (109 + 16) / 125][Stage 5:================================================>     (112 + 13) / 125][Stage 5:===================================================>   (116 + 9) / 125][Stage 5:=====================================================> (122 + 3) / 125][Stage 5:======================================================>(123 + 2) / 125][Stage 5:======================================================>(124 + 1) / 125]                                                                                [Stage 6:=>                                                     (4 + 104) / 126][Stage 6:====>                                                 (10 + 104) / 126][Stage 6:============>                                          (29 + 97) / 126][Stage 6:==================>                                    (43 + 83) / 126][Stage 6:===========================>                           (62 + 64) / 126][Stage 6:==================================>                    (78 + 48) / 126][Stage 6:======================================>                (89 + 37) / 126][Stage 6:=========================================>             (96 + 30) / 126][Stage 6:=============================================>        (107 + 19) / 126][Stage 6:================================================>     (114 + 12) / 126][Stage 6:===================================================>   (119 + 7) / 126][Stage 6:====================================================>  (120 + 6) / 126][Stage 6:=====================================================> (123 + 3) / 126][Stage 6:======================================================>(124 + 2) / 126][Stage 6:======================================================>(125 + 1) / 126]                                                                                Time elapsed: 9.238213074 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=4 and imageLevel = 0 and imageId = '30.svs'
[Stage 7:>                                                      (0 + 104) / 125][Stage 7:>                                                      (1 + 104) / 125][Stage 7:==>                                                    (6 + 104) / 125][Stage 7:========>                                             (20 + 104) / 125][Stage 7:==================>                                    (41 + 84) / 125][Stage 7:=========================>                             (57 + 68) / 125][Stage 7:=============================>                         (66 + 59) / 125][Stage 7:=================================>                     (77 + 48) / 125][Stage 7:=======================================>               (89 + 36) / 125][Stage 7:=============================================>        (105 + 20) / 125][Stage 7:===============================================>      (111 + 14) / 125][Stage 7:===================================================>   (117 + 8) / 125][Stage 7:=====================================================> (121 + 4) / 125][Stage 7:======================================================>(123 + 2) / 125][Stage 7:======================================================>(124 + 1) / 125]                                                                                [Stage 8:>                                                      (1 + 104) / 126][Stage 8:====>                                                 (11 + 104) / 126][Stage 8:=============>                                         (30 + 96) / 126][Stage 8:==================>                                    (43 + 83) / 126][Stage 8:=========================>                             (59 + 67) / 126][Stage 8:=============================>                         (68 + 58) / 126][Stage 8:====================================>                  (83 + 43) / 126][Stage 8:=========================================>             (95 + 31) / 126][Stage 8:===========================================>          (102 + 24) / 126][Stage 8:===============================================>      (111 + 15) / 126][Stage 8:=================================================>    (116 + 10) / 126][Stage 8:===================================================>   (119 + 7) / 126][Stage 8:=====================================================> (123 + 3) / 126][Stage 8:======================================================>(124 + 2) / 126][Stage 8:======================================================>(125 + 1) / 126]                                                                                Time elapsed: 9.789311804 seconds
>> Running query: SELECT imageBytes from data where partitionZIndex >= 1 and partitionZIndex <=8 and imageLevel = 0 and imageId = '30.svs'
[Stage 9:>                                                      (0 + 104) / 125][Stage 9:=>                                                     (4 + 104) / 125][Stage 9:======>                                               (14 + 104) / 125][Stage 9:==============>                                        (34 + 91) / 125][Stage 9:======================>                                (51 + 74) / 125][Stage 9:============================>                          (65 + 60) / 125][Stage 9:===================================>                   (80 + 45) / 125][Stage 9:=========================================>             (94 + 31) / 125][Stage 9:===========================================>          (101 + 24) / 125][Stage 9:==============================================>       (108 + 17) / 125][Stage 9:===================================================>   (116 + 9) / 125][Stage 9:====================================================>  (120 + 5) / 125][Stage 9:=====================================================> (122 + 3) / 125][Stage 9:======================================================>(123 + 2) / 125][Stage 9:======================================================>(124 + 1) / 125]                                                                                [Stage 10:=>                                                    (4 + 104) / 126][Stage 10:=====>                                               (13 + 104) / 126][Stage 10:===========>                                          (27 + 99) / 126][Stage 10:========================>                             (57 + 69) / 126][Stage 10:===============================>                      (73 + 53) / 126][Stage 10:====================================>                 (86 + 40) / 126][Stage 10:=========================================>            (96 + 30) / 126][Stage 10:==========================================>          (102 + 24) / 126][Stage 10:==============================================>      (110 + 16) / 126][Stage 10:==================================================>   (117 + 9) / 126][Stage 10:==================================================>   (118 + 8) / 126][Stage 10:===================================================>  (119 + 7) / 126][Stage 10:===================================================>  (120 + 6) / 126][Stage 10:====================================================> (123 + 3) / 126][Stage 10:=====================================================>(125 + 1) / 126]                                                                                Time elapsed: 10.142691013 seconds

scala> 

scala> 

scala> 

scala> 

scala> 

scala> :quit
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
17/04/27 10:30:32 ERROR cluster.StandaloneSchedulerBackend: Could not find CoarseGrainedScheduler.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.removeExecutor(CoarseGrainedSchedulerBackend.scala:423)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.executorRemoved(StandaloneSchedulerBackend.scala:160)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:182)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
