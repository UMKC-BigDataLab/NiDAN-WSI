    1  clear
    2  sudo apt-get -y update  && sudo apt-get -y install default-jdk && sudo apt-get -y install ssh && sudo apt-get -    y install rsync
    3  sudo apt-get -y install rsync
    4  clear
    5  ssh-keygen -t dsa -P ' ' -f ~/.ssh/id_dsa
    6  ls ~
    7  pwd
    8  ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
    9  cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
   10  ls
   11  pwd
   12  mkdir sources
   13  wget -c http://mirror.olnevhost.net/pub/apache/hadoop/common/current/hadoop-2.6.0.tar.gz
   14  wget -c http://mirror.olnevhost.net/pub/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz
   15  clear
   16  ls
   17  mv hadoop-2.6.0.tar.gz  sources/
   18  clear
   19  cd sources/
   20  tar -xvzf hadoop-2.6.0.tar.gz 
   21  clear
   22  ls
   23  sudo mv hadoop-2.6.0 /usr/local/hadoop
   24  update-alternatives --config java
   25  clear
   26  ls /usr/lib/jvm/
   27  ls /usr/
   28  ls /usr/local/
   29  clear
   30  cd ..
   31  clear
   32  ls
   33  ls -a
   34  vim .bashrc 
   35  source .bashrc 
   36  cd $HADOOP_HOME
   37  clear
   38  ls
   39  cd etc/
   40  clear
   41  ls
   42  cd hadoop/
   43  clear
   44  sudo vim hadoop-env.sh 
   45  sudo vim core-site.xml 
   46  sudo vim yarn-site.xml 
   47  clear
   48  sudo cp mapred-site.xml.template mapred-site.xml
   49  vim mapred-site.xml
   50  sudo vim mapred-site.xml
   51  clear
   52  sudo vim hdfs-site.xml 
   53  cd 
   54  sudo mkdir -p /usr/local/hadoop/hadoop_data/hdfs/namenode & sudo mkdir -p /usr/local/hadoop/hadoop_data/hdfs/datanode 
   55  ls /usr/local/hadoop/hadoop_data/hdfs/
   56  sudo chown dl544:dl544 -R /usr/local/hadoop
   57  sudo chown dl544 -R /usr/local/hadoop
   58  hdfs namenode -format
   59  du -h /usr/lib/jvm/java-7-openjdk-amd64/bin/java
   60  ls /usr/lib/jvm/java-7-openjdk-amd64/bin/
   61  ls /usr/lib/jvm/java-7-openjdk-amd64
   62  ls /usr/lib/jvm/java-7-openjdk-arm64/
   63  vim .bashrc 
   64  source .bashrc 
   65  sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh 
   66  hdfs namenode -format
   67  cd $HADOOP_HOME/etc/hadoop
   68  ls
   69  sudo vim yarn-site.xml 
   70  cd 
   71  hdfs namenode -format
   72  start-all.sh 
   73  jps
   74  sudo apt-get install git
   75  clear
   76  ls
   77  mkdir Nidan
   78  cd Nidan/
   79  clear
   80  git config --global user.name "delopezbarron"
   81  git config --global user.email "de.lopezbarron@gmail.com"
   82  git clone https://github.com/vn539/NIDAN-Thesis.git
   83  ls
   84  cd NIDAN-Thesis/
   85  clear
   86  ls
   87  cd ..
   88  clear
   89  ls
   90  cd ..
   91  ls
   92  rm -Rf Nidan/
   93  mkdir Nidan
   94  cd Nidan/
   95  clear
   96  git init
   97  git clone https://github.com/vn539/NIDAN-Thesis.git --branch dev
   98  ls
   99  ls NIDAN-Thesis/
  100  clear
  101  ls
  102  cd sources/
  103  clear
  104  ls
  105  ifconfig 
  106  clear
  107  cd ..
  108  clear
  109  ls
  110  chmod u+x ClusterSetUp.sh 
  111  ls
  112  ./ClusterSetUp.sh 
  113  ls
  114  ls sources/
  115  update-alternatives --config java 
  116  ls sources/
  117  ls
  118  ls sources/
  119  java
  120  java -splash
  121  whereis java
  122  whereis javac
  123  sudo whereis javac
  124  sudo whereis jdk
  125  sudo whereis javap
  126  ls /usr/local/hadoop/etc/hadoop/core-site.xml 
  127  cat /usr/local/hadoop/etc/hadoop/core-site.xml 
  128  cat /usr/local/hadoop/etc/hadoop/yarn-
  129  cat /usr/local/hadoop/etc/hadoop/yarn-site.xml 
  130  cat /usr/local/hadoop/etc/hadoop/mapred-site.xml
  131  cat /usr/local/hadoop/etc/hadoop/hdfs-site.xml 
  132  clear
  133  cd /usr/local/spark/
  134  clear
  135  ls
  136  cd conf/
  137  clear
  138  ls
  139  vim slaves
  140  vim spark-env.sh
  141  cd ~
  142  clear
  143  ls
  144  ls -a
  145  cat .viminfo 
  146  clear
  147  ifconfig 
  148  clear
  149  pwd
  150  vim .vimrc 
  151  clear
  152  vim .vimrc 
  153  clear
  154  ls
  155  cd Nidan/
  156  clear
  157  ls
  158  cd NIDAN-Thesis/
  159  clear
  160  ls
  161  cd src/
  162  clear
  163  ls
  164  source ~/.bashrc 
  165  vim ~/.bashrc 
  166  ls /usr/local/spark/
  167  vim ~/.bashrc 
  168  source ~/.bashrc 
  169  spark-shell 
  170  clear
  171  ls -a
  172  clear
  173  ls
  174  cd ..
  175  clear
  176  ls
  177  cat README.md 
  178  jar cf nidan-project-1.0.jar src/
  179  ls
  180  rm nidan-project-1.0.jar 
  181  cd src/
  182  clear
  183  ls
  184  vim Makefile
  185  make clean
  186  vim Makefile 
  187  make clean
  188  vim Makefile 
  189  make all
  190  echo $CLASSPATH 
  191  ls /usr/local/spark/lib/
  192  ls /usr/local/hadoop/lib
  193  ls /usr/local/hadoop/
  194  ls /usr/local/hadoop/include/
  195  ls /usr/local/hadoop/hadoop_data/
  196  ls /usr/local/hadoop/hadoop_data/hdfs/
  197  ls /usr/local/hadoop/lib
  198  ls /usr/local/hadoop/libexec/
  199  ls /usr/local/hadoop/share/
  200  ls /usr/local/hadoop/share/hadoop/
  201  ls /usr/local/hadoop/share/hadoop/yarn/
  202  ls /usr/local/hadoop/share/hadoop/yarn/lib/
  203  ls /usr/local/spark/
  204  ls /usr/local/spark/bin/
  205  ls /usr/local/spark/conf/
  206  ls /usr/local/spark/lib/
  207  jar tvf /usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar 
  208  make all
  209  jar tvf /usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar | grep "org.apache.spark.SparkConf"
  210  echo $CLASSPATH 
  211  vim ~/.bashrc 
  212  source ~/.bashrc 
  213  clear
  214  make all
  215  cat ~/.bashrc 
  216  vim MA
  217  vim Makefile 
  218  clear
  219  make all
  220  vim Makefile 
  221  make all
  222  vim Makefile 
  223  make all
  224  clear
  225  make all
  226  vim Makefile 
  227  clear
  228  make all
  229  ls
  230  spark-shell 
  231  clear
  232  vim Makefile 
  233  clear
  234  ls
  235  make all
  236  vim Makefile 
  237  cklear
  238  clear
  239  make clean
  240  make compile
  241  cat ~/.bashrc 
  242  ls ~/sources/
  243  mv ~/sources/scala-2.11.6 /usr/local/scala
  244  sudo mv ~/sources/scala-2.11.6 /usr/local/scala
  245  sudo chown -R dl544 /usr/local/scala
  246  clear
  247  make clean
  248  make compile
  249  vim Makefile 
  250  make clean
  251  clear
  252  ls
  253  make compile
  254  scalad --help
  255  scalac --help
  256  scalac -help
  257  clear
  258  vim Makefile 
  259  make compile
  260  sudo chmod u+wx -R /usr/lib/jvm
  261  make compile
  262  sudo chown -R dl544 /usr/lib/jvm
  263  make compile
  264  sudo chown -R dl544 /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64
  265  make compile
  266  sudo chmod a+wrx -R /usr/lib/jvm/
  267  make compile
  268  clear
  269  make compile
  270  ls /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  271  ls -l /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  272  ls -la /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  273  ls -ls /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  274  ls -ln /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  275  ls -l /usr/lib/jvm/java-1.7.0-openjdk-arm64
  276  ls -ln /usr/lib/jvm/java-7-openjdk-arm64/lib/aarch64/
  277  sudo chmod -R 777 /usr/lib/jvm/
  278  make compile
  279  clear
  280  vim Makefile 
  281  make compile
  282  vim Makefile 
  283  make compile
  284  clear
  285  ls
  286  vim Makefile 
  287  make compile
  288  clear
  289  cat * | grep "main("
  290  cat UnionRDDTrial.scala 
  291  clear
  292  vim UnionRDDTrial.scala 
  293  vim Makefile 
  294  vim UnionRDDTrial.scala 
  295  vim Makefile 
  296  clear
  297  make compile
  298  clear
  299  ls
  300  vim Makefile 
  301  make compile
  302  clear
  303  vim Makefile 
  304  clear
  305  make compile
  306  ls
  307  vim Makefile 
  308  make compile
  309  ls
  310  cat SparkSequence.scala 
  311  clear
  312  make compile
  313  vim Makefile 
  314  make compile
  315  scalac -help
  316  vim Makefile 
  317  make compile
  318  scala -classpath ./ *.scala
  319  scala -classpath ./:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar *.scala
  320  ls /usr/local/spark/lib/*.jar
  321  jar tvf /usr/local/spark/lib/*.jar
  322  jar tvf /usr/local/spark/lib/*
  323  jar tvf /usr/local/spark/lib/
  324* jar tvf /usr/local/spark/lib/
  325  scala -classpath "./:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar" *.scala
  326  ifconfig 
  327  clear
  328  cd ..
  329  clear
  330  ls
  331  ls -a
  332  mkdir libs
  333  mv ~/compress-lzf-1.0.3.jar libs/
  334  clear
  335  git commit -am "Creating a make file for the project"
  336  git add libs/
  337  git add src/
  338  git commit -m "Result of executing the makefile"
  339  git branch
  340  git push origin dev
  341  clear
  342  ls
  343  cd src/
  344  clear
  345  ls
  346  scala -classpath "./:../libs/*.jar:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar" *.scala
  347  jar tvf ../libs/compress-lzf-1.0.3.jar 
  348  scala -classpath "./*class:../libs/*.jar:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar" *.scala
  349  scalac -classpath "./*class:../libs/*.jar:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar" *.scala
  350  clear
  351  ls
  352  scalac -classpath "./*class:../libs/*.jar:/usr/local/spark/lib/*.jar:/usr/local/hadoop/lib/*.jar" HDFSToLocal.scala
  353  scalac HDFSToLocal.scala 
  354  scalac -classpath ../libs/compress-lzf-1.0.3.jar HDFSToLocal.scala 
  355  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/lib/  HDFSToLocal.scala 
  356  ls /usr/local/hadoop/lib
  357  ls /usr/local/hadoop/lib/native/
  358  ls /usr/local/hadoop/
  359  ls /usr/local/hadoop/bin/
  360  ls /usr/local/hadoop/etc/
  361  ls /usr/local/hadoop/etc/hadoop/
  362  ls /usr/local/hadoop/include/
  363  ls /usr/local/hadoop/lib
  364  ls /usr/local/hadoop/lib/native/
  365  ls /usr/local/hadoop/sbin/
  366  ls /usr/local/hadoop/share/
  367  ls /usr/local/hadoop/share/hadoop/
  368  ls /usr/local/hadoop/share/hadoop/hdfs/
  369  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/hdfs/*.jar  HDFSToLocal.scala 
  370  ls /usr/local/hadoop/share/hadoop/hdfs/
  371  ls /usr/local/hadoop/share/hadoop/common/
  372  ls /usr/local/hadoop/share/hadoop/common/lib/
  373  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/*.jar  HDFSToLocal.scala 
  374  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/*.jar  HDFSToLocal.scala 
  375  ls /usr/local/hadoop/share/hadoop/
  376  ls /usr/local/hadoop/share/hadoop/tools/
  377  ls /usr/local/hadoop/share/hadoop/tools/lib/
  378  ls /usr/local/hadoop/share/hadoop/
  379  ls /usr/local/hadoop/share/
  380  ls /usr/local/hadoop/share/ha
  381  ls /usr/local/hadoop/share/hadoop/
  382  ls /usr/local/hadoop/share/hadoop/common/
  383  jar tvf /usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar | grep "apache"
  384  jar tvf /usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar | grep "BytesWritable"
  385  jar tvf /usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar | grep "IntWritable"
  386  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar  HDFSToLocal.scala 
  387  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  HDFSToLocal.scala 
  388  scalac -classpath ../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  *.scala 
  389  scalac -classpath ./ImageSplits.class:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  *.scala 
  390  scalac -classpath ./*.class:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  *.scala 
  391  ls
  392  scalac -classpath ./*.java:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  *.scala 
  393  ls
  394  scalac -classpath ./*.java:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar  UnionRDDTrial.scala 
  395  scalac -classpath ./*.java:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar SparkPartitioner.scala 
  396  scalac -classpath ./ImageSplits.class:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar SparkPartitioner.scala 
  397  jar cf is.jar ImageSplits.class 
  398  scalac -classpath ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar SparkPartitioner.scala 
  399  scalac -deprecation -classpath ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar SparkPartitioner.scala 
  400  scalac -deprecation -classpath ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.scala 
  401  scalac -classpath ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.scala 
  402  ls
  403  cat Makefile 
  404  javacc -cp ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.java
  405  javac -cp ./is.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.java
  406  javac -cp ./*.class:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.java
  407  ls
  408  jar cf dick.jar *.jar
  409  javac -cp ./dick.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.java
  410  rm dick.jar 
  411  jar cf dick.jar *.class
  412  javac -cp ./dick.jar:../libs/compress-lzf-1.0.3.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.6.0.jar *.java
  413  ls
  414  vim Test.java
  415  javac Test.java 
  416  jar cf Bigick.jar *.class
  417  java -jar Bigick.jar Test
  418  java -jar Bigick.jar
  419* java -cp Bi
  420  cat Test.
  421  cat Test.java 
  422  vim Test.java 
  423  javac Test.java 
  424  java -cp BigDick.jar Test
  425  java -jar BigDick.jar Test
  426  jar cf BigDick.jar *.class
  427  java -cp BigDick.jar Test
  428  rm BigDick.jar 
  429  clear
  430  ls
  431  rm dick.jar 
  432  rm Bigick.jar 
  433  clear
  434  ls
  435  history 
  436  ifconfig 
  437  history > commands.txt
