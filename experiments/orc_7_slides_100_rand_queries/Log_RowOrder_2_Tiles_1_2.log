Warning: Ignoring non-spark config property: hive.exec.reducers.bytes.per.reducer=67108864
Warning: Ignoring non-spark config property: hive.fetch.task.aggr=false
Warning: Ignoring non-spark config property: hive.merge.sparkfiles=false
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask=true
Warning: Ignoring non-spark config property: hive.merge.size.per.task=256000000
Warning: Ignoring non-spark config property: hive.smbjoin.cache.rows=10000
Warning: Ignoring non-spark config property: hive.merge.smallfiles.avgsize=16000000
Warning: Ignoring non-spark config property: hive.optimize.sort.dynamic.partition=false
Warning: Ignoring non-spark config property: hive.exec.orc.default.stripe.size=67108864
Warning: Ignoring non-spark config property: hive.vectorized.execution.enabled=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication.min.reducer=4
Warning: Ignoring non-spark config property: hive.orc.splits.include.file.footer=false
Warning: Ignoring non-spark config property: hive.merge.mapfiles=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.list-status.num-threads=5
Warning: Ignoring non-spark config property: hive.vectorized.groupby.checkinterval=4096
Warning: Ignoring non-spark config property: hive.compute.query.using.stats=true
Warning: Ignoring non-spark config property: mapreduce.input.fileinputformat.split.maxsize=750000000
Warning: Ignoring non-spark config property: hive.merge.orcfile.stripe.level=true
Warning: Ignoring non-spark config property: hive.auto.convert.join.noconditionaltask.size=894435328
Warning: Ignoring non-spark config property: hive.fetch.task.conversion.threshold=1073741824
Warning: Ignoring non-spark config property: hive.auto.convert.join=true
Warning: Ignoring non-spark config property: hive.optimize.reducededuplication=true
Warning: Ignoring non-spark config property: hive.vectorized.groupby.flush.percent=0.1
Warning: Ignoring non-spark config property: hive.fetch.task.conversion=more
Warning: Ignoring non-spark config property: hive.limit.pushdown.memory.usage=0.4
Warning: Ignoring non-spark config property: hive.vectorized.execution.reduce.enabled=false
Warning: Ignoring non-spark config property: hive.map.aggr=true
Warning: Ignoring non-spark config property: hive.stats.autogather=true
Warning: Ignoring non-spark config property: hive.stats.fetch.column.stats=true
Warning: Ignoring non-spark config property: hive.cbo.enable=true
Warning: Ignoring non-spark config property: hive.map.aggr.hash.percentmemory=0.5
Warning: Ignoring non-spark config property: hive.optimize.index.filter=true
Warning: Ignoring non-spark config property: hive.optimize.bucketmapjoin.sortedmerge=false
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/25 12:47:50 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/25 12:48:05 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/25 12:48:05 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/25 12:48:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/25 12:48:08 WARN spark.SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
17/05/25 12:48:20 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://128.110.152.45:4040
Spark context available as 'sc' (master = spark://ctl:7077, app id = app-20170525124808-0653).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_121)
Type in expressions to have them evaluated.
Type :help for more information.

scala> import java.io.File
import java.io.File

scala> import java.io.FileOutputStream
import java.io.FileOutputStream

scala> import org.apache.spark.sql._
import org.apache.spark.sql._

scala> 

scala> val queryMsg = "#QUERY "
queryMsg: String = "#QUERY "

scala> val loadDBMsg = "#LOAD_DB "
loadDBMsg: String = "#LOAD_DB "

scala> val loadTable = "#LOAD_TABLE "
loadTable: String = "#LOAD_TABLE "

scala> val loadsqlHive = "#LOAD_SQL_CONTEXT "
loadsqlHive: String = "#LOAD_SQL_CONTEXT "

scala> val dataSource = "/nidan/orc/individualORC/slide1"
dataSource: String = /nidan/orc/individualORC/slide1

scala> 

scala> def show_timing[T](proc: => T): T = {
     |     val start=System.nanoTime()
     |     val res = proc
     |     val end = System.nanoTime()
     |     println("Time elapsed: " + (end-start)/1000000000.0 + " seconds")
     |     res
     | }
show_timing: [T](proc: => T)T

scala> 

scala> val writeToLocal = (in:(Array[Byte], Long, String)) =>{
     |     val bytes = in._1
     |     val output = in._3
     |     
     |     val writer = new FileOutputStream(output)
     |     writer.write(bytes)
     |     writer.close
     |     1
     |   }
writeToLocal: ((Array[Byte], Long, String)) => Int = <function1>

scala>   
     |   val queries = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 120  partitionIndex = 120 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 65  OR  partitionIndex = 79 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 135  OR  partitionIndex = 136 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 182  OR  partitionIndex = 183 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 77  OR  partitionIndex = 78 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 45  OR  partitionIndex = 46 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 86  OR  partitionIndex = 98 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 144 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 96  OR  partitionIndex = 97 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 44  OR  partitionIndex = 58 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 171  OR  partitionIndex = 172 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 165  OR  partitionIndex = 166 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 23  OR  partitionIndex = 24 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 82  OR  partitionIndex = 94 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 177  OR  partitionIndex = 178 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 153  OR  partitionIndex = 167 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 101  OR  partitionIndex = 115 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 63  OR  partitionIndex = 77 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 112 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 26  OR  partitionIndex = 38 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 143  OR  partitionIndex = 144 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 212  OR  partitionIndex = 226 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 36  OR  partitionIndex = 37 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 104  OR  partitionIndex = 118 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 169  OR  partitionIndex = 170 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 185  OR  partitionIndex = 199 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 181  OR  partitionIndex = 195 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 188  OR  partitionIndex = 189 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 117  OR  partitionIndex = 118 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 152  OR  partitionIndex = 166 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 18  OR  partitionIndex = 30 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 21  OR  partitionIndex = 22 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 105  OR  partitionIndex = 119 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 92  OR  partitionIndex = 93 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 150  OR  partitionIndex = 162 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 195  OR  partitionIndex = 209 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 8  OR  partitionIndex = 9 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 75  OR  partitionIndex = 89 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 44  OR  partitionIndex = 45 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 109  OR  partitionIndex = 110 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 41  OR  partitionIndex = 55 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 89  OR  partitionIndex = 90 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 235  OR  partitionIndex = 236 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 182  OR  partitionIndex = 196 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 214  OR  partitionIndex = 215 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 184  OR  partitionIndex = 185 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 0  OR  partitionIndex = 1 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 233  OR  partitionIndex = 234 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 142  OR  partitionIndex = 154 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 218  OR  partitionIndex = 219 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 95  OR  partitionIndex = 109 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 78  OR  partitionIndex = 90 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 29  OR  partitionIndex = 30 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 47  OR  partitionIndex = 48 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 160  OR  partitionIndex = 174 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 39  OR  partitionIndex = 53 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 220  OR  partitionIndex = 221 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 30  OR  partitionIndex = 42 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 45  OR  partitionIndex = 59 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 135  OR  partitionIndex = 149 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 194  OR  partitionIndex = 208 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 32  OR  partitionIndex = 46 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 105  OR  partitionIndex = 106 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 213  OR  partitionIndex = 227 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 5  OR  partitionIndex = 19 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 197  OR  partitionIndex = 198 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 159  OR  partitionIndex = 173 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 97  OR  partitionIndex = 111 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 164  OR  partitionIndex = 178 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 191  OR  partitionIndex = 205 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 12  OR  partitionIndex = 56 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 192  OR  partitionIndex = 236 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 87  OR  partitionIndex = 88 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 161  OR  partitionIndex = 175 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 27  OR  partitionIndex = 28 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 157  OR  partitionIndex = 171 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 128  OR  partitionIndex = 129 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 210  OR  partitionIndex = 211 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 14  OR  partitionIndex = 15 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 198  OR  partitionIndex = 210 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 10  OR  partitionIndex = 11 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 99  OR  partitionIndex = 113 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 113  OR  partitionIndex = 114 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 138  OR  partitionIndex = 150 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 132  OR  partitionIndex = 133 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 180  OR  partitionIndex = 181 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 227  OR  partitionIndex = 228 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 125  OR  partitionIndex = 139 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 190  OR  partitionIndex = 191 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 9  OR  partitionIndex = 23 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 68  OR  partitionIndex = 69 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 133  OR  partitionIndex = 147 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 40  OR  partitionIndex = 54 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 156  OR  partitionIndex = 157 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 17  OR  partitionIndex = 18 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 85  OR  partitionIndex = 86 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 186  OR  partitionIndex = 200 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 179  OR  partitionIndex = 180 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 59  OR  partitionIndex = 60 ", 2),
     | ("SELECT imageBytes FROM data WHERE  partitionIndex = 189  OR  partitionIndex = 203 ", 2)
     | )
queries: List[(String, Int)] = List(("SELECT imageBytes FROM data WHERE  partitionIndex = 120  partitionIndex = 120 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 65  OR  partitionIndex = 79 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 135  OR  partitionIndex = 136 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 182  OR  partitionIndex = 183 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 77  OR  partitionIndex = 78 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 45  OR  partitionIndex = 46 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 86  OR  partitionIndex = 98 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex = 130  OR  partitionIndex = 144 ",2), ("SELECT imageBytes FROM data WHERE  partitionIndex =...
scala> 

scala> val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@1c11a496

scala> 

scala> show_timing{sqlContext.read.orc(dataSource).createOrReplaceTempView("data")}
Time elapsed: 3.953154525 seconds

scala> 

scala> show_timing{sqlContext.sql(queries(0)._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, ind ex) => (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
org.apache.spark.sql.catalyst.parser.ParseException:
extraneous input 'partitionIndex' expecting {<EOF>, '.', '[', 'GROUP', 'ORDER', 'HAVING', 'LIMIT', 'OR', 'AND', 'IN', NOT, 'BETWEEN', 'LIKE', RLIKE, 'IS', 'WINDOW', 'UNION', 'EXCEPT', 'MINUS', 'INTERSECT', EQ, '<=>', '<>', '!=', '<', LTE, '>', GTE, '+', '-', '*', '/', '%', 'DIV', '&', '|', '^', 'SORT', 'CLUSTER', 'DISTRIBUTE'}(line 1, pos 57)

== SQL ==
SELECT imageBytes FROM data WHERE  partitionIndex = 120  partitionIndex = 120
---------------------------------------------------------^^^

  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:197)
  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:99)
  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:45)
  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:53)
  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:592)
  at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)
  at $anonfun$1.apply$mcI$sp(<console>:38)
  at $anonfun$1.apply(<console>:38)
  at $anonfun$1.apply(<console>:38)
  at show_timing(<console>:30)
  ... 50 elided

scala> 

scala> for (query <- queries){
     | println(s">> Running query: ${query._1}")
     | show_timing{sqlContext.sql(query._1).map(_.getAs[Array[Byte]](0)).rdd.zipWithIndex.map{case (bytes, index) = > (bytes, index, s"o6_${index}.JPEG")}.collect.map(writeToLocal).filter(_ => false).size}
     | }
>> Running query: SELECT imageBytes FROM data WHERE  partitionIndex = 120  partitionIndex = 120 
org.apache.spark.sql.catalyst.parser.ParseException:
extraneous input 'partitionIndex' expecting {<EOF>, '.', '[', 'GROUP', 'ORDER', 'HAVING', 'LIMIT', 'OR', 'AND', 'IN', NOT, 'BETWEEN', 'LIKE', RLIKE, 'IS', 'WINDOW', 'UNION', 'EXCEPT', 'MINUS', 'INTERSECT', EQ, '<=>', '<>', '!=', '<', LTE, '>', GTE, '+', '-', '*', '/', '%', 'DIV', '&', '|', '^', 'SORT', 'CLUSTER', 'DISTRIBUTE'}(line 1, pos 57)

== SQL ==
SELECT imageBytes FROM data WHERE  partitionIndex = 120  partitionIndex = 120
---------------------------------------------------------^^^

  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:197)
  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:99)
  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:45)
  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:53)
  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:592)
  at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)
  at $anonfun$1$$anonfun$apply$1.apply$mcI$sp(<console>:40)
  at $anonfun$1$$anonfun$apply$1.apply(<console>:40)
  at $anonfun$1$$anonfun$apply$1.apply(<console>:40)
  at show_timing(<console>:30)
  at $anonfun$1.apply(<console>:40)
  at $anonfun$1.apply(<console>:38)
  at scala.collection.immutable.List.foreach(List.scala:381)
  ... 53 elided

scala> 

scala> :quit

real	0m55.812s
user	3m8.460s
sys	0m2.600s
